{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Text Vectorization for Toxic Comment Classification\n",
    "\n",
    "This notebook compares traditional vectorization methods (TF-IDF, Count) with advanced embedding techniques (Word2Vec, GloVe, FastText) on the toxic comment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import torch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Available CPU cores: {n_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "train_data = pd.read_csv('../Dataset/train_preprocessed.csv')\n",
    "\n",
    "# Check the data\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target labels\n",
    "X = train_data['processed_text']  # Use the preprocessed text\n",
    "y = train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(\"\")  # Replace NaN values with empty strings\n",
    "y = y.fillna(0)   # Replace any missing target values with 0\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y['toxic']\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Advanced Vectorizers\n",
    "\n",
    "Let's implement custom vectorizers for Word2Vec, GloVe, and FastText embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec Vectorizer\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=1, workers=4, sg=1):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers\n",
    "        self.sg = sg  # 0 for CBOW, 1 for Skip-gram\n",
    "        self.model = None\n",
    "        self.word_vectors = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Tokenize the text\n",
    "        tokenized_corpus = [nltk.word_tokenize(text.lower()) for text in tqdm(X, desc=\"Tokenizing for Word2Vec\")]\n",
    "        \n",
    "        # Train Word2Vec model\n",
    "        print(\"Training Word2Vec model...\")\n",
    "        self.model = Word2Vec(\n",
    "            sentences=tokenized_corpus,\n",
    "            vector_size=self.vector_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=self.workers,\n",
    "            sg=self.sg\n",
    "        )\n",
    "        \n",
    "        self.word_vectors = self.model.wv\n",
    "        print(f\"Word2Vec model trained with {len(self.word_vectors.key_to_index)} words\")\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        tokenized_corpus = [nltk.word_tokenize(text.lower()) for text in tqdm(X, desc=\"Vectorizing with Word2Vec\")]\n",
    "        \n",
    "        # Create document vectors by averaging word vectors\n",
    "        doc_vectors = np.zeros((len(tokenized_corpus), self.vector_size))\n",
    "        for i, tokens in enumerate(tokenized_corpus):\n",
    "            vec = np.zeros(self.vector_size)\n",
    "            count = 0\n",
    "            for token in tokens:\n",
    "                if token in self.word_vectors:\n",
    "                    vec += self.word_vectors[token]\n",
    "                    count += 1\n",
    "            if count > 0:\n",
    "                vec /= count\n",
    "            doc_vectors[i] = vec\n",
    "        \n",
    "        return doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText Vectorizer\n",
    "class FastTextVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=1, workers=4):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Tokenize the text\n",
    "        tokenized_corpus = [nltk.word_tokenize(text.lower()) for text in tqdm(X, desc=\"Tokenizing for FastText\")]\n",
    "        \n",
    "        # Train FastText model\n",
    "        print(\"Training FastText model...\")\n",
    "        self.model = FastText(\n",
    "            sentences=tokenized_corpus,\n",
    "            vector_size=self.vector_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=self.workers\n",
    "        )\n",
    "        \n",
    "        print(f\"FastText model trained with {len(self.model.wv.key_to_index)} words\")\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        tokenized_corpus = [nltk.word_tokenize(text.lower()) for text in tqdm(X, desc=\"Vectorizing with FastText\")]\n",
    "        \n",
    "        # Create document vectors by averaging word vectors\n",
    "        doc_vectors = np.zeros((len(tokenized_corpus), self.vector_size))\n",
    "        for i, tokens in enumerate(tokenized_corpus):\n",
    "            vec = np.zeros(self.vector_size)\n",
    "            count = 0\n",
    "            for token in tokens:\n",
    "                # FastText can handle OOV words\n",
    "                vec += self.model.wv[token]\n",
    "                count += 1\n",
    "            if count > 0:\n",
    "                vec /= count\n",
    "            doc_vectors[i] = vec\n",
    "        \n",
    "        return doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe - Using pre-trained embeddings\n",
    "class GloveVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100):\n",
    "        self.vector_size = vector_size\n",
    "        self.word_vectors = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Attempt to download pre-trained GloVe using gensim downloader\n",
    "        try:\n",
    "            import gensim.downloader as api\n",
    "            print(\"Downloading pre-trained GloVe embeddings...\")\n",
    "            # Use a smaller model for demonstration\n",
    "            glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "            self.word_vectors = {word: glove_model[word] for word in glove_model.key_to_index}\n",
    "            print(f\"Loaded GloVe embeddings with {len(self.word_vectors)} words\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading GloVe: {e}\")\n",
    "            print(\"Will use an empty embedding. Results will be poor.\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        tokenized_corpus = [nltk.word_tokenize(text.lower()) for text in tqdm(X, desc=\"Vectorizing with GloVe\")]\n",
    "        \n",
    "        # Create document vectors by averaging word vectors\n",
    "        doc_vectors = np.zeros((len(tokenized_corpus), self.vector_size))\n",
    "        for i, tokens in enumerate(tokenized_corpus):\n",
    "            vec = np.zeros(self.vector_size)\n",
    "            count = 0\n",
    "            for token in tokens:\n",
    "                if token in self.word_vectors:\n",
    "                    vec += self.word_vectors[token]\n",
    "                    count += 1\n",
    "            if count > 0:\n",
    "                vec /= count\n",
    "            doc_vectors[i] = vec\n",
    "        \n",
    "        return doc_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, model_name):\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    \n",
    "    # Calculate F1 scores for each class\n",
    "    f1_scores = []\n",
    "    for i, column in enumerate(y.columns):\n",
    "        f1 = f1_score(y[column], y_pred[:, i])\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # Calculate macro and micro F1\n",
    "    macro_f1 = np.mean(f1_scores)\n",
    "    micro_f1 = f1_score(y, y_pred, average='micro')\n",
    "    \n",
    "    print(f\"\\n============ {model_name} Results ============\")\n",
    "    print(f\"Inference time: {inference_time:.2f} seconds\")\n",
    "    print(f\"Validation accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "    print(f\"Micro F1: {micro_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nF1 scores by toxicity type:\")\n",
    "    for i, column in enumerate(y.columns):\n",
    "        f1 = f1_score(y[column], y_pred[:, i])\n",
    "        print(f\"{column}: {f1:.4f}\")\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_f1': micro_f1,\n",
    "        'inference_time': inference_time\n",
    "    }\n",
    "    \n",
    "    for i, column in enumerate(y.columns):\n",
    "        results[f'f1_{column}'] = f1_scores[i]\n",
    "    \n",
    "    return results, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and Evaluate Traditional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "print(\"\\n\\n================ PREPARING TF-IDF VECTORS ================\")\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(\"Fitting TF-IDF vectorizer...\")\n",
    "start_time = time.time()\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"TF-IDF vectorizer fitted in {train_time:.2f} seconds\")\n",
    "\n",
    "# Transform training and validation data\n",
    "print(\"Transforming data with TF-IDF...\")\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "print(f\"TF-IDF vectors shape: {X_train_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Count Vectorizer\n",
    "print(\"\\n\\n================ PREPARING COUNT VECTORS ================\")\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "print(\"Fitting Count vectorizer...\")\n",
    "start_time = time.time()\n",
    "count_vectorizer.fit(X_train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Count vectorizer fitted in {train_time:.2f} seconds\")\n",
    "\n",
    "# Transform training and validation data\n",
    "print(\"Transforming data with Count Vectorizer...\")\n",
    "X_train_count = count_vectorizer.transform(X_train)\n",
    "X_val_count = count_vectorizer.transform(X_val)\n",
    "print(f\"Count vectors shape: {X_train_count.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec + SVM\n",
    "w2v_vectorizer = Word2VecVectorizer(vector_size=1000, window=5, min_count=1, workers=n_cores, sg=1)\n",
    "\n",
    "# Fit the vectorizer to get word embeddings\n",
    "print(\"Fitting Word2Vec vectorizer...\")\n",
    "start_time = time.time()\n",
    "w2v_vectorizer.fit(X_train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Word2Vec training completed in {train_time:.2f} seconds\")\n",
    "\n",
    "# Transform training data\n",
    "print(\"Transforming training data with Word2Vec...\")\n",
    "X_train_w2v = w2v_vectorizer.transform(X_train)\n",
    "\n",
    "# # Train classifier\n",
    "# w2v_classifier = MultiOutputClassifier(LinearSVC(\n",
    "#     C=1.0,\n",
    "#     max_iter=10000,\n",
    "#     dual=False,\n",
    "#     class_weight='balanced',\n",
    "#     random_state=42\n",
    "# ))\n",
    "\n",
    "# print(\"Training Word2Vec + SVM classifier...\")\n",
    "# start_time = time.time()\n",
    "# w2v_classifier.fit(X_train_w2v, y_train)\n",
    "# train_time = time.time() - start_time\n",
    "# print(f\"Classifier training completed in {train_time:.2f} seconds\")\n",
    "\n",
    "# Transform validation data and evaluate\n",
    "print(\"Transforming validation data with Word2Vec...\")\n",
    "X_val_w2v = w2v_vectorizer.transform(X_val)\n",
    "\n",
    "# # Create a class for evaluation that behaves like a pipeline\n",
    "# class ModelWrapper:\n",
    "#     def __init__(self, vectorizer, classifier):\n",
    "#         self.vectorizer = vectorizer\n",
    "#         self.classifier = classifier\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         X_transformed = self.vectorizer.transform(X)\n",
    "#         return self.classifier.predict(X_transformed)\n",
    "\n",
    "# w2v_model = ModelWrapper(w2v_vectorizer, w2v_classifier)\n",
    "# w2v_results, w2v_preds = evaluate_model(w2v_model, X_val, y_val, \"Word2Vec + SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for multiple classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText + SVM\n",
    "fasttext_vectorizer = FastTextVectorizer(vector_size=1000, window=5, min_count=1, workers=n_cores)\n",
    "\n",
    "# Fit the vectorizer to get word embeddings\n",
    "print(\"Fitting FastText vectorizer...\")\n",
    "start_time = time.time()\n",
    "fasttext_vectorizer.fit(X_train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"FastText training completed in {train_time:.2f} seconds\")\n",
    "\n",
    "# Transform training data\n",
    "print(\"Transforming training data with FastText...\")\n",
    "X_train_fasttext = fasttext_vectorizer.transform(X_train)\n",
    "\n",
    "# # Train classifier\n",
    "# fasttext_classifier = MultiOutputClassifier(LinearSVC(\n",
    "#     C=1.0,\n",
    "#     max_iter=10000,\n",
    "#     dual=False,\n",
    "#     class_weight='balanced',\n",
    "#     random_state=42\n",
    "# ))\n",
    "\n",
    "# print(\"Training FastText + SVM classifier...\")\n",
    "# start_time = time.time()\n",
    "# fasttext_classifier.fit(X_train_fasttext, y_train)\n",
    "# train_time = time.time() - start_time\n",
    "# print(f\"Classifier training completed in {train_time:.2f} seconds\")\n",
    "\n",
    "# Transform validation data and evaluate\n",
    "print(\"Transforming validation data with FastText...\")\n",
    "X_val_fasttext = fasttext_vectorizer.transform(X_val)\n",
    "\n",
    "# fasttext_model = ModelWrapper(fasttext_vectorizer, fasttext_classifier)\n",
    "# fasttext_results, fasttext_preds = evaluate_model(fasttext_model, X_val, y_val, \"FastText + SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train GloVe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe + SVM\n",
    "glove_vectorizer = GloveVectorizer(vector_size=1000)\n",
    "\n",
    "# Fit the vectorizer to get word embeddings\n",
    "print(\"Fitting GloVe vectorizer...\")\n",
    "start_time = time.time()\n",
    "glove_vectorizer.fit(X_train)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"GloVe preparation completed in {train_time:.2f} seconds\")\n",
    "\n",
    "# Transform training data\n",
    "print(\"Transforming training data with GloVe...\")\n",
    "X_train_glove = glove_vectorizer.transform(X_train)\n",
    "\n",
    "# # Train classifier\n",
    "# glove_classifier = MultiOutputClassifier(LinearSVC(\n",
    "#     C=1.0,\n",
    "#     max_iter=10000,\n",
    "#     dual=False,\n",
    "#     class_weight='balanced',\n",
    "#     random_state=42\n",
    "# ))\n",
    "\n",
    "# print(\"Training GloVe + SVM classifier...\")\n",
    "# start_time = time.time()\n",
    "# glove_classifier.fit(X_train_glove, y_train)\n",
    "# train_time = time.time() - start_time\n",
    "# print(f\"Classifier training completed in {train_time:.2f} seconds\")\n",
    "\n",
    "# Transform validation data and evaluate\n",
    "print(\"Transforming validation data with GloVe...\")\n",
    "X_val_glove = glove_vectorizer.transform(X_val)\n",
    "\n",
    "# glove_model = ModelWrapper(glove_vectorizer, glove_classifier)\n",
    "# glove_results, glove_preds = evaluate_model(glove_model, X_val, y_val, \"GloVe + SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_count_with_one_classifier(X_train_count, X_val_count, y_train, y_val):\n",
    "    \"\"\"\n",
    "    Evaluate only LogisticRegression on Count Vectorized features to save time.\n",
    "    \n",
    "    Args:\n",
    "        X_train_count: Count vectorized training features\n",
    "        X_val_count: Count vectorized validation features\n",
    "        y_train: Training labels\n",
    "        y_val: Validation labels\n",
    "        \n",
    "    Returns:\n",
    "        List with single classifier result\n",
    "    \"\"\"\n",
    "    # Define one classifier - LogisticRegression is often a good choice for count vectors\n",
    "    classifier = MultiOutputClassifier(LogisticRegression(\n",
    "        C=1.0,\n",
    "        max_iter=1000,\n",
    "        solver='liblinear',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=n_cores\n",
    "    ))\n",
    "    \n",
    "    model_name = \"Count + LogisticRegression\"\n",
    "    print(f\"\\n===== Training {model_name} =====\")\n",
    "    \n",
    "    # Train classifier\n",
    "    start_time = time.time()\n",
    "    classifier.fit(X_train_count, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"Training completed in {train_time:.2f} seconds\")\n",
    "    \n",
    "    # Create a wrapper for evaluation\n",
    "    class SimpleModelWrapper:\n",
    "        def __init__(self, clf):\n",
    "            self.clf = clf\n",
    "        def predict(self, X):\n",
    "            return self.clf.predict(X)\n",
    "    \n",
    "    model = SimpleModelWrapper(classifier)\n",
    "    result, preds = evaluate_model(model, X_val_count, y_val, model_name)\n",
    "    result['train_time'] = train_time\n",
    "    \n",
    "    return [result]  # Return as list to maintain compatibility with existing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_embeddings_with_multiple_classifiers(X_train_embedded, X_val_embedded, y_train, y_val, embedding_name):\n",
    "    \"\"\"\n",
    "    Evaluate multiple classifiers on the provided embedded features.\n",
    "    Using GPU acceleration where available.\n",
    "    \n",
    "    Args:\n",
    "        X_train_embedded: Embedded training features\n",
    "        X_val_embedded: Embedded validation features\n",
    "        y_train: Training labels\n",
    "        y_val: Validation labels\n",
    "        embedding_name: Name of the embedding method\n",
    "        \n",
    "    Returns:\n",
    "        List of results for each classifier\n",
    "    \"\"\"\n",
    "    # Check if GPU is available\n",
    "    gpu_available = False\n",
    "\n",
    "\n",
    "    gpu_available = gpu_available or torch.cuda.is_available()\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU acceleration available with PyTorch: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    \n",
    "    # Define classifiers to evaluate\n",
    "    classifiers = {\n",
    "        'SVM': MultiOutputClassifier(LinearSVC(\n",
    "            C=1.0, \n",
    "            max_iter=10000, \n",
    "            dual=False, \n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        )),\n",
    "        \n",
    "        'LogisticRegression': MultiOutputClassifier(LogisticRegression(\n",
    "            C=1.0,\n",
    "            max_iter=1000,\n",
    "            solver='liblinear',\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=n_cores\n",
    "        )),\n",
    "        \n",
    "        'KNeighborsClassifier': MultiOutputClassifier(KNeighborsClassifier(\n",
    "            n_neighbors=5,\n",
    "            weights='distance',\n",
    "            n_jobs=n_cores\n",
    "        )),\n",
    "    }\n",
    "    \n",
    "    # For XGBoost, configure GPU if available\n",
    "    if gpu_available:\n",
    "        xgb_params = {\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'use_label_encoder': False,\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': n_cores,\n",
    "            'tree_method': 'gpu_hist',  # Use GPU acceleration\n",
    "            'gpu_id': 0\n",
    "        }\n",
    "        print(\"Using GPU acceleration for XGBoost with tree_method='gpu_hist'\")\n",
    "    else:\n",
    "        xgb_params = {\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'use_label_encoder': False,\n",
    "            'eval_metric': 'logloss',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': n_cores\n",
    "        }\n",
    "        print(\"GPU not available for XGBoost, using CPU\")\n",
    "        \n",
    "    classifiers['XGBoost'] = MultiOutputClassifier(xgb.XGBClassifier(**xgb_params))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Evaluate each classifier\n",
    "    for clf_name, classifier in classifiers.items():\n",
    "        model_name = f\"{embedding_name} + {clf_name}\"\n",
    "        print(f\"\\n===== Training {model_name} =====\")\n",
    "        \n",
    "        # Train classifier\n",
    "        start_time = time.time()\n",
    "        classifier.fit(X_train_embedded, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        print(f\"Training completed in {train_time:.2f} seconds\")\n",
    "        \n",
    "        # Create a wrapper for evaluation\n",
    "        class SimpleModelWrapper:\n",
    "            def __init__(self, clf):\n",
    "                self.clf = clf\n",
    "            def predict(self, X):\n",
    "                return self.clf.predict(X)\n",
    "        \n",
    "        model = SimpleModelWrapper(classifier)\n",
    "        result, preds = evaluate_model(model, X_val_embedded, y_val, model_name)\n",
    "        result['train_time'] = train_time\n",
    "        results.append(result)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dictionary to store all results\n",
    "all_classifier_results = []\n",
    "all_results = []  # Initialize all_results here\n",
    "\n",
    "# 0. Evaluate classifiers with TF-IDF vectors\n",
    "print(\"\\n\\n================ EVALUATING TF-IDF WITH MULTIPLE CLASSIFIERS ================\")\n",
    "tfidf_results = evaluate_embeddings_with_multiple_classifiers(\n",
    "    X_train_tfidf, X_val_tfidf, y_train, y_val, \"TF-IDF\"\n",
    ")\n",
    "all_classifier_results.extend(tfidf_results)\n",
    "\n",
    "# 0.1. Evaluate Count Vectorizer with just one classifier to save time\n",
    "print(\"\\n\\n================ EVALUATING COUNT VECTORIZER WITH ONE CLASSIFIER ================\")\n",
    "count_results = evaluate_count_with_one_classifier(\n",
    "    X_train_count, X_val_count, y_train, y_val\n",
    ")\n",
    "all_classifier_results.extend(count_results)\n",
    "\n",
    "# 1. Evaluate classifiers with Word2Vec embeddings\n",
    "print(\"\\n\\n================ EVALUATING WORD2VEC EMBEDDINGS WITH MULTIPLE CLASSIFIERS ================\")\n",
    "w2v_results = evaluate_embeddings_with_multiple_classifiers(\n",
    "    X_train_w2v, X_val_w2v, y_train, y_val, \"Word2Vec\"\n",
    ")\n",
    "all_classifier_results.extend(w2v_results)\n",
    "\n",
    "# 2. Evaluate classifiers with FastText embeddings\n",
    "print(\"\\n\\n================ EVALUATING FASTTEXT EMBEDDINGS WITH MULTIPLE CLASSIFIERS ================\")\n",
    "fasttext_results = evaluate_embeddings_with_multiple_classifiers(\n",
    "    X_train_fasttext, X_val_fasttext, y_train, y_val, \"FastText\"\n",
    ")\n",
    "all_classifier_results.extend(fasttext_results)\n",
    "\n",
    "# 3. Evaluate classifiers with GloVe embeddings\n",
    "print(\"\\n\\n================ EVALUATING GLOVE EMBEDDINGS WITH MULTIPLE CLASSIFIERS ================\")\n",
    "glove_results = evaluate_embeddings_with_multiple_classifiers(\n",
    "    X_train_glove, X_val_glove, y_train, y_val, \"GloVe\"\n",
    ")\n",
    "all_classifier_results.extend(glove_results)\n",
    "\n",
    "# Create a combined dataframe with all results\n",
    "combined_df = pd.DataFrame(all_classifier_results)\n",
    "\n",
    "# Display all results, sorted by macro F1 score\n",
    "print(\"\\n\\n================ COMBINED RESULTS FOR ALL VECTORIZERS AND CLASSIFIERS ================\")\n",
    "print(combined_df[['model_name', 'accuracy', 'macro_f1', 'micro_f1', 'inference_time', 'train_time']].sort_values('macro_f1', ascending=False))\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(x='model_name', y='macro_f1', data=combined_df.sort_values('macro_f1', ascending=False).head(15))\n",
    "plt.title('Top 15 Models by Macro F1 Score')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Macro F1 Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize performance by toxicity category for top 5 models\n",
    "top_models = combined_df.sort_values('macro_f1', ascending=False).head(5)['model_name'].tolist()\n",
    "\n",
    "category_results = []\n",
    "for result in all_classifier_results:\n",
    "    if result['model_name'] in top_models:\n",
    "        model_name = result['model_name']\n",
    "        for col in y_val.columns:\n",
    "            category_results.append({\n",
    "                'model': model_name,\n",
    "                'category': col,\n",
    "                'f1_score': result[f'f1_{col}']\n",
    "            })\n",
    "\n",
    "category_df = pd.DataFrame(category_results)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.barplot(x='category', y='f1_score', hue='model', data=category_df)\n",
    "plt.title('F1 Score by Toxicity Category for Top 5 Models')\n",
    "plt.xlabel('Toxicity Category')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# No need for the old way of storing results - we've already evaluated everything together\n",
    "results_df = pd.DataFrame(all_classifier_results)\n",
    "best_model_name = results_df.sort_values('macro_f1', ascending=False).iloc[0]['model_name']\n",
    "print(f\"\\nThe best performing model overall is: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create organized directory structure\n",
    "os.makedirs('../results/vectorizers_models', exist_ok=True)\n",
    "os.makedirs('../models/vectorizers', exist_ok=True)\n",
    "\n",
    "# Save the results dataframe to CSV and pickle in the vectorizers_models subfolder\n",
    "results_df.to_csv('../results/vectorizers_models/model_comparison_results.csv', index=False)\n",
    "results_df.to_pickle('../results/vectorizers_models/model_comparison_results.pkl')\n",
    "\n",
    "# Collect shape information for all feature representations\n",
    "feature_shapes = {\n",
    "    'TF-IDF': X_train_tfidf.shape,\n",
    "    'Count': X_train_count.shape,\n",
    "    'Word2Vec': X_train_w2v.shape,\n",
    "    'FastText': X_train_fasttext.shape,\n",
    "    'GloVe': X_train_glove.shape\n",
    "}\n",
    "\n",
    "# Save the feature shape information in the vectorizers_models subfolder\n",
    "with open('../results/vectorizers_models/feature_shapes.txt', 'w') as f:\n",
    "    f.write(\"Feature representation shapes:\\n\")\n",
    "    for name, shape in feature_shapes.items():\n",
    "        f.write(f\"{name}: {shape}\\n\")\n",
    "\n",
    "# Save all vectorizers in the vectorizers subfolder\n",
    "vectorizers = {\n",
    "    'tfidf': tfidf_vectorizer,\n",
    "    'count': count_vectorizer,\n",
    "    'word2vec': w2v_vectorizer,\n",
    "    'fasttext': fasttext_vectorizer,\n",
    "    'glove': glove_vectorizer\n",
    "}\n",
    "\n",
    "for name, vectorizer in vectorizers.items():\n",
    "    with open(f'../models/vectorizers/{name}_vectorizer.pkl', 'wb') as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "\n",
    "# Save best classifier information in the vectorizers_models subfolder\n",
    "embedding_types = ['TF-IDF', 'Word2Vec', 'FastText', 'GloVe']\n",
    "embedding_results = {\n",
    "    'TF-IDF': tfidf_results,\n",
    "    'Word2Vec': w2v_results,\n",
    "    'FastText': fasttext_results,\n",
    "    'GloVe': glove_results\n",
    "}\n",
    "\n",
    "best_classifiers = {}\n",
    "for embedding_type in embedding_types:\n",
    "    # Find best classifier for this embedding\n",
    "    best_result = max(embedding_results[embedding_type], key=lambda x: x['macro_f1'])\n",
    "    best_classifier_type = best_result['model_name'].split(' + ')[1]\n",
    "    best_classifiers[embedding_type] = best_classifier_type\n",
    "    print(f\"Best classifier for {embedding_type}: {best_classifier_type}\")\n",
    "\n",
    "# Save best classifier information\n",
    "with open('../results/vectorizers_models/best_classifiers.txt', 'w') as f:\n",
    "    f.write(\"Best classifier for each embedding type:\\n\")\n",
    "    for embedding_type, classifier_type in best_classifiers.items():\n",
    "        f.write(f\"{embedding_type}: {classifier_type}\\n\")\n",
    "\n",
    "# Print feature shape summary\n",
    "print(\"\\nFeature representation shapes:\")\n",
    "for name, shape in feature_shapes.items():\n",
    "    print(f\"{name}: {shape}\")\n",
    "\n",
    "print(\"\\nAll vectorizers and model results saved in the organized folder structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
