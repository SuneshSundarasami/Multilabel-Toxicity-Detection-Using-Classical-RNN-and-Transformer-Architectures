{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RNN Models for Toxic Comment Classification\n",
    "\n",
    "This notebook implements and compares various RNN architectures (LSTM, GRU, Bidirectional RNNs) using different embedding techniques for the toxic comment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# For pre-trained embeddings\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "train_data = pd.read_csv('../Dataset/train_preprocessed.csv')\n",
    "\n",
    "# Check the data\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target labels\n",
    "X = train_data['processed_text']  # Use the preprocessed text\n",
    "y = train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(\"\")  # Replace NaN values with empty strings\n",
    "y = y.fillna(0)   # Replace any missing target values with 0\n",
    "\n",
    "# Split the data into training, validation and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y['toxic']\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.11, random_state=42, stratify=y_temp['toxic']\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing for Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources if not already downloaded\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold=2):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = {}\n",
    "        idx = 2  # Start from 2 as 0 and 1 are reserved for PAD and UNK\n",
    "        \n",
    "        for sentence in tqdm(sentence_list, desc=\"Building vocabulary\"):\n",
    "            for word in nltk.word_tokenize(sentence.lower()):\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 1\n",
    "                else:\n",
    "                    frequencies[word] += 1\n",
    "                \n",
    "                if frequencies[word] == self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1\n",
    "    \n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = nltk.word_tokenize(text.lower())\n",
    "        return [self.stoi.get(token, self.stoi[\"<UNK>\"]) for token in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from training data\n",
    "vocab = Vocabulary(freq_threshold=2)\n",
    "vocab.build_vocabulary(X_train.values)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentDataset(Dataset):\n",
    "    def __init__(self, X, y, vocab):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.X.iloc[index]\n",
    "        labels = torch.FloatTensor(self.y.iloc[index].values)\n",
    "        \n",
    "        # Convert text to numerical form\n",
    "        numericalized_text = self.vocab.numericalize(text)\n",
    "        return torch.tensor(numericalized_text), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences in a batch to the same length\n",
    "def collate_batch(batch):\n",
    "    text_list, label_list = [], []\n",
    "    \n",
    "    for text, label in batch:\n",
    "        text_list.append(text)\n",
    "        label_list.append(label)\n",
    "    \n",
    "    # Pad sequences\n",
    "    text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(label_list)\n",
    "    \n",
    "    return text_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = ToxicCommentDataset(X_train, y_train, vocab)\n",
    "val_dataset = ToxicCommentDataset(X_val, y_val, vocab)\n",
    "test_dataset = ToxicCommentDataset(X_test, y_test, vocab)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout if n_layers > 1 else 0,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        # If bidirectional, multiply by 2 as we'll have hidden states from both directions\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text shape: [batch size, sentence length]\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # embedded shape: [batch size, sentence length, embedding dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        # output shape: [batch size, sentence length, hidden dim * num directions]\n",
    "        # hidden shape: [num layers * num directions, batch size, hidden dim]\n",
    "        \n",
    "        if self.lstm.bidirectional:\n",
    "            # Concatenate the final forward and backward hidden states\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "        # hidden shape: [batch size, hidden dim * num directions]\n",
    "        \n",
    "        return torch.sigmoid(self.fc(self.dropout(hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          hidden_dim, \n",
    "                          num_layers=n_layers, \n",
    "                          bidirectional=bidirectional, \n",
    "                          dropout=dropout if n_layers > 1 else 0,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        \n",
    "        if self.gru.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "            \n",
    "        return torch.sigmoid(self.fc(self.dropout(hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, lstm_output):\n",
    "        # lstm_output shape: [batch_size, seq_len, hidden_dim]\n",
    "        attention_weights = torch.softmax(self.attention(lstm_output), dim=1)\n",
    "        # attention_weights shape: [batch_size, seq_len, 1]\n",
    "        \n",
    "        context_vector = torch.sum(attention_weights * lstm_output, dim=1)\n",
    "        # context_vector shape: [batch_size, hidden_dim]\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=True, \n",
    "                           dropout=dropout if n_layers > 1 else 0,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.attention = AttentionLayer(hidden_dim * 2)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        outputs, _ = self.lstm(embedded)\n",
    "        # outputs shape: [batch_size, seq_len, hidden_dim * 2]\n",
    "        \n",
    "        context, attention_weights = self.attention(outputs)\n",
    "        # context shape: [batch_size, hidden_dim * 2]\n",
    "        \n",
    "        return torch.sigmoid(self.fc(self.dropout(context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    for texts, labels in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        predictions = model(texts)\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        predictions = (predictions > 0.5).float()\n",
    "        accuracy = ((predictions == labels).float().sum()) / (len(labels) * labels.size(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += accuracy.item()\n",
    "    \n",
    "    return epoch_loss / len(data_loader), epoch_accuracy / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            texts = texts.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            predictions = (predictions > 0.5).float()\n",
    "            accuracy = ((predictions == labels).float().sum()) / (len(labels) * labels.size(1))\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "    \n",
    "    return epoch_loss / len(data_loader), epoch_accuracy / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(data_loader, desc=\"Predicting\", leave=False):\n",
    "            texts = texts.to(device)\n",
    "            outputs = model(texts)\n",
    "            \n",
    "            # Convert sigmoid outputs to binary predictions\n",
    "            preds = (outputs > 0.5).float().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            \n",
    "            predictions.append(preds)\n",
    "            actual_labels.append(labels)\n",
    "    \n",
    "    # Concatenate batch predictions\n",
    "    predictions = np.vstack(predictions)\n",
    "    actual_labels = np.vstack(actual_labels)\n",
    "    \n",
    "    return predictions, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_metrics(predictions, actual_labels, label_names):\n",
    "    results = {}\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    results['accuracy'] = accuracy\n",
    "    \n",
    "    # Calculate F1 scores for each class\n",
    "    f1_scores = []\n",
    "    for i, column in enumerate(label_names):\n",
    "        f1 = f1_score(actual_labels[:, i], predictions[:, i])\n",
    "        f1_scores.append(f1)\n",
    "        results[f'f1_{column}'] = f1\n",
    "    \n",
    "    # Calculate macro and micro F1\n",
    "    macro_f1 = np.mean(f1_scores)\n",
    "    micro_f1 = f1_score(actual_labels, predictions, average='micro')\n",
    "    results['macro_f1'] = macro_f1\n",
    "    results['micro_f1'] = micro_f1\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "    print(f\"Micro F1: {micro_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nF1 scores by toxicity type:\")\n",
    "    for i, column in enumerate(label_names):\n",
    "        print(f\"{column}: {f1_scores[i]:.4f}\")\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, n_epochs=10):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        epoch_mins = (end_time - start_time) // 60\n",
    "        epoch_secs = (end_time - start_time) % 60\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), '../models/best_rnn_model.pt')\n",
    "            print(f\"\\t[Saved best model with val_loss: {val_loss:.4f}]\")\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs:.1f}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\tVal. Loss: {val_loss:.4f} | Val. Acc: {val_acc*100:.2f}%')\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "    \n",
    "    return train_losses, train_accs, val_losses, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(train_losses, train_accs, val_losses, val_accs, model_name):\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{model_name} - Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Training Accuracy')\n",
    "    plt.plot(val_accs, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../results/{model_name.lower().replace(\" \", \"_\")}_training_history.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model Hyperparameters\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 6  # Six toxicity categories\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.3\n",
    "PAD_IDX = 0\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM Model\n",
    "lstm_model = LSTMClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    dropout=DROPOUT,\n",
    "    pad_idx=PAD_IDX\n",
    ")\n",
    "\n",
    "# Move model to device (GPU/CPU)\n",
    "lstm_model = lstm_model.to(device)\n",
    "print(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "lstm_train_losses, lstm_train_accs, lstm_val_losses, lstm_val_accs = train_model(\n",
    "    lstm_model, train_loader, val_loader, criterion, optimizer, device, N_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "lstm_model.load_state_dict(torch.load('../models/best_rnn_model.pt'))\n",
    "lstm_model.eval()\n",
    "\n",
    "# Get predictions and evaluate\n",
    "lstm_preds, lstm_actual = predict(lstm_model, test_loader, device)\n",
    "print(\"\\n============ BiLSTM Model Evaluation ============\")\n",
    "lstm_results = model_performance_metrics(lstm_preds, lstm_actual, y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    lstm_train_losses, lstm_train_accs, lstm_val_losses, lstm_val_accs, \"BiLSTM Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and Evaluate GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GRU Model\n",
    "gru_model = GRUClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    dropout=DROPOUT,\n",
    "    pad_idx=PAD_IDX\n",
    ")\n",
    "\n",
    "# Move model to device (GPU/CPU)\n",
    "gru_model = gru_model.to(device)\n",
    "print(gru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(gru_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "gru_train_losses, gru_train_accs, gru_val_losses, gru_val_accs = train_model(\n",
    "    gru_model, train_loader, val_loader, criterion, optimizer, device, N_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained GRU model\n",
    "torch.save(gru_model.state_dict(), '../models/gru_model.pt')\n",
    "\n",
    "# Get predictions and evaluate\n",
    "gru_preds, gru_actual = predict(gru_model, test_loader, device)\n",
    "print(\"\\n============ BiGRU Model Evaluation ============\")\n",
    "gru_results = model_performance_metrics(gru_preds, gru_actual, y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    gru_train_losses, gru_train_accs, gru_val_losses, gru_val_accs, \"BiGRU Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train and Evaluate Attention-based BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Attention-based BiLSTM Model\n",
    "attn_lstm_model = AttentionBiLSTM(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    pad_idx=PAD_IDX\n",
    ")\n",
    "\n",
    "# Move model to device (GPU/CPU)\n",
    "attn_lstm_model = attn_lstm_model.to(device)\n",
    "print(attn_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(attn_lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "attn_train_losses, attn_train_accs, attn_val_losses, attn_val_accs = train_model(\n",
    "    attn_lstm_model, train_loader, val_loader, criterion, optimizer, device, N_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Attention-based BiLSTM model\n",
    "torch.save(attn_lstm_model.state_dict(), '../models/attn_bilstm_model.pt')\n",
    "\n",
    "# Get predictions and evaluate\n",
    "attn_preds, attn_actual = predict(attn_lstm_model, test_loader, device)\n",
    "print(\"\\n============ Attention BiLSTM Model Evaluation ============\")\n",
    "attn_results = model_performance_metrics(attn_preds, attn_actual, y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    attn_train_losses, attn_train_accs, attn_val_losses, attn_val_accs, \"Attention BiLSTM Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare All RNN Models with Previous Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load previous results\n",
    "try:\n",
    "    # Load the previous results dataframe\n",
    "    results_df = pd.read_pickle(\"../results/vectorizer_model_results.pkl\")\n",
    "    print(\"Loaded previous model results.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Previous model results not found. Creating new results dataframe.\")\n",
    "    results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RNN model results to the dataframe\n",
    "rnn_results = [\n",
    "    {**lstm_results, 'model_name': 'BiLSTM'},\n",
    "    {**gru_results, 'model_name': 'BiGRU'},\n",
    "    {**attn_results, 'model_name': 'Attention BiLSTM'}\n",
    "]\n",
    "\n",
    "# Combine with existing results or create new dataframe\n",
    "if not results_df.empty:\n",
    "    rnn_df = pd.DataFrame(rnn_results)\n",
    "    combined_df = pd.concat([results_df, rnn_df], ignore_index=True)\n",
    "else:\n",
    "    combined_df = pd.DataFrame(rnn_results)\n",
    "\n",
    "# Save the combined results\n",
    "combined_df.to_pickle(\"../results/all_model_results.pkl\")\n",
    "print(\"Combined model results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all results, sorted by macro F1 score\n",
    "print(\"\\n\\n================ COMBINED RESULTS FOR ALL MODELS ================\")\n",
    "print(combined_df[['model_name', 'accuracy', 'macro_f1', 'micro_f1']].sort_values('macro_f1', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(x='model_name', y='macro_f1', data=combined_df.sort_values('macro_f1', ascending=False))\n",
    "plt.title('Models by Macro F1 Score')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Macro F1 Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/all_models_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap to compare F1 scores across toxicity categories\n",
    "category_cols = [col for col in combined_df.columns if col.startswith('f1_')]\n",
    "heatmap_df = combined_df[['model_name'] + category_cols].copy()\n",
    "heatmap_df.columns = ['model_name'] + [col.split('_', 1)[1] for col in category_cols]\n",
    "heatmap_df = heatmap_df.set_index('model_name')\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(heatmap_df, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", linewidths=.5)\n",
    "plt.title('F1 Scores by Toxicity Category and Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/toxicity_category_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Deployment for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentPredictor:\n",
    "    def __init__(self, model_path, vocab, device='cpu'):\n",
    "        self.device = torch.device(device)\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        # Determine model type and load\n",
    "        if 'bilstm' in model_path.lower():\n",
    "            self.model = LSTMClassifier(\n",
    "                vocab_size=len(vocab),\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                hidden_dim=HIDDEN_DIM,\n",
    "                output_dim=OUTPUT_DIM,\n",
    "                n_layers=N_LAYERS,\n",
    "                bidirectional=BIDIRECTIONAL,\n",
    "                dropout=0.0,  # No dropout during inference\n",
    "                pad_idx=PAD_IDX\n",
    "            )\n",
    "        elif 'gru' in model_path.lower():\n",
    "            self.model = GRUClassifier(\n",
    "                vocab_size=len(vocab),\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                hidden_dim=HIDDEN_DIM,\n",
    "                output_dim=OUTPUT_DIM,\n",
    "                n_layers=N_LAYERS,\n",
    "                bidirectional=BIDIRECTIONAL,\n",
    "                dropout=0.0,  # No dropout during inference\n",
    "                pad_idx=PAD_IDX\n",
    "            )\n",
    "        elif 'attn' in model_path.lower():\n",
    "            self.model = AttentionBiLSTM(\n",
    "                vocab_size=len(vocab),\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                hidden_dim=HIDDEN_DIM,\n",
    "                output_dim=OUTPUT_DIM,\n",
    "                n_layers=N_LAYERS,\n",
    "                dropout=0.0,  # No dropout during inference\n",
    "                pad_idx=PAD_IDX\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type\")\n",
    "            \n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.label_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "        \n",
    "    def predict(self, text):\n",
    "        # Tokenize and numericalize\n",
    "        numericalized_text = self.vocab.numericalize(text)\n",
    "        tensor = torch.LongTensor(numericalized_text).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(tensor).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        # Create a dictionary with class probabilities\n",
    "        result = {}\n",
    "        for i, label in enumerate(self.label_names):\n",
    "            result[label] = float(prediction[i])\n",
    "            \n",
    "        # Also add binary classifications\n",
    "        binary_preds = {}\n",
    "        for label in self.label_names:\n",
    "            binary_preds[label] = 1 if result[label] > 0.5 else 0\n",
    "            \n",
    "        return {\n",
    "            'probabilities': result,\n",
    "            'predictions': binary_preds,\n",
    "            'is_toxic': any(binary_preds.values())\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vocabulary\n",
    "with open('../models/rnn_vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "# Create a predictor instance\n",
    "predictor = ToxicCommentPredictor('../models/best_rnn_model.pt', vocab, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the predictor with some example comments\n",
    "example_texts = [\n",
    "    \"This is a positive comment. I really appreciate your help.\",\n",
    "    \"You are an idiot and should not be allowed to post here.\",\n",
    "    \"This is neutral content that has no emotional charge.\",\n",
    "    \"I strongly disagree with your opinion, but respect your right to have it.\"\n",
    "]\n",
    "\n",
    "for text in example_texts:\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    result = predictor.predict(text)\n",
    "    print(f\"Is toxic: {result['is_toxic']}\")\n",
    "    print(\"Toxicity probabilities:\")\n",
    "    for label, prob in result['probabilities'].items():\n",
    "        print(f\"  {label}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save All Model Architecture Info and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with model architectures and hyperparameters\n",
    "model_info = {\n",
    "    'BiLSTM': {\n",
    "        'type': 'LSTM',\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'n_layers': N_LAYERS,\n",
    "        'bidirectional': BIDIRECTIONAL,\n",
    "        'dropout': DROPOUT,\n",
    "        'vocab_size': vocab_size,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': N_EPOCHS\n",
    "    },\n",
    "    'BiGRU': {\n",
    "        'type': 'GRU',\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'n_layers': N_LAYERS,\n",
    "        'bidirectional': BIDIRECTIONAL,\n",
    "        'dropout': DROPOUT,\n",
    "        'vocab_size': vocab_size,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': N_EPOCHS\n",
    "    },\n",
    "    'Attention BiLSTM': {\n",
    "        'type': 'Attention BiLSTM',\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'n_layers': N_LAYERS,\n",
    "        'bidirectional': True,  # Always bidirectional for this model\n",
    "        'dropout': DROPOUT,\n",
    "        'vocab_size': vocab_size,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': N_EPOCHS\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the model information\n",
    "with open('../models/rnn_model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(model_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dictionary for easy comparison\n",
    "summary = {\n",
    "    'model_comparison': combined_df[['model_name', 'accuracy', 'macro_f1', 'micro_f1']].sort_values('macro_f1', ascending=False).to_dict('records'),\n",
    "    'best_model': combined_df.loc[combined_df['macro_f1'].idxmax()]['model_name'],\n",
    "    'model_info': model_info\n",
    "}\n",
    "\n",
    "# Save the summary\n",
    "with open('../results/rnn_models_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(f\"Best model: {summary['best_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Implemented three RNN architectures for toxic comment classification:\n",
    "   - Bidirectional LSTM\n",
    "   - Bidirectional GRU\n",
    "   - Attention-based Bidirectional LSTM\n",
    "\n",
    "2. Trained and evaluated each model on the toxic comment dataset\n",
    "\n",
    "3. Compared the RNN models with previously trained traditional ML models\n",
    "\n",
    "4. Created a simple inference system for making predictions on new text\n",
    "\n",
    "5. Saved the models, their architectures, and evaluation results for future use\n",
    "\n",
    "The RNN models, especially those with attention mechanisms, can capture sequential information in the text that traditional bag-of-words models like TF-IDF might miss, potentially improving the detection of complex toxic patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}