{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RNN Models for Toxic Comment Classification\n",
    "\n",
    "This notebook implements and compares various RNN architectures (LSTM, GRU, Bidirectional RNNs) using different embedding techniques for the toxic comment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d10f13a6bf0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score,precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# For pre-trained embeddings\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (159571, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>original_length</th>\n",
       "      <th>processed_length</th>\n",
       "      <th>length_reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made my username hardcore me...</td>\n",
       "      <td>264</td>\n",
       "      <td>202</td>\n",
       "      <td>23.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww ! he match background colour im seemingly...</td>\n",
       "      <td>112</td>\n",
       "      <td>86</td>\n",
       "      <td>23.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , im really not trying edit war . guy ...</td>\n",
       "      <td>233</td>\n",
       "      <td>165</td>\n",
       "      <td>29.184549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i cant make real suggestion improvement i wond...</td>\n",
       "      <td>622</td>\n",
       "      <td>406</td>\n",
       "      <td>34.726688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you , sir , my hero . chance you remember page...</td>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "      <td>19.402985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                      processed_text  original_length  \\\n",
       "0  explanation edits made my username hardcore me...              264   \n",
       "1  daww ! he match background colour im seemingly...              112   \n",
       "2  hey man , im really not trying edit war . guy ...              233   \n",
       "3  i cant make real suggestion improvement i wond...              622   \n",
       "4  you , sir , my hero . chance you remember page...               67   \n",
       "\n",
       "   processed_length  length_reduction  \n",
       "0               202         23.484848  \n",
       "1                86         23.214286  \n",
       "2               165         29.184549  \n",
       "3               406         34.726688  \n",
       "4                54         19.402985  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "train_data = pd.read_csv('../Dataset/train_preprocessed.csv')\n",
    "\n",
    "# Check the data\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 127815\n",
      "Validation set size: 15798\n",
      "Test set size: 15958\n"
     ]
    }
   ],
   "source": [
    "# Define the features and target labels\n",
    "X = train_data['processed_text']  # Use the preprocessed text\n",
    "y = train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(\"\")  # Replace NaN values with empty strings\n",
    "y = y.fillna(0)   # Replace any missing target values with 0\n",
    "\n",
    "# Split the data into training, validation and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y['toxic']\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.11, random_state=42, stratify=y_temp['toxic']\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution BEFORE oversampling:\n",
      "toxic: 0.0958 (12251 samples)\n",
      "severe_toxic: 0.0099 (1262 samples)\n",
      "obscene: 0.0530 (6769 samples)\n",
      "threat: 0.0029 (374 samples)\n",
      "insult: 0.0494 (6308 samples)\n",
      "identity_hate: 0.0086 (1100 samples)\n",
      "\n",
      "Class distribution AFTER oversampling:\n",
      "toxic: 0.1163 (15225 samples)\n",
      "severe_toxic: 0.0225 (2948 samples)\n",
      "obscene: 0.0706 (9246 samples)\n",
      "threat: 0.0098 (1288 samples)\n",
      "insult: 0.0671 (8791 samples)\n",
      "identity_hate: 0.0199 (2604 samples)\n"
     ]
    }
   ],
   "source": [
    "def oversample_minority_classes(X_train, y_train):\n",
    "    \"\"\"Oversample minority classes to improve balance\"\"\"\n",
    "    \n",
    "    # Original data\n",
    "    original_X = X_train.copy()\n",
    "    original_y = y_train.copy()\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    # Identify examples of each rare class and augment\n",
    "    for label in ['threat', 'identity_hate', 'severe_toxic']:\n",
    "        # Find positive examples\n",
    "        pos_indices = y_train[y_train[label] == 1].index\n",
    "        pos_X = X_train.loc[pos_indices]  # Use .loc instead of .iloc\n",
    "        pos_y = y_train.loc[pos_indices]  # Use .loc instead of .iloc\n",
    "        \n",
    "        # Oversample 3x for threat (rarest), 2x for others\n",
    "        multiplier = 3 if label == 'threat' else 2\n",
    "        \n",
    "        for _ in range(multiplier - 1):\n",
    "            augmented_X.append(pos_X)\n",
    "            augmented_y.append(pos_y)\n",
    "    \n",
    "    # Combine with original data\n",
    "    augmented_X = pd.concat([original_X] + augmented_X)\n",
    "    augmented_y = pd.concat([original_y] + augmented_y)\n",
    "    \n",
    "    return augmented_X.reset_index(drop=True), augmented_y.reset_index(drop=True)\n",
    "\n",
    "print(\"Class distribution BEFORE oversampling:\")\n",
    "for col in y_train.columns:\n",
    "    print(f\"{col}: {y_train[col].mean():.4f} ({y_train[col].sum()} samples)\")\n",
    "\n",
    "# Apply augmentation\n",
    "X_train_aug, y_train_aug = oversample_minority_classes(X_train, y_train)\n",
    "\n",
    "# Check distribution after oversampling\n",
    "print(\"\\nClass distribution AFTER oversampling:\")\n",
    "for col in y_train_aug.columns:\n",
    "    print(f\"{col}: {y_train_aug[col].mean():.4f} ({y_train_aug[col].sum()} samples)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing for Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resources if not already downloaded\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold=2):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "        self.freq_threshold = freq_threshold\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = {}\n",
    "        idx = 2  # Start from 2 as 0 and 1 are reserved for PAD and UNK\n",
    "        \n",
    "        for sentence in tqdm(sentence_list, desc=\"Building vocabulary\"):\n",
    "            for word in nltk.word_tokenize(sentence.lower()):\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 1\n",
    "                else:\n",
    "                    frequencies[word] += 1\n",
    "                \n",
    "                if frequencies[word] == self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1\n",
    "    \n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = nltk.word_tokenize(text.lower())\n",
    "        return [self.stoi.get(token, self.stoi[\"<UNK>\"]) for token in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de62141e8ffc4229b7d775f59549c5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building vocabulary:   0%|          | 0/127815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 72577\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary from training data\n",
    "vocab = Vocabulary(freq_threshold=2)\n",
    "vocab.build_vocabulary(X_train.values)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentDataset(Dataset):\n",
    "    def __init__(self, X, y, vocab):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.X.iloc[index]\n",
    "        labels = torch.FloatTensor(self.y.iloc[index].values)\n",
    "        \n",
    "        # Convert text to numerical form\n",
    "        numericalized_text = self.vocab.numericalize(text)\n",
    "        return torch.LongTensor(numericalized_text), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences in a batch to the same length\n",
    "def collate_batch(batch):\n",
    "    text_list, label_list = [], []\n",
    "    \n",
    "    for text, label in batch:\n",
    "        text_list.append(text)\n",
    "        label_list.append(label)\n",
    "    \n",
    "    # Pad sequences\n",
    "    text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(label_list)\n",
    "    \n",
    "    return text_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = ToxicCommentDataset(X_train, y_train, vocab)\n",
    "train_augmented_dataset = ToxicCommentDataset(X_train_aug, y_train_aug, vocab)\n",
    "val_dataset = ToxicCommentDataset(X_val, y_val, vocab)\n",
    "test_dataset = ToxicCommentDataset(X_test, y_test, vocab)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch,\n",
    "    num_workers=16\n",
    ")\n",
    "train_augmented_loader = DataLoader(\n",
    "    train_augmented_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch,\n",
    "    num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout if n_layers > 1 else 0,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        # If bidirectional, multiply by 2 as we'll have hidden states from both directions\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text shape: [batch size, sentence length]\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        # embedded shape: [batch size, sentence length, embedding dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        # output shape: [batch size, sentence length, hidden dim * num directions]\n",
    "        # hidden shape: [num layers * num directions, batch size, hidden dim]\n",
    "        \n",
    "        if self.lstm.bidirectional:\n",
    "            # Concatenate the final forward and backward hidden states\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "        # hidden shape: [batch size, hidden dim * num directions]\n",
    "        \n",
    "        return torch.sigmoid(self.fc(self.dropout(hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          hidden_dim, \n",
    "                          num_layers=n_layers, \n",
    "                          bidirectional=bidirectional, \n",
    "                          dropout=dropout if n_layers > 1 else 0,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        \n",
    "        if self.gru.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "            \n",
    "        return torch.sigmoid(self.fc(self.dropout(hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, lstm_output):\n",
    "        # lstm_output shape: [batch_size, seq_len, hidden_dim]\n",
    "        attention_weights = torch.softmax(self.attention(lstm_output), dim=1)\n",
    "        # attention_weights shape: [batch_size, seq_len, 1]\n",
    "        \n",
    "        context_vector = torch.sum(attention_weights * lstm_output, dim=1)\n",
    "        # context_vector shape: [batch_size, hidden_dim]\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=True, \n",
    "                           dropout=dropout if n_layers > 1 else 0,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        self.attention = AttentionLayer(hidden_dim * 2)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        outputs, _ = self.lstm(embedded)\n",
    "        # outputs shape: [batch_size, seq_len, hidden_dim * 2]\n",
    "        \n",
    "        context, attention_weights = self.attention(outputs)\n",
    "        # context shape: [batch_size, hidden_dim * 2]\n",
    "        \n",
    "        return torch.sigmoid(self.fc(self.dropout(context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate class weights\n",
    "class_weights = {}\n",
    "for col in y_train.columns:\n",
    "    weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.array([0, 1]),\n",
    "        y=y_train[col]\n",
    "    )\n",
    "    class_weights[col] = torch.FloatTensor(weights).to(device)\n",
    "\n",
    "# Define weighted loss function\n",
    "def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "    column_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = {}\n",
    "        for col in column_names:\n",
    "            weights[col] = torch.ones([2]).to(output.device)\n",
    "    \n",
    "    loss = 0\n",
    "    for i, col in enumerate(column_names):\n",
    "        if col in weights:\n",
    "            class_weight = weights[col]\n",
    "        else:\n",
    "            class_weight = torch.ones([2]).to(output.device)\n",
    "            \n",
    "        loss_per_sample = F.binary_cross_entropy(\n",
    "            output[:, i],\n",
    "            target[:, i],\n",
    "            reduction='none'\n",
    "        )\n",
    "        weight_per_sample = class_weight[1] * target[:, i] + class_weight[0] * (1 - target[:, i])\n",
    "        loss += (loss_per_sample * weight_per_sample).mean()\n",
    "    \n",
    "    return loss / target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        \"\"\"\n",
    "        alpha: List of class weights, should match the number of classes\n",
    "        gamma: Focusing parameter (higher = more focus on hard examples)\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha  # Class weight for each class\n",
    "        self.gamma = gamma  # Focusing parameter\n",
    "        self.epsilon = 1e-6  # For numerical stability\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # Inputs should already be sigmoided (0-1)\n",
    "        inputs = torch.clamp(inputs, self.epsilon, 1 - self.epsilon)\n",
    "        \n",
    "        # Calculate BCE for each class\n",
    "        bce_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        \n",
    "        # Calculate focal weights\n",
    "        pt = torch.exp(-bce_loss)  # pt = probability of the correct class\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "        \n",
    "        # Apply class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(inputs.device)\n",
    "            # Get weights for each sample based on its true class\n",
    "            batch_alpha = torch.ones_like(inputs).to(inputs.device)\n",
    "            for i in range(len(alpha)):\n",
    "                batch_alpha[:, i] = alpha[i]\n",
    "            focal_weight = batch_alpha * focal_weight\n",
    "        \n",
    "        # Calculate weighted loss\n",
    "        focal_loss = focal_weight * bce_loss\n",
    "        \n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, criterion, device, accumulation_steps=2):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, (texts, labels) in enumerate(tqdm(data_loader, desc=\"Training\", leave=False)):\n",
    "        texts = texts.long().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        predictions = model(texts)\n",
    "        loss = criterion(predictions, labels) / accumulation_steps\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(data_loader):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = (predictions > 0.5).float()\n",
    "            accuracy = ((predictions == labels).float().sum()) / (len(labels) * labels.size(1))\n",
    "        \n",
    "        epoch_loss += loss.item() * accumulation_steps\n",
    "        epoch_accuracy += accuracy.item()\n",
    "    \n",
    "    return epoch_loss / len(data_loader), epoch_accuracy / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            texts = texts.long().to(device)  # Convert to long before sending to device\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            predictions = (predictions > 0.5).float()\n",
    "            accuracy = ((predictions == labels).float().sum()) / (len(labels) * labels.size(1))\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "    \n",
    "    return epoch_loss / len(data_loader), epoch_accuracy / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(data_loader, desc=\"Predicting\", leave=False):\n",
    "            texts = texts.long().to(device)  # Convert to long before sending to device\n",
    "            outputs = model(texts)\n",
    "            \n",
    "            # Convert sigmoid outputs to binary predictions\n",
    "            preds = (outputs > 0.5).float().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            \n",
    "            predictions.append(preds)\n",
    "            actual_labels.append(labels)\n",
    "    \n",
    "    # Concatenate batch predictions\n",
    "    predictions = np.vstack(predictions)\n",
    "    actual_labels = np.vstack(actual_labels)\n",
    "    \n",
    "    return predictions, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_thresholds(model, val_loader, device):\n",
    "    \"\"\"Find optimal thresholds using validation data only\"\"\"\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Collect validation predictions\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(val_loader, desc=\"Finding thresholds\", leave=False):\n",
    "            texts = texts.long().to(device)\n",
    "            outputs = model(texts).cpu().numpy()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    # Find optimal threshold for each class using VALIDATION data\n",
    "    thresholds = []\n",
    "    for i in range(all_outputs.shape[1]):\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in np.arange(0.1, 0.9, 0.05):\n",
    "            preds = (all_outputs[:, i] > threshold).astype(float)\n",
    "            f1 = f1_score(all_labels[:, i], preds)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        thresholds.append(best_threshold)\n",
    "    \n",
    "    print(f\"Optimal thresholds found on validation: {thresholds}\")\n",
    "    return thresholds\n",
    "\n",
    "def predict_with_thresholds(model, data_loader, thresholds, device):\n",
    "    \"\"\"Apply pre-determined thresholds to make predictions\"\"\"\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Collect test predictions\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(data_loader, desc=\"Predicting\", leave=False):\n",
    "            texts = texts.long().to(device)\n",
    "            outputs = model(texts).cpu().numpy()\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    # Apply the pre-determined thresholds\n",
    "    predictions = np.zeros_like(all_outputs)\n",
    "    for i in range(all_outputs.shape[1]):\n",
    "        predictions[:, i] = (all_outputs[:, i] > thresholds[i]).astype(float)\n",
    "    \n",
    "    return predictions, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_evaluation_table(predictions, actual_labels, label_names):\n",
    "    \"\"\"Generate a detailed evaluation table using pandas DataFrame\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, column in enumerate(label_names):\n",
    "        # Calculate metrics\n",
    "        precision = precision_score(actual_labels[:, i], predictions[:, i])\n",
    "        recall = recall_score(actual_labels[:, i], predictions[:, i])\n",
    "        f1 = f1_score(actual_labels[:, i], predictions[:, i])\n",
    "        \n",
    "        # Calculate confusion matrix elements\n",
    "        tp = ((predictions[:, i] == 1) & (actual_labels[:, i] == 1)).sum()\n",
    "        fp = ((predictions[:, i] == 1) & (actual_labels[:, i] == 0)).sum()\n",
    "        fn = ((predictions[:, i] == 0) & (actual_labels[:, i] == 1)).sum()\n",
    "        tn = ((predictions[:, i] == 0) & (actual_labels[:, i] == 0)).sum()\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        prevalence = (tp + fn) / (tp + tn + fp + fn)\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Category': column,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "            'Accuracy': accuracy,\n",
    "            'Prevalence': prevalence,\n",
    "            'Specificity': specificity,\n",
    "            'TP': tp,\n",
    "            'FP': fp,\n",
    "            'FN': fn,\n",
    "            'TN': tn\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and format\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Format metrics as percentages\n",
    "    for col in ['Precision', 'Recall', 'F1', 'Accuracy', 'Prevalence', 'Specificity']:\n",
    "        df[col] = df[col].map('{:.2%}'.format)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_metrics(predictions, actual_labels, label_names):\n",
    "    results = {}\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    results['accuracy'] = accuracy\n",
    "    \n",
    "    # Calculate F1 scores for each class\n",
    "    f1_scores = []\n",
    "    for i, column in enumerate(label_names):\n",
    "        f1 = f1_score(actual_labels[:, i], predictions[:, i])\n",
    "        f1_scores.append(f1)\n",
    "        results[f'f1_{column}'] = f1\n",
    "    \n",
    "    # Calculate macro and micro F1\n",
    "    macro_f1 = np.mean(f1_scores)\n",
    "    micro_f1 = f1_score(actual_labels, predictions, average='micro')\n",
    "    results['macro_f1'] = macro_f1\n",
    "    results['micro_f1'] = micro_f1\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "    print(f\"Micro F1: {micro_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nF1 scores by toxicity type:\")\n",
    "    for i, column in enumerate(label_names):\n",
    "        print(f\"{column}: {f1_scores[i]:.4f}\")\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, n_epochs=10):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        epoch_mins = (end_time - start_time) // 60\n",
    "        epoch_secs = (end_time - start_time) % 60\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), '../models/best_rnn_model.pt')\n",
    "            print(f\"\\t[Saved best model with val_loss: {val_loss:.4f}]\")\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs:.1f}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\tVal. Loss: {val_loss:.4f} | Val. Acc: {val_acc*100:.2f}%')\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "    \n",
    "    return train_losses, train_accs, val_losses, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(train_losses, train_accs, val_losses, val_accs, model_name):\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{model_name} - Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Training Accuracy')\n",
    "    plt.plot(val_accs, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../results/{model_name.lower().replace(\" \", \"_\")}_training_history.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model Hyperparameters\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 6  # Six toxicity categories\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.3\n",
    "PAD_IDX = 0\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (embedding): Embedding(72577, 100, padding_idx=0)\n",
      "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize LSTM Model\n",
    "lstm_model = LSTMClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    dropout=DROPOUT,\n",
    "    pad_idx=PAD_IDX\n",
    ")\n",
    "\n",
    "# Move model to device (GPU/CPU)\n",
    "lstm_model = lstm_model.to(device)\n",
    "print(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [0.09584947 0.00987365 0.05295936 0.0029261  0.04935258 0.00860619]\n",
      "Class weights: [ 0.25350136  1.35017928  0.42619535 10.37937809  0.45209466  7.21076867]\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Create weights based on class distribution\n",
    "class_dist = np.array([y_train[col].mean() for col in y_train.columns])\n",
    "print(f\"Class distribution: {class_dist}\")\n",
    "class_weights = 1 / (class_dist + 0.01)  # Add small epsilon to avoid division by zero\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)  # Normalize weights\n",
    "\n",
    "# Give extra emphasis to threat and identity_hate classes\n",
    "class_weights[3] *= 5  # Quintuple weight for threat\n",
    "class_weights[5] *= 5  # Quintuple weight for identity_hate\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Create the focal loss\n",
    "criterion = FocalLoss(alpha=torch.FloatTensor(class_weights), gamma=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab62f28798446218cf51c7ae26563d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088110afd1d94d2789cd61e3b2d4c99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Saved best model with val_loss: 0.0031]\n",
      "Epoch: 01 | Time: 5.0m 55.2s\n",
      "\tTrain Loss: 0.0034 | Train Acc: 97.64%\n",
      "\tVal. Loss: 0.0031 | Val. Acc: 98.13%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model\n",
    "lstm_train_losses, lstm_train_accs, lstm_val_losses, lstm_val_accs = train_model(\n",
    "    lstm_model, train_augmented_loader, val_loader, criterion, optimizer, device, N_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check class distribution\n",
    "# print(\"Class distribution in training set:\")\n",
    "# for col in y_train.columns:\n",
    "#     print(f\"{col}: {y_train[col].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c023cccf7a44ef98817301ee3a9ec9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding thresholds:   0%|          | 0/494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal thresholds found on validation: [0.5000000000000001, 0.5000000000000001, 0.45000000000000007, 0.5500000000000002, 0.45000000000000007, 0.5000000000000001]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf9bf1b084b4f079adfe2e58285169c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ BiLSTM Model Evaluation ============\n",
      "Accuracy: 0.9193\n",
      "Macro F1: 0.6047\n",
      "Micro F1: 0.7336\n",
      "\n",
      "F1 scores by toxicity type:\n",
      "toxic: 0.7761\n",
      "severe_toxic: 0.5017\n",
      "obscene: 0.7725\n",
      "threat: 0.3333\n",
      "insult: 0.7158\n",
      "identity_hate: 0.5288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Prevalence</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toxic</td>\n",
       "      <td>87.52%</td>\n",
       "      <td>69.72%</td>\n",
       "      <td>77.61%</td>\n",
       "      <td>96.15%</td>\n",
       "      <td>9.58%</td>\n",
       "      <td>98.95%</td>\n",
       "      <td>1066</td>\n",
       "      <td>152</td>\n",
       "      <td>463</td>\n",
       "      <td>14277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obscene</td>\n",
       "      <td>69.46%</td>\n",
       "      <td>87.01%</td>\n",
       "      <td>77.25%</td>\n",
       "      <td>97.28%</td>\n",
       "      <td>5.31%</td>\n",
       "      <td>97.86%</td>\n",
       "      <td>737</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>14787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insult</td>\n",
       "      <td>64.68%</td>\n",
       "      <td>80.12%</td>\n",
       "      <td>71.58%</td>\n",
       "      <td>96.81%</td>\n",
       "      <td>5.01%</td>\n",
       "      <td>97.69%</td>\n",
       "      <td>641</td>\n",
       "      <td>350</td>\n",
       "      <td>159</td>\n",
       "      <td>14808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>identity_hate</td>\n",
       "      <td>54.93%</td>\n",
       "      <td>50.98%</td>\n",
       "      <td>52.88%</td>\n",
       "      <td>99.13%</td>\n",
       "      <td>0.96%</td>\n",
       "      <td>99.60%</td>\n",
       "      <td>78</td>\n",
       "      <td>64</td>\n",
       "      <td>75</td>\n",
       "      <td>15741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>severe_toxic</td>\n",
       "      <td>49.35%</td>\n",
       "      <td>51.01%</td>\n",
       "      <td>50.17%</td>\n",
       "      <td>99.05%</td>\n",
       "      <td>0.93%</td>\n",
       "      <td>99.51%</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>15731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threat</td>\n",
       "      <td>54.55%</td>\n",
       "      <td>24.00%</td>\n",
       "      <td>33.33%</td>\n",
       "      <td>99.70%</td>\n",
       "      <td>0.31%</td>\n",
       "      <td>99.94%</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>15898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category Precision  Recall      F1 Accuracy Prevalence Specificity  \\\n",
       "0          toxic    87.52%  69.72%  77.61%   96.15%      9.58%      98.95%   \n",
       "2        obscene    69.46%  87.01%  77.25%   97.28%      5.31%      97.86%   \n",
       "4         insult    64.68%  80.12%  71.58%   96.81%      5.01%      97.69%   \n",
       "5  identity_hate    54.93%  50.98%  52.88%   99.13%      0.96%      99.60%   \n",
       "1   severe_toxic    49.35%  51.01%  50.17%   99.05%      0.93%      99.51%   \n",
       "3         threat    54.55%  24.00%  33.33%   99.70%      0.31%      99.94%   \n",
       "\n",
       "     TP   FP   FN     TN  \n",
       "0  1066  152  463  14277  \n",
       "2   737  324  110  14787  \n",
       "4   641  350  159  14808  \n",
       "5    78   64   75  15741  \n",
       "1    76   78   73  15731  \n",
       "3    12   10   38  15898  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the best model\n",
    "lstm_model.load_state_dict(torch.load('../models/best_rnn_model.pt'))\n",
    "lstm_model.eval()\n",
    "\n",
    "# Find optimal thresholds on validation data\n",
    "optimal_thresholds = find_optimal_thresholds(lstm_model, val_loader, device)\n",
    "\n",
    "# Apply these thresholds on the test set\n",
    "lstm_preds, lstm_actual = predict_with_thresholds(lstm_model, test_loader, optimal_thresholds, device)\n",
    "\n",
    "# Evaluate using the test set with validation-determined thresholds\n",
    "print(\"\\n============ BiLSTM Model Evaluation ============\")\n",
    "lstm_results = model_performance_metrics(lstm_preds, lstm_actual, y.columns)\n",
    "\n",
    "# Detailed evaluation\n",
    "df_evaluation = detailed_evaluation_table(lstm_preds, lstm_actual, y.columns)\n",
    "\n",
    "\n",
    "# To sort by F1 score:\n",
    "df_sorted = df_evaluation.sort_values('F1', ascending=False)\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add this code before plotting and saving your training history\n",
    "import os\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "plot_training_history(\n",
    "    lstm_train_losses, lstm_train_accs, lstm_val_losses, lstm_val_accs, \"BiLSTM Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and Evaluate GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GRU Model\n",
    "gru_model = GRUClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    bidirectional=BIDIRECTIONAL,\n",
    "    dropout=DROPOUT,\n",
    "    pad_idx=PAD_IDX\n",
    ")\n",
    "\n",
    "# Move model to device (GPU/CPU)\n",
    "gru_model = gru_model.to(device)\n",
    "print(gru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(gru_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "gru_train_losses, gru_train_accs, gru_val_losses, gru_val_accs = train_model(\n",
    "    gru_model, train_loader, val_loader, criterion, optimizer, device, N_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained GRU model\n",
    "torch.save(gru_model.state_dict(), '../models/gru_model.pt')\n",
    "\n",
    "# Get predictions and evaluate\n",
    "gru_preds, gru_actual = predict(gru_model, test_loader, device)\n",
    "print(\"\\n============ BiGRU Model Evaluation ============\")\n",
    "gru_results = model_performance_metrics(gru_preds, gru_actual, y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    gru_train_losses, gru_train_accs, gru_val_losses, gru_val_accs, \"BiGRU Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train and Evaluate Attention-based BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Attention-based BiLSTM Model\n",
    "attn_lstm_model = AttentionBiLSTM(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    pad_idx=PAD_IDX\n",
    ")\n",
    "\n",
    "# Move model to device (GPU/CPU)\n",
    "attn_lstm_model = attn_lstm_model.to(device)\n",
    "print(attn_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(attn_lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "attn_train_losses, attn_train_accs, attn_val_losses, attn_val_accs = train_model(\n",
    "    attn_lstm_model, train_loader, val_loader, criterion, optimizer, device, N_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Attention-based BiLSTM model\n",
    "torch.save(attn_lstm_model.state_dict(), '../models/attn_bilstm_model.pt')\n",
    "\n",
    "# Get predictions and evaluate\n",
    "attn_preds, attn_actual = predict(attn_lstm_model, test_loader, device)\n",
    "print(\"\\n============ Attention BiLSTM Model Evaluation ============\")\n",
    "attn_results = model_performance_metrics(attn_preds, attn_actual, y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    attn_train_losses, attn_train_accs, attn_val_losses, attn_val_accs, \"Attention BiLSTM Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare All RNN Models with Previous Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load previous results\n",
    "try:\n",
    "    # Load the previous results dataframe\n",
    "    results_df = pd.read_pickle(\"../results/vectorizer_model_results.pkl\")\n",
    "    print(\"Loaded previous model results.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Previous model results not found. Creating new results dataframe.\")\n",
    "    results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RNN model results to the dataframe\n",
    "rnn_results = [\n",
    "    {**lstm_results, 'model_name': 'BiLSTM'},\n",
    "    {**gru_results, 'model_name': 'BiGRU'},\n",
    "    {**attn_results, 'model_name': 'Attention BiLSTM'}\n",
    "]\n",
    "\n",
    "# Combine with existing results or create new dataframe\n",
    "if not results_df.empty:\n",
    "    rnn_df = pd.DataFrame(rnn_results)\n",
    "    combined_df = pd.concat([results_df, rnn_df], ignore_index=True)\n",
    "else:\n",
    "    combined_df = pd.DataFrame(rnn_results)\n",
    "\n",
    "# Save the combined results\n",
    "combined_df.to_pickle(\"../results/all_model_results.pkl\")\n",
    "print(\"Combined model results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all results, sorted by macro F1 score\n",
    "print(\"\\n\\n================ COMBINED RESULTS FOR ALL MODELS ================\")\n",
    "print(combined_df[['model_name', 'accuracy', 'macro_f1', 'micro_f1']].sort_values('macro_f1', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.barplot(x='model_name', y='macro_f1', data=combined_df.sort_values('macro_f1', ascending=False))\n",
    "plt.title('Models by Macro F1 Score')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Macro F1 Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/all_models_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap to compare F1 scores across toxicity categories\n",
    "category_cols = [col for col in combined_df.columns if col.startswith('f1_')]\n",
    "heatmap_df = combined_df[['model_name'] + category_cols].copy()\n",
    "heatmap_df.columns = ['model_name'] + [col.split('_', 1)[1] for col in category_cols]\n",
    "heatmap_df = heatmap_df.set_index('model_name')\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(heatmap_df, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", linewidths=.5)\n",
    "plt.title('F1 Scores by Toxicity Category and Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/toxicity_category_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Deployment for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentPredictor:\n",
    "    def __init__(self, model_path, vocab, device='cpu'):\n",
    "        self.device = torch.device(device)\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        # Determine model type and load\n",
    "        if 'bilstm' in model_path.lower():\n",
    "            self.model = LSTMClassifier(\n",
    "                vocab_size=len(vocab),\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                hidden_dim=HIDDEN_DIM,\n",
    "                output_dim=OUTPUT_DIM,\n",
    "                n_layers=N_LAYERS,\n",
    "                bidirectional=BIDIRECTIONAL,\n",
    "                dropout=0.0,  # No dropout during inference\n",
    "                pad_idx=PAD_IDX\n",
    "            )\n",
    "        elif 'gru' in model_path.lower():\n",
    "            self.model = GRUClassifier(\n",
    "                vocab_size=len(vocab),\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                hidden_dim=HIDDEN_DIM,\n",
    "                output_dim=OUTPUT_DIM,\n",
    "                n_layers=N_LAYERS,\n",
    "                bidirectional=BIDIRECTIONAL,\n",
    "                dropout=0.0,  # No dropout during inference\n",
    "                pad_idx=PAD_IDX\n",
    "            )\n",
    "        elif 'attn' in model_path.lower():\n",
    "            self.model = AttentionBiLSTM(\n",
    "                vocab_size=len(vocab),\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                hidden_dim=HIDDEN_DIM,\n",
    "                output_dim=OUTPUT_DIM,\n",
    "                n_layers=N_LAYERS,\n",
    "                dropout=0.0,  # No dropout during inference\n",
    "                pad_idx=PAD_IDX\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type\")\n",
    "            \n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.label_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "        \n",
    "    def predict(self, text):\n",
    "        # Tokenize and numericalize\n",
    "        numericalized_text = self.vocab.numericalize(text)\n",
    "        tensor = torch.LongTensor(numericalized_text).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(tensor).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        # Create a dictionary with class probabilities\n",
    "        result = {}\n",
    "        for i, label in enumerate(self.label_names):\n",
    "            result[label] = float(prediction[i])\n",
    "            \n",
    "        # Also add binary classifications\n",
    "        binary_preds = {}\n",
    "        for label in self.label_names:\n",
    "            binary_preds[label] = 1 if result[label] > 0.5 else 0\n",
    "            \n",
    "        return {\n",
    "            'probabilities': result,\n",
    "            'predictions': binary_preds,\n",
    "            'is_toxic': any(binary_preds.values())\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vocabulary\n",
    "with open('../models/rnn_vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "# Create a predictor instance\n",
    "predictor = ToxicCommentPredictor('../models/best_rnn_model.pt', vocab, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the predictor with some example comments\n",
    "example_texts = [\n",
    "    \"This is a positive comment. I really appreciate your help.\",\n",
    "    \"You are an idiot and should not be allowed to post here.\",\n",
    "    \"This is neutral content that has no emotional charge.\",\n",
    "    \"I strongly disagree with your opinion, but respect your right to have it.\"\n",
    "]\n",
    "\n",
    "for text in example_texts:\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    result = predictor.predict(text)\n",
    "    print(f\"Is toxic: {result['is_toxic']}\")\n",
    "    print(\"Toxicity probabilities:\")\n",
    "    for label, prob in result['probabilities'].items():\n",
    "        print(f\"  {label}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save All Model Architecture Info and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with model architectures and hyperparameters\n",
    "model_info = {\n",
    "    'BiLSTM': {\n",
    "        'type': 'LSTM',\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'n_layers': N_LAYERS,\n",
    "        'bidirectional': BIDIRECTIONAL,\n",
    "        'dropout': DROPOUT,\n",
    "        'vocab_size': vocab_size,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': N_EPOCHS\n",
    "    },\n",
    "    'BiGRU': {\n",
    "        'type': 'GRU',\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'n_layers': N_LAYERS,\n",
    "        'bidirectional': BIDIRECTIONAL,\n",
    "        'dropout': DROPOUT,\n",
    "        'vocab_size': vocab_size,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': N_EPOCHS\n",
    "    },\n",
    "    'Attention BiLSTM': {\n",
    "        'type': 'Attention BiLSTM',\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'n_layers': N_LAYERS,\n",
    "        'bidirectional': True,  # Always bidirectional for this model\n",
    "        'dropout': DROPOUT,\n",
    "        'vocab_size': vocab_size,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'epochs': N_EPOCHS\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the model information\n",
    "with open('../models/rnn_model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(model_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dictionary for easy comparison\n",
    "summary = {\n",
    "    'model_comparison': combined_df[['model_name', 'accuracy', 'macro_f1', 'micro_f1']].sort_values('macro_f1', ascending=False).to_dict('records'),\n",
    "    'best_model': combined_df.loc[combined_df['macro_f1'].idxmax()]['model_name'],\n",
    "    'model_info': model_info\n",
    "}\n",
    "\n",
    "# Save the summary\n",
    "with open('../results/rnn_models_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(f\"Best model: {summary['best_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Implemented three RNN architectures for toxic comment classification:\n",
    "   - Bidirectional LSTM\n",
    "   - Bidirectional GRU\n",
    "   - Attention-based Bidirectional LSTM\n",
    "\n",
    "2. Trained and evaluated each model on the toxic comment dataset\n",
    "\n",
    "3. Compared the RNN models with previously trained traditional ML models\n",
    "\n",
    "4. Created a simple inference system for making predictions on new text\n",
    "\n",
    "5. Saved the models, their architectures, and evaluation results for future use\n",
    "\n",
    "The RNN models, especially those with attention mechanisms, can capture sequential information in the text that traditional bag-of-words models like TF-IDF might miss, potentially improving the detection of complex toxic patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
