{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c3a3d9",
   "metadata": {},
   "source": [
    "# Fine-tuning FLAN-T5-base with Classification Head for Multi-Label Toxic Comment Classification\n",
    "\n",
    "This notebook outlines the process for fine-tuning the `google/flan-t5-base` model from Hugging Face on a multi-label toxic comment classification task using a classification head approach.\n",
    "The fine-tuning is performed on Kaggle using a Nvidia P100 GPU with LoRA (Low-Rank Adaptation) for parameter-efficient training.\n",
    "\n",
    "## Key Features:\n",
    "- **Model**: FLAN-T5-base with custom classification head\n",
    "- **Task**: Multi-label toxic comment classification\n",
    "- **Approach**: Classification head (not text-to-text generation)\n",
    "- **Training Data**: 20% subsample of original dataset for faster training\n",
    "- **Optimization**: LoRA adapters for memory efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db92a95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:30:19.471577Z",
     "iopub.status.busy": "2025-06-22T12:30:19.471335Z",
     "iopub.status.idle": "2025-06-22T12:32:47.176557Z",
     "shell.execute_reply": "2025-06-22T12:32:47.175588Z",
     "shell.execute_reply.started": "2025-06-22T12:30:19.471543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib==3.8.2\n",
      "  Downloading matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes==0.43.0\n",
      "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting transformers==4.44.2\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m248.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==0.33.0\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting peft==0.12.0\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m250.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.4.0\n",
      "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.8.2)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.8.2)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.8.2)\n",
      "  Downloading fonttools-4.58.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m218.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib==3.8.2)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib==3.8.2)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.8.2)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.8.2)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib==3.8.2)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting filelock (from transformers==4.44.2)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.44.2)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.44.2)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.44.2)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m235.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from transformers==4.44.2)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.44.2)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting psutil (from accelerate==0.33.0)\n",
      "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.4.0)\n",
      "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch==2.4.0)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.4.0)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch==2.4.0)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch==2.4.0)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch==2.4.0)\n",
      "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m273.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib==3.8.2)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.0)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.44.2)\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.44.2)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.44.2)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.44.2)\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.0)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m202.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m229.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m260.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m339.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m333.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m274.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m271.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m242.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m249.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m361.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m177.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m177.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m177.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m190.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m143.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m158.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m137.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m319.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m254.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m329.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m117.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.8/514.8 kB\u001b[0m \u001b[31m325.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m314.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m353.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m177.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m279.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m293.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m329.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m307.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m228.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m247.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m334.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m250.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m307.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m317.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m317.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m282.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.7/157.7 kB\u001b[0m \u001b[31m346.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m320.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m303.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m163.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m338.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, six, safetensors, regex, pyyaml, pyparsing, psutil, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, joblib, idna, hf-xet, fsspec, fonttools, filelock, cycler, charset_normalizer, certifi, triton, scipy, requests, python-dateutil, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, contourpy, scikit-learn, pandas, nvidia-cusolver-cu12, matplotlib, huggingface-hub, torch, tokenizers, seaborn, transformers, bitsandbytes, accelerate, peft\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2025.2\n",
      "    Uninstalling pytz-2025.2:\n",
      "      Successfully uninstalled pytz-2025.2\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2025.2\n",
      "    Uninstalling tzdata-2025.2:\n",
      "      Successfully uninstalled tzdata-2025.2\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.14.0\n",
      "    Uninstalling typing_extensions-4.14.0:\n",
      "      Successfully uninstalled typing_extensions-4.14.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.6.0\n",
      "    Uninstalling threadpoolctl-3.6.0:\n",
      "      Successfully uninstalled threadpoolctl-3.6.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.5.3\n",
      "    Uninstalling safetensors-0.5.3:\n",
      "      Successfully uninstalled safetensors-0.5.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.3\n",
      "    Uninstalling pyparsing-3.2.3:\n",
      "      Successfully uninstalled pyparsing-3.2.3\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 7.0.0\n",
      "    Uninstalling psutil-7.0.0:\n",
      "      Successfully uninstalled psutil-7.0.0\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.2.1\n",
      "    Uninstalling pillow-11.2.1:\n",
      "      Successfully uninstalled pillow-11.2.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.86\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.86:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.86\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.5\n",
      "    Uninstalling networkx-3.5:\n",
      "      Successfully uninstalled networkx-3.5\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.4.8\n",
      "    Uninstalling kiwisolver-1.4.8:\n",
      "      Successfully uninstalled kiwisolver-1.4.8\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.5.1\n",
      "    Uninstalling joblib-1.5.1:\n",
      "      Successfully uninstalled joblib-1.5.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: hf-xet\n",
      "    Found existing installation: hf-xet 1.1.5\n",
      "    Uninstalling hf-xet-1.1.5:\n",
      "      Successfully uninstalled hf-xet-1.1.5\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.58.4\n",
      "    Uninstalling fonttools-4.58.4:\n",
      "      Successfully uninstalled fonttools-4.58.4\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.18.0\n",
      "    Uninstalling filelock-3.18.0:\n",
      "      Successfully uninstalled filelock-3.18.0\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.12.1\n",
      "    Uninstalling cycler-0.12.1:\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "  Attempting uninstall: charset_normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.2\n",
      "    Uninstalling charset-normalizer-3.4.2:\n",
      "      Successfully uninstalled charset-normalizer-3.4.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.6.15\n",
      "    Uninstalling certifi-2025.6.15:\n",
      "      Successfully uninstalled certifi-2025.6.15\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.6\n",
      "    Uninstalling Jinja2-3.1.6:\n",
      "      Successfully uninstalled Jinja2-3.1.6\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.3.2\n",
      "    Uninstalling contourpy-1.3.2:\n",
      "      Successfully uninstalled contourpy-1.3.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.7.0\n",
      "    Uninstalling scikit-learn-1.7.0:\n",
      "      Successfully uninstalled scikit-learn-1.7.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.3.0\n",
      "    Uninstalling pandas-2.3.0:\n",
      "      Successfully uninstalled pandas-2.3.0\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.8.2\n",
      "    Uninstalling matplotlib-3.8.2:\n",
      "      Successfully uninstalled matplotlib-3.8.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.33.0\n",
      "    Uninstalling huggingface-hub-0.33.0:\n",
      "      Successfully uninstalled huggingface-hub-0.33.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.13.2\n",
      "    Uninstalling seaborn-0.13.2:\n",
      "      Successfully uninstalled seaborn-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.2\n",
      "    Uninstalling transformers-4.44.2:\n",
      "      Successfully uninstalled transformers-4.44.2\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.43.0\n",
      "    Uninstalling bitsandbytes-0.43.0:\n",
      "      Successfully uninstalled bitsandbytes-0.43.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.33.0\n",
      "    Uninstalling accelerate-0.33.0:\n",
      "      Successfully uninstalled accelerate-0.33.0\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.12.0\n",
      "    Uninstalling peft-0.12.0:\n",
      "      Successfully uninstalled peft-0.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
      "category-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.0 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
      "langchain-core 0.3.50 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\n",
      "google-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 accelerate-0.33.0 bitsandbytes-0.43.0 certifi-2025.6.15 charset_normalizer-3.4.2 contourpy-1.3.2 cycler-0.12.1 filelock-3.18.0 fonttools-4.58.4 fsspec-2025.5.1 hf-xet-1.1.5 huggingface-hub-0.33.0 idna-3.10 jinja2-3.1.6 joblib-1.5.1 kiwisolver-1.4.8 matplotlib-3.8.2 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 packaging-25.0 pandas-2.3.0 peft-0.12.0 pillow-11.2.1 psutil-7.0.0 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.15.3 seaborn-0.13.2 six-1.17.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.19.1 torch-2.4.0 tqdm-4.67.1 transformers-4.44.2 triton-3.0.0 typing-extensions-4.14.0 tzdata-2025.2 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"numpy<2.0\" \"matplotlib==3.8.2\" scikit-learn pandas \"bitsandbytes==0.43.0\" \"transformers==4.44.2\" \"accelerate==0.33.0\" \"peft==0.12.0\" seaborn tqdm \"torch==2.4.0\" --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4046a953-82e5-4a13-9d1d-df37c5d53099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:33:02.740868Z",
     "iopub.status.busy": "2025-06-22T12:33:02.740221Z",
     "iopub.status.idle": "2025-06-22T12:33:21.788439Z",
     "shell.execute_reply": "2025-06-22T12:33:21.787645Z",
     "shell.execute_reply.started": "2025-06-22T12:33:02.740835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 12:33:08.897118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750595589.112639      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750595589.170497      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0+cu121\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "GPU: Tesla P100-PCIE-16GB\n",
      "GPU Memory: 15.9 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Force single GPU usage\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    T5EncoderModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baec7f2-5f0f-40e4-8883-bb4b63d0b764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:33:24.548320Z",
     "iopub.status.busy": "2025-06-22T12:33:24.547674Z",
     "iopub.status.idle": "2025-06-22T12:33:29.972803Z",
     "shell.execute_reply": "2025-06-22T12:33:29.972195Z",
     "shell.execute_reply.started": "2025-06-22T12:33:24.548296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4-bit quantization with NF4\n",
      "Quantization enabled: True\n",
      "LoRA enabled: True\n",
      "Training data subsampling: True (20.0% of data)\n",
      "Expected memory usage: Lower with quantization + LoRA\n",
      "Loading T5 tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcf97f5473a4c7a9ae0def0b40d19a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b614dfe204e41a3b523472df9aabf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb5fd3ca46048c089426d4d157df668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddb044f0b00468aaa783d9fd747ac25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing pad token: <pad>\n",
      "Tokenizer loaded. Vocab size: 32100\n"
     ]
    }
   ],
   "source": [
    "#  Configuration\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "# Model configuration for training\n",
    "EFFECTIVE_MAX_LENGTH = 512  \n",
    "MAX_LENGTH = EFFECTIVE_MAX_LENGTH\n",
    "BATCH_SIZE = 8  # Reduced batch size due to larger model\n",
    "LEARNING_RATE = 1e-4  \n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 500\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Training data subsampling configuration\n",
    "TRAINING_SUBSAMPLE_FRACTION = 0.2  # Use 20% of training data after split\n",
    "USE_TRAINING_SUBSAMPLING = True\n",
    "\n",
    "# Quantization configuration\n",
    "USE_QUANTIZATION = True  # Enable quantization to force single device usage\n",
    "if USE_QUANTIZATION and torch.cuda.is_available():\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "    print(\"Using 4-bit quantization with NF4\")\n",
    "else:\n",
    "    quantization_config = None\n",
    "    print(\"No quantization - using full precision\")\n",
    "\n",
    "# LoRA configuration\n",
    "USE_LORA = True  # Use LoRA for parameter-efficient fine-tuning\n",
    "LORA_R = 16  \n",
    "LORA_ALPHA = 32  # Alpha parameter\n",
    "LORA_DROPOUT = 0.1\n",
    "# Target modules for T5 encoder\n",
    "LORA_TARGET_MODULES = [\"q\", \"v\", \"k\", \"o\", \"wi\", \"wo\"]  # T5 attention and feed-forward layers\n",
    "\n",
    "# Update paths\n",
    "TRAIN_DATA_PATH = \"/kaggle/input/jigsaw-toxic-comment-classification-preprocessed/jigsaw-toxic-comment-classification-preprocessed/train_preprocessed.csv\" \n",
    "\n",
    "OUTPUT_DIR = \"/kaggle/working/\"\n",
    "TEXT_COLUMN = \"comment_text\" \n",
    "LABEL_COLUMNS = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "NUM_LABELS = len(LABEL_COLUMNS)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Device configuration will be handled by quantization and device_map\n",
    "print(f\"Quantization enabled: {USE_QUANTIZATION}\")\n",
    "print(f\"LoRA enabled: {USE_LORA}\")\n",
    "print(f\"Training data subsampling: {USE_TRAINING_SUBSAMPLING} ({TRAINING_SUBSAMPLE_FRACTION*100}% of data)\")\n",
    "print(f\"Expected memory usage: Lower with quantization + LoRA\")\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"Loading T5 tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(f\"Set pad_token to eos_token: {tokenizer.pad_token}\")\n",
    "else:\n",
    "    print(f\"Using existing pad token: {tokenizer.pad_token}\")\n",
    "\n",
    "print(f\"Tokenizer loaded. Vocab size: {len(tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905839f-451b-48d7-9d1e-7eb1ed16c258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:39:25.262034Z",
     "iopub.status.busy": "2025-06-22T12:39:25.261461Z",
     "iopub.status.idle": "2025-06-22T12:39:25.275916Z",
     "shell.execute_reply": "2025-06-22T12:39:25.275122Z",
     "shell.execute_reply.started": "2025-06-22T12:39:25.262011Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForClassification class defined successfully\n"
     ]
    }
   ],
   "source": [
    "# Custom T5 Model for Classification\n",
    "class T5ForClassification(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.1):\n",
    "        super(T5ForClassification, self).__init__()\n",
    "        # Load T5 encoder only\n",
    "        self.encoder = T5EncoderModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Get hidden size from the encoder config\n",
    "        self.hidden_size = self.encoder.config.d_model\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.hidden_size // 2, num_labels)\n",
    "        )\n",
    "        \n",
    "        # Store configuration for compatibility\n",
    "        self.config = self.encoder.config\n",
    "        self.config.num_labels = num_labels\n",
    "        self.config.problem_type = \"multi_label_classification\"\n",
    "        \n",
    "        # Initialize classifier weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize the weights of the classification head\"\"\"\n",
    "        for module in self.classifier.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use the last hidden state\n",
    "        sequence_output = encoder_outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        # Pool the sequence (mean pooling over sequence length, excluding padding)\n",
    "        if attention_mask is not None:\n",
    "            # Apply attention mask and compute mean\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).expand(sequence_output.size()).float()\n",
    "            sum_embeddings = torch.sum(sequence_output * mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "            pooled_output = sum_embeddings / sum_mask\n",
    "        else:\n",
    "            # Simple mean if no attention mask\n",
    "            pooled_output = torch.mean(sequence_output, dim=1)\n",
    "        \n",
    "        # Get logits from classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Calculate loss if labels are provided\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels.float())\n",
    "        \n",
    "        # Return in the format expected by Transformers\n",
    "        from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=None,\n",
    "            attentions=None\n",
    "        )\n",
    "    \n",
    "    def resize_token_embeddings(self, new_num_tokens):\n",
    "        \"\"\"Resize token embeddings to match tokenizer\"\"\"\n",
    "        return self.encoder.resize_token_embeddings(new_num_tokens)\n",
    "    \n",
    "    def gradient_checkpointing_enable(self, gradient_checkpointing_kwargs=None):\n",
    "        \"\"\"Enable gradient checkpointing for the encoder\"\"\"\n",
    "        if hasattr(self.encoder, 'gradient_checkpointing_enable'):\n",
    "            self.encoder.gradient_checkpointing_enable(gradient_checkpointing_kwargs)\n",
    "    \n",
    "    def gradient_checkpointing_disable(self):\n",
    "        \"\"\"Disable gradient checkpointing for the encoder\"\"\"\n",
    "        if hasattr(self.encoder, 'gradient_checkpointing_disable'):\n",
    "            self.encoder.gradient_checkpointing_disable()\n",
    "    \n",
    "    def save_pretrained(self, save_directory):\n",
    "        \"\"\"Save the model\"\"\"\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "        \n",
    "        # Save the encoder\n",
    "        self.encoder.save_pretrained(save_directory)\n",
    "        \n",
    "        # Save the classifier head\n",
    "        classifier_path = os.path.join(save_directory, \"classifier_head.pt\")\n",
    "        torch.save(self.classifier.state_dict(), classifier_path)\n",
    "        \n",
    "        # Save model config\n",
    "        config_path = os.path.join(save_directory, \"model_config.json\")\n",
    "        import json\n",
    "        with open(config_path, \"w\") as f:\n",
    "            json.dump({\n",
    "                \"model_type\": \"T5ForClassification\",\n",
    "                \"base_model\": \"google/flan-t5-base\",\n",
    "                \"num_labels\": self.config.num_labels,\n",
    "                \"hidden_size\": self.hidden_size\n",
    "            }, f, indent=2)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_path, num_labels):\n",
    "        \"\"\"Load the model from a saved directory\"\"\"\n",
    "        # Load the encoder\n",
    "        encoder = T5EncoderModel.from_pretrained(model_path)\n",
    "        \n",
    "        # Create the model\n",
    "        model = cls.__new__(cls)\n",
    "        super(T5ForClassification, model).__init__()\n",
    "        model.encoder = encoder\n",
    "        model.hidden_size = encoder.config.d_model\n",
    "        model.config = encoder.config\n",
    "        model.config.num_labels = num_labels\n",
    "        \n",
    "        # Recreate classifier\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(model.hidden_size, model.hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(model.hidden_size // 2, num_labels)\n",
    "        )\n",
    "        \n",
    "        # Load classifier weights\n",
    "        classifier_path = os.path.join(model_path, \"classifier_head.pt\")\n",
    "        if os.path.exists(classifier_path):\n",
    "            model.classifier.load_state_dict(torch.load(classifier_path))\n",
    "        \n",
    "        return model\n",
    "\n",
    "print(\"T5ForClassification class defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5f44ab-4585-46b5-9b73-9480a2d1d86d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:33:48.167405Z",
     "iopub.status.busy": "2025-06-22T12:33:48.166770Z",
     "iopub.status.idle": "2025-06-22T12:33:48.175465Z",
     "shell.execute_reply": "2025-06-22T12:33:48.174746Z",
     "shell.execute_reply.started": "2025-06-22T12:33:48.167381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def oversample_minority_classes(X_train, y_train):\n",
    "    \"\"\"Oversample minority classes to improve balance\"\"\"\n",
    "    original_X = X_train.copy()\n",
    "    original_y = y_train.copy()\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    # Print original distribution\n",
    "    print(\"Class distribution BEFORE oversampling:\")\n",
    "    for col in y_train.columns:\n",
    "        positive_count = y_train[col].sum()\n",
    "        total_count = len(y_train)\n",
    "        print(f\"{col}: {positive_count}/{total_count} ({positive_count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    multipliers = {\n",
    "        'threat': 40,\n",
    "        'identity_hate': 20,\n",
    "        'severe_toxic': 15\n",
    "    }\n",
    "    \n",
    "    for label, multiplier in multipliers.items():\n",
    "        # Add error handling for missing labels\n",
    "        if label not in y_train.columns:\n",
    "            print(f\"Warning: Label '{label}' not found in data, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        pos_indices = y_train[y_train[label] == 1].index\n",
    "        \n",
    "        # Check if there are any positive samples\n",
    "        if len(pos_indices) == 0:\n",
    "            print(f\"Warning: No positive samples found for '{label}', skipping...\")\n",
    "            continue\n",
    "            \n",
    "        pos_X = X_train.loc[pos_indices]\n",
    "        pos_y = y_train.loc[pos_indices]\n",
    "        \n",
    "        print(f\"Oversampling {label}: {len(pos_indices)} samples × {multiplier-1} = {len(pos_indices)*(multiplier-1)} additional samples\")\n",
    "        \n",
    "        for _ in range(multiplier - 1):\n",
    "            augmented_X.append(pos_X)\n",
    "            augmented_y.append(pos_y)\n",
    "    \n",
    "    # Handle case where no augmentation occurred\n",
    "    if augmented_X:\n",
    "        augmented_X = pd.concat([original_X] + augmented_X, ignore_index=True)\n",
    "        augmented_y = pd.concat([original_y] + augmented_y, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No oversampling performed\")\n",
    "        augmented_X = original_X\n",
    "        augmented_y = original_y\n",
    "    \n",
    "    print(f\"\\nDataset size: {len(original_X)} → {len(augmented_X)} (+{len(augmented_X)-len(original_X)} samples)\")\n",
    "    \n",
    "    print(\"Class distribution AFTER oversampling:\")\n",
    "    for col in augmented_y.columns:\n",
    "        positive_count = augmented_y[col].sum()\n",
    "        total_count = len(augmented_y)\n",
    "        print(f\"{col}: {positive_count}/{total_count} ({positive_count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    return augmented_X.reset_index(drop=True), augmented_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd7cfe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:33:53.179501Z",
     "iopub.status.busy": "2025-06-22T12:33:53.178918Z",
     "iopub.status.idle": "2025-06-22T12:34:02.186132Z",
     "shell.execute_reply": "2025-06-22T12:34:02.185345Z",
     "shell.execute_reply.started": "2025-06-22T12:33:53.179480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed training data...\n",
      " Training data loaded successfully: (159571, 9)\n",
      "\n",
      "Original training data columns:\n",
      "['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'processed_text']\n",
      "\n",
      " All required columns found in training data\n",
      "\n",
      "First few rows of original training data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
      "0             0        0       0       0              0   \n",
      "1             0        0       0       0              0   \n",
      "2             0        0       0       0              0   \n",
      "3             0        0       0       0              0   \n",
      "4             0        0       0       0              0   \n",
      "\n",
      "                                      processed_text  \n",
      "0  explanation edits made username hardcore metal...  \n",
      "1  daww match background colour im seemingly stuc...  \n",
      "2  hey man im really not trying edit war guy cons...  \n",
      "3  cant make real suggestion improvement wondered...  \n",
      "4                sir hero chance remember page thats  \n",
      "\n",
      "Label distribution in original training data:\n",
      "toxic            15294\n",
      "severe_toxic      1595\n",
      "obscene           8449\n",
      "threat             478\n",
      "insult            7877\n",
      "identity_hate     1405\n",
      "dtype: int64\n",
      "\n",
      "Percentage of positive labels:\n",
      "toxic            9.584448\n",
      "severe_toxic     0.999555\n",
      "obscene          5.294822\n",
      "threat           0.299553\n",
      "insult           4.936361\n",
      "identity_hate    0.880486\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SPLITTING DATA INTO TRAIN/VALIDATION/TEST\n",
      "==================================================\n",
      "Data split completed:\n",
      "- Training set: 111,763 samples (70.0%)\n",
      "- Validation set: 23,872 samples (15.0%)\n",
      "- Test set: 23,936 samples (15.0%)\n",
      "- Total: 159,571 samples\n",
      "\n",
      " Split datasets saved:\n",
      "- Training data: /kaggle/working//train_split.csv\n",
      "- Validation data: /kaggle/working//val_split.csv\n",
      "- Test data (with labels): /kaggle/working//test_split_with_labels.csv\n",
      "- Test data (without labels): /kaggle/working//test_split_no_labels.csv\n",
      "\n",
      " LABEL DISTRIBUTION COMPARISON:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Label counts and percentages by split:\n",
      "     Split   Size  toxic_count  toxic_pct  severe_toxic_count  severe_toxic_pct  obscene_count  obscene_pct  threat_count  threat_pct  insult_count  insult_pct  identity_hate_count  identity_hate_pct\n",
      "  Original 159571        15294   9.584448                1595          0.999555           8449     5.294822           478    0.299553          7877    4.936361                 1405           0.880486\n",
      "     Train 111763        10712   9.584567                1144          1.023595           5939     5.313923           336    0.300636          5541    4.957813                  993           0.888487\n",
      "Validation  23872         2288   9.584450                 222          0.929960           1231     5.156669            66    0.276475          1150    4.817359                  197           0.825235\n",
      "      Test  23936         2294   9.583890                 229          0.956718           1279     5.343416            76    0.317513          1186    4.954880                  215           0.898229\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Updating paths for training process...\n",
      "Updated paths:\n",
      "- TRAIN_DATA_PATH: /kaggle/working//train_split.csv\n",
      "- VAL_DATA_PATH: /kaggle/working//val_split.csv\n",
      "- TEST_DATA_PATH: /kaggle/working//test_split_no_labels.csv\n",
      "- TEST_WITH_LABELS_PATH: /kaggle/working//test_split_with_labels.csv\n",
      "\n",
      " Data splitting completed successfully!\n",
      "Ready to proceed with training using the split data.\n"
     ]
    }
   ],
   "source": [
    "# Load and Split Dataset into Train/Validation/Test\n",
    "print(\"Loading preprocessed training data...\")\n",
    "try:\n",
    "    full_train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "    print(f\" Training data loaded successfully: {full_train_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" Training data not found at: {TRAIN_DATA_PATH}\")\n",
    "    print(\"Please update paths in the configuration section\")\n",
    "    raise\n",
    "\n",
    "# Display basic information about the data\n",
    "print(\"\\nOriginal training data columns:\")\n",
    "print(full_train_df.columns.tolist())\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = [TEXT_COLUMN] + LABEL_COLUMNS\n",
    "missing_columns = [col for col in required_columns if col not in full_train_df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"\\n Missing required columns in training data: {missing_columns}\")\n",
    "    print(f\"Available columns: {full_train_df.columns.tolist()}\")\n",
    "    print(\"\\nPlease ensure your preprocessed data has the following columns:\")\n",
    "    print(f\"- {TEXT_COLUMN} (the processed text)\")\n",
    "    print(f\"- {', '.join(LABEL_COLUMNS)} (label columns)\")\n",
    "    raise ValueError(\"Missing required columns\")\n",
    "else:\n",
    "    print(\"\\n All required columns found in training data\")\n",
    "\n",
    "print(\"\\nFirst few rows of original training data:\")\n",
    "print(full_train_df.head())\n",
    "\n",
    "# Check label distribution in original data\n",
    "print(\"\\nLabel distribution in original training data:\")\n",
    "label_stats = full_train_df[LABEL_COLUMNS].sum()\n",
    "print(label_stats)\n",
    "\n",
    "# Calculate percentage of positive labels\n",
    "print(\"\\nPercentage of positive labels:\")\n",
    "label_percentages = (full_train_df[LABEL_COLUMNS].sum() / len(full_train_df)) * 100\n",
    "print(label_percentages)\n",
    "\n",
    "# Visualize original label distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "label_stats.plot(kind='bar')\n",
    "plt.title('Label Counts in Original Training Data')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "label_percentages.plot(kind='bar')\n",
    "plt.title('Label Percentages in Original Training Data')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split the data into train/validation/test (70%/15%/15%)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SPLITTING DATA INTO TRAIN/VALIDATION/TEST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# First split: separate test set (15% of total data)\n",
    "train_val_df, test_df = train_test_split(\n",
    "    full_train_df, \n",
    "    test_size=0.15, \n",
    "    random_state=42,\n",
    "    stratify=full_train_df[LABEL_COLUMNS[0]]  # Stratify on primary toxic label\n",
    ")\n",
    "\n",
    "# Second split: separate validation from remaining data (15% of total = ~17.6% of remaining)\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=0.176,  # This gives us ~15% of original data for validation\n",
    "    random_state=42,\n",
    "    stratify=train_val_df[LABEL_COLUMNS[0]]  # Stratify on primary toxic label\n",
    ")\n",
    "\n",
    "print(f\"Data split completed:\")\n",
    "print(f\"- Training set: {len(train_df):,} samples ({len(train_df)/len(full_train_df)*100:.1f}%)\")\n",
    "print(f\"- Validation set: {len(val_df):,} samples ({len(val_df)/len(full_train_df)*100:.1f}%)\")\n",
    "print(f\"- Test set: {len(test_df):,} samples ({len(test_df)/len(full_train_df)*100:.1f}%)\")\n",
    "print(f\"- Total: {len(train_df) + len(val_df) + len(test_df):,} samples\")\n",
    "\n",
    "# Create test set without labels for prediction\n",
    "test_df_no_labels = test_df[[TEXT_COLUMN]].copy()\n",
    "if 'id' not in test_df.columns:\n",
    "    # Create an ID column if it doesn't exist\n",
    "    test_df_no_labels['id'] = range(len(test_df_no_labels))\n",
    "    test_df['id'] = range(len(test_df))\n",
    "else:\n",
    "    test_df_no_labels['id'] = test_df['id'].copy()\n",
    "\n",
    "# Save the split datasets\n",
    "train_split_path = f\"{OUTPUT_DIR}/train_split.csv\"\n",
    "val_split_path = f\"{OUTPUT_DIR}/val_split.csv\"\n",
    "test_split_with_labels_path = f\"{OUTPUT_DIR}/test_split_with_labels.csv\"\n",
    "test_split_no_labels_path = f\"{OUTPUT_DIR}/test_split_no_labels.csv\"\n",
    "\n",
    "train_df.to_csv(train_split_path, index=False)\n",
    "val_df.to_csv(val_split_path, index=False)\n",
    "test_df.to_csv(test_split_with_labels_path, index=False)\n",
    "test_df_no_labels.to_csv(test_split_no_labels_path, index=False)\n",
    "\n",
    "print(f\"\\n Split datasets saved:\")\n",
    "print(f\"- Training data: {train_split_path}\")\n",
    "print(f\"- Validation data: {val_split_path}\")\n",
    "print(f\"- Test data (with labels): {test_split_with_labels_path}\")\n",
    "print(f\"- Test data (without labels): {test_split_no_labels_path}\")\n",
    "\n",
    "# Compare label distributions across splits\n",
    "print(f\"\\n LABEL DISTRIBUTION COMPARISON:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "splits_info = {\n",
    "    'Original': full_train_df,\n",
    "    'Train': train_df,\n",
    "    'Validation': val_df,\n",
    "    'Test': test_df\n",
    "}\n",
    "\n",
    "comparison_data = []\n",
    "for split_name, split_df in splits_info.items():\n",
    "    row = {'Split': split_name, 'Size': len(split_df)}\n",
    "    for label in LABEL_COLUMNS:\n",
    "        count = split_df[label].sum()\n",
    "        percentage = (count / len(split_df)) * 100\n",
    "        row[f'{label}_count'] = count\n",
    "        row[f'{label}_pct'] = percentage\n",
    "    comparison_data.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nLabel counts and percentages by split:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize distribution comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Label Distribution Comparison Across Splits', fontsize=16)\n",
    "\n",
    "# Plot 1: Sample counts\n",
    "splits = ['Train', 'Validation', 'Test']\n",
    "sizes = [len(train_df), len(val_df), len(test_df)]\n",
    "axes[0, 0].bar(splits, sizes, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[0, 0].set_title('Sample Counts by Split')\n",
    "axes[0, 0].set_ylabel('Number of Samples')\n",
    "for i, v in enumerate(sizes):\n",
    "    axes[0, 0].text(i, v + max(sizes)*0.01, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 2: Label percentages for each split\n",
    "label_pcts = {\n",
    "    'Train': [(train_df[label].sum() / len(train_df)) * 100 for label in LABEL_COLUMNS],\n",
    "    'Validation': [(val_df[label].sum() / len(val_df)) * 100 for label in LABEL_COLUMNS],\n",
    "    'Test': [(test_df[label].sum() / len(test_df)) * 100 for label in LABEL_COLUMNS]\n",
    "}\n",
    "\n",
    "x = np.arange(len(LABEL_COLUMNS))\n",
    "width = 0.25\n",
    "\n",
    "axes[0, 1].bar(x - width, label_pcts['Train'], width, label='Train', color='skyblue')\n",
    "axes[0, 1].bar(x, label_pcts['Validation'], width, label='Validation', color='lightgreen')\n",
    "axes[0, 1].bar(x + width, label_pcts['Test'], width, label='Test', color='lightcoral')\n",
    "\n",
    "axes[0, 1].set_title('Label Percentages by Split')\n",
    "axes[0, 1].set_xlabel('Labels')\n",
    "axes[0, 1].set_ylabel('Percentage (%)')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels([label.replace('_', '\\n') for label in LABEL_COLUMNS], rotation=45)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: Training set label distribution (bar chart)\n",
    "train_label_counts = [train_df[label].sum() for label in LABEL_COLUMNS]\n",
    "axes[1, 0].bar(range(len(LABEL_COLUMNS)), train_label_counts, color='skyblue')\n",
    "axes[1, 0].set_title('Training Set Label Counts')\n",
    "axes[1, 0].set_xlabel('Labels')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_xticks(range(len(LABEL_COLUMNS)))\n",
    "axes[1, 0].set_xticklabels([label.replace('_', '\\n') for label in LABEL_COLUMNS], rotation=45)\n",
    "\n",
    "# Plot 4: Test set label distribution (bar chart)\n",
    "test_label_counts = [test_df[label].sum() for label in LABEL_COLUMNS]\n",
    "axes[1, 1].bar(range(len(LABEL_COLUMNS)), test_label_counts, color='lightcoral')\n",
    "axes[1, 1].set_title('Test Set Label Counts')\n",
    "axes[1, 1].set_xlabel('Labels')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_xticks(range(len(LABEL_COLUMNS)))\n",
    "axes[1, 1].set_xticklabels([label.replace('_', '\\n') for label in LABEL_COLUMNS], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/data_split_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Update paths for the training process\n",
    "print(f\"\\n Updating paths for training process...\")\n",
    "TRAIN_DATA_PATH = train_split_path\n",
    "VAL_DATA_PATH = val_split_path\n",
    "TEST_DATA_PATH = test_split_no_labels_path  # Use the version without labels for prediction\n",
    "TEST_WITH_LABELS_PATH = test_split_with_labels_path  # Keep reference to version with labels\n",
    "\n",
    "print(f\"Updated paths:\")\n",
    "print(f\"- TRAIN_DATA_PATH: {TRAIN_DATA_PATH}\")\n",
    "print(f\"- VAL_DATA_PATH: {VAL_DATA_PATH}\")\n",
    "print(f\"- TEST_DATA_PATH: {TEST_DATA_PATH}\")\n",
    "print(f\"- TEST_WITH_LABELS_PATH: {TEST_WITH_LABELS_PATH}\")\n",
    "\n",
    "# Use the split data for training\n",
    "train_df_split = train_df.copy()\n",
    "val_df_split = val_df.copy()\n",
    "test_df = test_df_no_labels.copy()  # This will be used for prediction\n",
    "\n",
    "print(f\"\\n Data splitting completed successfully!\")\n",
    "print(f\"Ready to proceed with training using the split data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954dc19d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:34:07.598749Z",
     "iopub.status.busy": "2025-06-22T12:34:07.598084Z",
     "iopub.status.idle": "2025-06-22T12:34:07.660771Z",
     "shell.execute_reply": "2025-06-22T12:34:07.660101Z",
     "shell.execute_reply.started": "2025-06-22T12:34:07.598724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data with subsampling and oversampling...\n",
      "\n",
      "==================================================\n",
      "SUBSAMPLING TRAINING DATA TO 20.0%\n",
      "==================================================\n",
      "Original training set size: 111,763\n",
      "Subsampling to: 22,352 samples (20.0%)\n",
      "\n",
      "Label distribution comparison:\n",
      "Original training set:\n",
      "  toxic: 10,712 (9.58%)\n",
      "  severe_toxic: 1,144 (1.02%)\n",
      "  obscene: 5,939 (5.31%)\n",
      "  threat: 336 (0.30%)\n",
      "  insult: 5,541 (4.96%)\n",
      "  identity_hate: 993 (0.89%)\n",
      "\n",
      "Subsampled training set:\n",
      "  toxic: 2,123 (9.50%)\n",
      "  severe_toxic: 206 (0.92%)\n",
      "  obscene: 1,154 (5.16%)\n",
      "  threat: 58 (0.26%)\n",
      "  insult: 1,105 (4.94%)\n",
      "  identity_hate: 184 (0.82%)\n",
      "\n",
      "Using subsampled training dataset: 22,352 samples\n",
      "\n",
      "==================================================\n",
      "APPLYING OVERSAMPLING TO MINORITY CLASSES\n",
      "==================================================\n",
      "Class distribution BEFORE oversampling:\n",
      "toxic: 2123.0/22352 (9.50%)\n",
      "severe_toxic: 206.0/22352 (0.92%)\n",
      "obscene: 1154.0/22352 (5.16%)\n",
      "threat: 58.0/22352 (0.26%)\n",
      "insult: 1105.0/22352 (4.94%)\n",
      "identity_hate: 184.0/22352 (0.82%)\n",
      "Oversampling threat: 58 samples × 39 = 2262 additional samples\n",
      "Oversampling identity_hate: 184 samples × 19 = 3496 additional samples\n",
      "Oversampling severe_toxic: 206 samples × 14 = 2884 additional samples\n",
      "\n",
      "Dataset size: 22352 → 30994 (+8642 samples)\n",
      "Class distribution AFTER oversampling:\n",
      "toxic: 10246.0/30994 (33.06%)\n",
      "severe_toxic: 4568.0/30994 (14.74%)\n",
      "obscene: 7604.0/30994 (24.53%)\n",
      "threat: 2777.0/30994 (8.96%)\n",
      "insult: 7658.0/30994 (24.71%)\n",
      "identity_hate: 4845.0/30994 (15.63%)\n",
      "\n",
      "Final training data after subsampling and oversampling:\n",
      "Training samples: 30,994\n",
      "Training labels shape: (30994, 6)\n",
      "\n",
      "Validation data (unchanged):\n",
      "- Validation texts: 23,872\n",
      "- Validation labels shape: (23872, 6)\n",
      "\n",
      "Test data:\n",
      "- Test texts: 23,936\n",
      "- Test labels: None (for prediction)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing training data with subsampling and oversampling...\")\n",
    "\n",
    "# Apply subsampling if enabled\n",
    "if USE_TRAINING_SUBSAMPLING and TRAINING_SUBSAMPLE_FRACTION < 1.0:\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"SUBSAMPLING TRAINING DATA TO {TRAINING_SUBSAMPLE_FRACTION*100}%\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    original_train_size = len(train_df_split)\n",
    "    subsample_size = int(original_train_size * TRAINING_SUBSAMPLE_FRACTION)\n",
    "    \n",
    "    print(f\"Original training set size: {original_train_size:,}\")\n",
    "    print(f\"Subsampling to: {subsample_size:,} samples ({TRAINING_SUBSAMPLE_FRACTION*100}%)\")\n",
    "    \n",
    "    # Perform stratified subsampling to maintain label distribution\n",
    "    train_df_subsampled = train_df_split.sample(\n",
    "        n=subsample_size, \n",
    "        random_state=42, \n",
    "        replace=False\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nLabel distribution comparison:\")\n",
    "    print(\"Original training set:\")\n",
    "    for label in LABEL_COLUMNS:\n",
    "        orig_count = train_df_split[label].sum()\n",
    "        orig_pct = (orig_count / len(train_df_split)) * 100\n",
    "        print(f\"  {label}: {orig_count:,} ({orig_pct:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nSubsampled training set:\")\n",
    "    for label in LABEL_COLUMNS:\n",
    "        sub_count = train_df_subsampled[label].sum()\n",
    "        sub_pct = (sub_count / len(train_df_subsampled)) * 100\n",
    "        print(f\"  {label}: {sub_count:,} ({sub_pct:.2f}%)\")\n",
    "    \n",
    "    # Use subsampled data for training\n",
    "    train_df_for_training = train_df_subsampled\n",
    "    print(f\"\\nUsing subsampled training dataset: {len(train_df_for_training):,} samples\")\n",
    "else:\n",
    "    print(\"Using full training dataset (no subsampling)\")\n",
    "    train_df_for_training = train_df_split\n",
    "    print(f\"Training samples: {len(train_df_for_training):,}\")\n",
    "\n",
    "# Extract texts and labels from the training data to use\n",
    "train_texts = train_df_for_training[TEXT_COLUMN].fillna('').tolist()\n",
    "train_labels = train_df_for_training[LABEL_COLUMNS].values.astype(float)\n",
    "\n",
    "# Convert to DataFrame for oversampling\n",
    "train_df_for_oversampling = pd.DataFrame({\n",
    "    TEXT_COLUMN: train_texts\n",
    "})\n",
    "train_labels_df = pd.DataFrame(train_labels, columns=LABEL_COLUMNS)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"APPLYING OVERSAMPLING TO MINORITY CLASSES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Apply oversampling\n",
    "X_oversampled, y_oversampled = oversample_minority_classes(\n",
    "    train_df_for_oversampling, \n",
    "    train_labels_df\n",
    ")\n",
    "\n",
    "# Convert back to lists for the rest of the pipeline\n",
    "train_texts_split = X_oversampled[TEXT_COLUMN].tolist()\n",
    "train_labels_split = y_oversampled.values.astype(float)\n",
    "\n",
    "print(f\"\\nFinal training data after subsampling and oversampling:\")\n",
    "print(f\"Training samples: {len(train_texts_split):,}\")\n",
    "print(f\"Training labels shape: {train_labels_split.shape}\")\n",
    "\n",
    "# Validation data\n",
    "val_texts = val_df_split[TEXT_COLUMN].fillna('').tolist()\n",
    "val_labels = val_df_split[LABEL_COLUMNS].values.astype(float)\n",
    "\n",
    "print(f\"\\nValidation data (unchanged):\")\n",
    "print(f\"- Validation texts: {len(val_texts):,}\")\n",
    "print(f\"- Validation labels shape: {val_labels.shape}\")\n",
    "\n",
    "# Test data preparation\n",
    "test_texts = test_df[TEXT_COLUMN].fillna('').tolist() if TEXT_COLUMN in test_df.columns else []\n",
    "test_labels = None\n",
    "\n",
    "print(f\"\\nTest data:\")\n",
    "print(f\"- Test texts: {len(test_texts):,}\")\n",
    "print(f\"- Test labels: None (for prediction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c3a7f-b662-4244-a250-834cdd82d71e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:34:17.302128Z",
     "iopub.status.busy": "2025-06-22T12:34:17.301589Z",
     "iopub.status.idle": "2025-06-22T12:34:41.136228Z",
     "shell.execute_reply": "2025-06-22T12:34:41.135344Z",
     "shell.execute_reply.started": "2025-06-22T12:34:17.302109Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MAX_LENGTH for T5 tokenization: 512\n",
      "T5 can handle longer sequences - using 512 tokens\n",
      "Creating Hugging Face Datasets from lists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-tokenizing datasets using .map()... This might take some time for T5.\n",
      "T5 tokenization with 512 max length may be slower but provides better context understanding.\n",
      "Using num_proc=2 for .map()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34afe52e9c2b48abbcd148d14a8cdcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing training data (num_proc=2):   0%|          | 0/30994 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f4d97dd2544a68b281da9ec3408b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing validation data (num_proc=2):   0%|          | 0/23872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b07855a831f4c78bc1bb9215536434a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing test data (num_proc=2):   0%|          | 0/23936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datasets pre-tokenized and formatted for PyTorch.\n",
      "Sample from tokenized training dataset: {'labels': tensor([0., 0., 0., 0., 0., 0.]), 'input_ids': tensor([   96,  4039,   397,   461, 22115,    52,   332,  9361,  1915,   549,\n",
      "          345,    10,  7400,  9164,  3502,   329,     6,    96,   121,   371,\n",
      "          173,    51,     7,    24,    43,    59,   118,  5899,    57,  3468,\n",
      "         2836,    12,    43,     3, 28916,  3218,  4832,   225,    59,    43,\n",
      "           70,   293,  2984,   535,   121,   101,   225,  7986, 18667,     7,\n",
      "           13,     8, 12802,    10,   461, 22115,    52,   332,  9361,   139,\n",
      "           48,  1108,     6,    38,   165,  1108,    19,   966,  4585, 23350,\n",
      "           45,    48,    80,  6161,     5,    96,     1,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n",
      "\n",
      "Tokenization verification:\n",
      "- Sample text length: 326 characters\n",
      "- Tokenized length: 77 tokens\n",
      "- Max length setting: 512 tokens\n",
      "- T5 can effectively use the longer context for better understanding\n",
      "\n",
      "✓ Pre-tokenized datasets assigned.\n",
      "Training dataset size: 30,994\n",
      "Validation dataset size: 23,872\n",
      "Test dataset size: 23,936\n"
     ]
    }
   ],
   "source": [
    "# Create Hugging Face Datasets and Tokenize for T5\n",
    "from datasets import Dataset as HFDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ensure tokenizer is loaded\n",
    "if 'tokenizer' not in globals():\n",
    "    raise NameError(\"Tokenizer not found. Ensure it's loaded in a previous cell.\")\n",
    "if tokenizer.pad_token is None:\n",
    "    if tokenizer.eos_token:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        print(f\"Tokenizer pad_token set to eos_token: {tokenizer.pad_token} (ID: {tokenizer.pad_token_id})\")\n",
    "    else:\n",
    "        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        print(f\"Added a new pad_token: [PAD] (ID: {tokenizer.pad_token_id})\")\n",
    "\n",
    "print(f\"Using MAX_LENGTH for T5 tokenization: {MAX_LENGTH}\")\n",
    "print(f\"T5 can handle longer sequences - using {MAX_LENGTH} tokens\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenization function optimized for T5\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None  \n",
    "    )\n",
    "\n",
    "print(\"Creating Hugging Face Datasets from lists...\")\n",
    "hf_train_data = HFDataset.from_dict({\n",
    "    \"text\": train_texts_split,\n",
    "    \"labels\": train_labels_split.tolist()\n",
    "})\n",
    "hf_val_data = HFDataset.from_dict({\n",
    "    \"text\": val_texts,\n",
    "    \"labels\": val_labels.tolist()\n",
    "})\n",
    "\n",
    "if test_texts:\n",
    "    if test_labels is not None:\n",
    "        hf_test_data = HFDataset.from_dict({ \"text\": test_texts, \"labels\": test_labels.tolist() })\n",
    "    else:\n",
    "        hf_test_data = HFDataset.from_dict({ \"text\": test_texts })\n",
    "else:\n",
    "    hf_test_data = None\n",
    "\n",
    "print(\"Pre-tokenizing datasets using .map()... This might take some time for T5.\")\n",
    "print(f\"T5 tokenization with {MAX_LENGTH} max length may be slower but provides better context understanding.\")\n",
    "\n",
    "# Temporarily allow tokenizer parallelism for this step\n",
    "original_tokenizer_parallelism = os.environ.get(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "num_available_cpus = os.cpu_count() or 1\n",
    "num_proc_to_use = min(4, num_available_cpus // 2 if num_available_cpus > 1 else 1)\n",
    "print(f\"Using num_proc={num_proc_to_use} for .map()\")\n",
    "\n",
    "tokenized_train_dataset = hf_train_data.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=num_proc_to_use,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing training data\"\n",
    ")\n",
    "tokenized_val_dataset = hf_val_data.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=num_proc_to_use,\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing validation data\"\n",
    ")\n",
    "if hf_test_data:\n",
    "    tokenized_test_dataset = hf_test_data.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        num_proc=num_proc_to_use,\n",
    "        remove_columns=[\"text\"] if \"text\" in hf_test_data.column_names else None,\n",
    "        desc=\"Tokenizing test data\"\n",
    "    )\n",
    "else:\n",
    "    tokenized_test_dataset = None\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = original_tokenizer_parallelism\n",
    "\n",
    "# Set format to PyTorch tensors\n",
    "tokenized_train_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_val_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "if tokenized_test_dataset:\n",
    "    if \"labels\" in tokenized_test_dataset.column_names:\n",
    "        tokenized_test_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    else:\n",
    "        tokenized_test_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "print(\"✓ Datasets pre-tokenized and formatted for PyTorch.\")\n",
    "print(f\"Sample from tokenized training dataset: {tokenized_train_dataset[0]}\")\n",
    "\n",
    "# Verify tokenization worked correctly\n",
    "sample_text = train_texts_split[0] if train_texts_split else \"sample text\"\n",
    "sample_tokens = tokenizer(sample_text, truncation=True, max_length=MAX_LENGTH)\n",
    "print(f\"\\nTokenization verification:\")\n",
    "print(f\"- Sample text length: {len(sample_text)} characters\")\n",
    "print(f\"- Tokenized length: {len(sample_tokens['input_ids'])} tokens\")\n",
    "print(f\"- Max length setting: {MAX_LENGTH} tokens\")\n",
    "print(f\"- T5 can effectively use the longer context for better understanding\")\n",
    "\n",
    "# Assign datasets to trainer variables\n",
    "train_dataset = tokenized_train_dataset\n",
    "val_dataset = tokenized_val_dataset\n",
    "test_dataset = tokenized_test_dataset\n",
    "\n",
    "print(\"\\n✓ Pre-tokenized datasets assigned.\")\n",
    "if train_dataset:\n",
    "    print(f\"Training dataset size: {len(train_dataset):,}\")\n",
    "if val_dataset:\n",
    "    print(f\"Validation dataset size: {len(val_dataset):,}\")\n",
    "if test_dataset:\n",
    "    print(f\"Test dataset size: {len(test_dataset):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7514032-e5c2-40aa-9620-aa226a9beece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:34:44.751426Z",
     "iopub.status.busy": "2025-06-22T12:34:44.750906Z",
     "iopub.status.idle": "2025-06-22T12:34:51.052087Z",
     "shell.execute_reply": "2025-06-22T12:34:51.051398Z",
     "shell.execute_reply.started": "2025-06-22T12:34:44.751399Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading custom T5 model google/flan-t5-base for sequence classification...\n",
      "Using custom T5ForClassification with classification head...\n",
      "CUDA cache cleared. Available memory: 15.9 GB\n",
      "Loading custom T5ForClassification model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a749530e903d493c9cb54a001fd839b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49310ff087de472cbbe47376a65a3299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Custom T5ForClassification model loaded successfully!\n",
      "  - Encoder: google/flan-t5-base\n",
      "  - Hidden size: 768\n",
      "  - Number of labels: 6\n",
      "Model with quantization is on: cpu\n",
      "Set model.config.pad_token_id to: 0\n",
      "Warning: Tokenizer size (32100) != original vocab size (32128), but quantization prevents resizing\n",
      "✓ Model prepared for k-bit training\n",
      "trainable params: 2,017,926 || all params: 111,944,076 || trainable%: 1.8026\n",
      "✓ LoRA adapters added to model\n",
      "\n",
      "📊 Model Configuration Summary:\n",
      "- Model: google/flan-t5-base with classification head\n",
      "- Architecture: T5 Encoder + Classification Head\n",
      "- Quantization: True\n",
      "- LoRA: True\n",
      "- Labels: 6 (toxic, severe_toxic, obscene, threat, insult, identity_hate)\n",
      "- Max Length: 512\n",
      "- Batch Size: 8\n",
      "- Hidden Size: 768\n",
      "\n",
      "🔧 Model Setup Check:\n",
      "- Model device: cpu\n",
      "- Model type: <class 'peft.peft_model.PeftModelForSequenceClassification'>\n",
      "- Is DataParallel: False\n",
      "- CUDA device count: 1\n"
     ]
    }
   ],
   "source": [
    "# Load Custom T5 Model for Classification\n",
    "num_labels = len(LABEL_COLUMNS)\n",
    "\n",
    "print(f\"Loading custom T5 model {MODEL_NAME} for sequence classification...\")\n",
    "print(\"Using custom T5ForClassification with classification head...\")\n",
    "\n",
    "# Clear CUDA cache before loading model\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"CUDA cache cleared. Available memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# Load custom T5 classification model\n",
    "model_loaded = False\n",
    "\n",
    "try:\n",
    "    print(\"Loading custom T5ForClassification model...\")\n",
    "    model = T5ForClassification(\n",
    "        model_name=MODEL_NAME,\n",
    "        num_labels=num_labels,\n",
    "        dropout_rate=0.1\n",
    "    )\n",
    "    print(f\"✓ Custom T5ForClassification model loaded successfully!\")\n",
    "    print(f\"  - Encoder: {MODEL_NAME}\")\n",
    "    print(f\"  - Hidden size: {model.hidden_size}\")\n",
    "    print(f\"  - Number of labels: {num_labels}\")\n",
    "    model_loaded = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to load custom T5 model: {e}\")\n",
    "    raise RuntimeError(f\"Failed to load T5 model: {e}\")\n",
    "\n",
    "# Move model to GPU if available and not using quantization\n",
    "if torch.cuda.is_available() and not USE_QUANTIZATION:\n",
    "    print(f\"Moving model to GPU (cuda:0)...\")\n",
    "    model = model.to('cuda:0')\n",
    "    print(f\"✓ Model moved to: {next(model.parameters()).device}\")\n",
    "elif USE_QUANTIZATION:\n",
    "    print(f\"Model with quantization is on: {next(model.parameters()).device}\")\n",
    "else:\n",
    "    print(\"WARNING: CUDA not available, model will run on CPU\")\n",
    "\n",
    "# Ensure the model config is updated with the pad_token_id from the tokenizer\n",
    "if tokenizer.pad_token_id is not None:\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    print(f\"Set model.config.pad_token_id to: {model.config.pad_token_id}\")\n",
    "\n",
    "# Resize token embeddings if needed\n",
    "original_vocab_size = model.config.vocab_size if hasattr(model.config, 'vocab_size') else len(tokenizer)\n",
    "if len(tokenizer) != original_vocab_size:\n",
    "    if not USE_QUANTIZATION:\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        print(f\"Token embeddings resized from {original_vocab_size} to {len(tokenizer)}\")\n",
    "    else:\n",
    "        print(f\"Warning: Tokenizer size ({len(tokenizer)}) != original vocab size ({original_vocab_size}), but quantization prevents resizing\")\n",
    "\n",
    "# Prepare model for k-bit training if using quantization\n",
    "if USE_QUANTIZATION:\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    print(\"✓ Model prepared for k-bit training\")\n",
    "\n",
    "# Configure LoRA if enabled\n",
    "if USE_LORA:\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        inference_mode=False,\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        bias=\"none\",\n",
    "    )\n",
    "    \n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    print(\"✓ LoRA adapters added to model\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Number of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "print(f\"\\n📊 Model Configuration Summary:\")\n",
    "print(f\"- Model: {MODEL_NAME} with classification head\")\n",
    "print(f\"- Architecture: T5 Encoder + Classification Head\")\n",
    "print(f\"- Quantization: {USE_QUANTIZATION}\")\n",
    "print(f\"- LoRA: {USE_LORA}\")\n",
    "print(f\"- Labels: {NUM_LABELS} ({', '.join(LABEL_COLUMNS)})\")\n",
    "print(f\"- Max Length: {MAX_LENGTH}\")\n",
    "print(f\"- Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"- Hidden Size: {model.hidden_size}\")\n",
    "\n",
    "# Check if model is properly configured\n",
    "print(f\"\\n🔧 Model Setup Check:\")\n",
    "print(f\"- Model device: {next(model.parameters()).device}\")\n",
    "print(f\"- Model type: {type(model)}\")\n",
    "print(f\"- Is DataParallel: {isinstance(model, torch.nn.DataParallel)}\")\n",
    "print(f\"- CUDA device count: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Force model to single device if multiple GPUs detected and quantization is not used\n",
    "if torch.cuda.device_count() > 1 and not USE_QUANTIZATION:\n",
    "    print(\"⚠️ Multiple GPUs detected without quantization - forcing single GPU usage\")\n",
    "    model = model.to(torch.device(\"cuda:0\"))\n",
    "    print(f\"Model moved to: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c075ed3-2178-40a1-b32e-6bd3cfe57793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:40:00.704203Z",
     "iopub.status.busy": "2025-06-22T12:40:00.703903Z",
     "iopub.status.idle": "2025-06-22T12:40:00.737416Z",
     "shell.execute_reply": "2025-06-22T12:40:00.736880Z",
     "shell.execute_reply.started": "2025-06-22T12:40:00.704180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments configured for T5 model:\n",
      "- Model: FLAN-T5-base with classification head\n",
      "- Batch size: 8 (with gradient accumulation: 2)\n",
      "- Effective batch size: 16\n",
      "- Learning rate: 0.0001\n",
      "- Max sequence length: 512\n",
      "- Quantization: True\n",
      "- Mixed precision: bf16=True, fp16=False\n",
      "- Gradient checkpointing: False (disabled for compatibility)\n",
      "- Output directory: /kaggle/working/\n"
     ]
    }
   ],
   "source": [
    "#  Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS, \n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,  \n",
    "    gradient_accumulation_steps=2,  # Increased due to smaller batch size\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_dir=f'{OUTPUT_DIR}/logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    # Mixed precision settings optimized for T5\n",
    "    fp16=torch.cuda.is_available() and not USE_QUANTIZATION,\n",
    "    bf16=torch.cuda.is_available() and USE_QUANTIZATION,  # Use bf16 with quantization\n",
    "    dataloader_num_workers=2,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=False,  # Disabled for custom T5ForClassification model\n",
    "    max_grad_norm=1.0,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    save_safetensors=True,\n",
    "    report_to=None,\n",
    "    dataloader_pin_memory=False,  \n",
    "    ddp_find_unused_parameters=False,\n",
    "    # T5-specific optimizations\n",
    "    dataloader_drop_last=False,\n",
    "    prediction_loss_only=False,\n",
    ")\n",
    "\n",
    "print(\"TrainingArguments configured for T5 model:\")\n",
    "print(f\"- Model: FLAN-T5-base with classification head\")\n",
    "print(f\"- Batch size: {BATCH_SIZE} (with gradient accumulation: {training_args.gradient_accumulation_steps})\")\n",
    "print(f\"- Effective batch size: {BATCH_SIZE * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"- Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"- Max sequence length: {MAX_LENGTH}\")\n",
    "print(f\"- Quantization: {USE_QUANTIZATION}\")\n",
    "print(f\"- Mixed precision: bf16={training_args.bf16}, fp16={training_args.fp16}\")\n",
    "print(f\"- Gradient checkpointing: {training_args.gradient_checkpointing} (disabled for compatibility)\")\n",
    "print(f\"- Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb4a32-b45a-4fde-8bd1-92a15a17cd9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:40:08.328779Z",
     "iopub.status.busy": "2025-06-22T12:40:08.328095Z",
     "iopub.status.idle": "2025-06-22T12:40:08.336675Z",
     "shell.execute_reply": "2025-06-22T12:40:08.335774Z",
     "shell.execute_reply.started": "2025-06-22T12:40:08.328756Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics function defined with float16 compatibility fixes.\n"
     ]
    }
   ],
   "source": [
    "#  Define Metrics for Multi-Label Classification\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute metrics for multi-label classification\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Convert to float32 to avoid scipy.sparse float16 incompatibility\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.float().numpy()\n",
    "    else:\n",
    "        predictions = np.array(predictions, dtype=np.float32)\n",
    "        \n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.float().numpy()\n",
    "    else:\n",
    "        labels = np.array(labels, dtype=np.float32)\n",
    "    \n",
    "    # Apply sigmoid to get probabilities\n",
    "    predictions = torch.sigmoid(torch.tensor(predictions, dtype=torch.float32)).numpy()\n",
    "    \n",
    "    # Convert to binary predictions using 0.5 threshold\n",
    "    binary_predictions = (predictions > 0.5).astype(np.int32)  # Use int32 instead of int\n",
    "    labels = labels.astype(np.int32)  # Ensure labels are also int32\n",
    "    \n",
    "    # Calculate metrics for each label\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, binary_predictions, average=None, zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Calculate macro averages\n",
    "    macro_precision = np.mean(precision)\n",
    "    macro_recall = np.mean(recall)\n",
    "    macro_f1 = np.mean(f1)\n",
    "    \n",
    "    # Calculate micro averages\n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        labels.flatten(), binary_predictions.flatten(), average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Calculate AUC for each label\n",
    "    auc_scores = []\n",
    "    for i in range(labels.shape[1]):\n",
    "        try:\n",
    "            auc = roc_auc_score(labels[:, i], predictions[:, i])\n",
    "            auc_scores.append(auc)\n",
    "        except ValueError:\n",
    "            auc_scores.append(0.0)  # If only one class present\n",
    "    \n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    \n",
    "    # Exact match accuracy (all labels must be correct)\n",
    "    exact_match = np.mean(np.all(binary_predictions == labels, axis=1))\n",
    "    \n",
    "    return {\n",
    "        'macro_precision': macro_precision,\n",
    "        'macro_recall': macro_recall,\n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_precision': micro_precision,\n",
    "        'micro_recall': micro_recall,\n",
    "        'micro_f1': micro_f1,\n",
    "        'mean_auc': mean_auc,\n",
    "        'exact_match_accuracy': exact_match\n",
    "    }\n",
    "\n",
    "print(\"Metrics function defined with float16 compatibility fixes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e0e2dbb-d99d-42bd-a4c6-f44c1935c653",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:40:11.208143Z",
     "iopub.status.busy": "2025-06-22T12:40:11.207451Z",
     "iopub.status.idle": "2025-06-22T12:40:11.214641Z",
     "shell.execute_reply": "2025-06-22T12:40:11.213808Z",
     "shell.execute_reply.started": "2025-06-22T12:40:11.208123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AdaptiveFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, class_gammas=None, label_columns=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.class_gammas = class_gammas or {}\n",
    "        self.epsilon = 1e-6\n",
    "        # Use provided label columns instead of hardcoding\n",
    "        self.label_columns = label_columns or ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Ensure numerical stability\n",
    "        inputs = torch.clamp(inputs, self.epsilon, 1 - self.epsilon)\n",
    "        # Binary cross-entropy per label\n",
    "        bce_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        # Prepare per-class focal weighting\n",
    "        focal_loss = torch.zeros_like(bce_loss)\n",
    "        \n",
    "        for i, name in enumerate(self.label_columns):\n",
    "            gamma = self.class_gammas.get(name, 2.0)\n",
    "            pt = torch.exp(-bce_loss[:, i])  # model confidence for true class\n",
    "            weight = (1 - pt) ** gamma\n",
    "            if self.alpha is not None and i < len(self.alpha):\n",
    "                weight = weight * self.alpha[i]\n",
    "            focal_loss[:, i] = weight * bce_loss[:, i]\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa4e9ad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:40:15.118516Z",
     "iopub.status.busy": "2025-06-22T12:40:15.118011Z",
     "iopub.status.idle": "2025-06-22T12:40:15.125185Z",
     "shell.execute_reply": "2025-06-22T12:40:15.124400Z",
     "shell.execute_reply.started": "2025-06-22T12:40:15.118494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainerWithAdaptiveLoss(Trainer):\n",
    "    def __init__(self, *args, loss_fn=None, threshold=0.5, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.loss_history = []\n",
    "        self.threshold = threshold  # Add threshold parameter\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.sigmoid(outputs.logits)\n",
    "        loss = self.loss_fn(probs, labels)\n",
    "        \n",
    "        # Store loss for monitoring\n",
    "        self.loss_history.append(loss.item())\n",
    "        \n",
    "        # Log some statistics periodically\n",
    "        if len(self.loss_history) % 50 == 0:\n",
    "            recent_losses = self.loss_history[-50:]\n",
    "            avg_loss = sum(recent_losses) / len(recent_losses)\n",
    "            print(f\"Recent avg loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        \"\"\"Override prediction step to return binary predictions\"\"\"\n",
    "        # Get the standard prediction step results\n",
    "        loss, logits, labels = super().prediction_step(model, inputs, prediction_loss_only=False, ignore_keys=ignore_keys)\n",
    "        \n",
    "        if logits is not None:\n",
    "            # Convert logits to probabilities\n",
    "            probs = torch.sigmoid(logits)\n",
    "            # Convert probabilities to binary predictions using threshold\n",
    "            binary_preds = (probs >= self.threshold).float()\n",
    "            # Return binary predictions instead of raw logits\n",
    "            return loss, binary_preds, labels\n",
    "        \n",
    "        return loss, logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8774ab-c45b-4e73-a39d-e7cdb66c3599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:40:17.938964Z",
     "iopub.status.busy": "2025-06-22T12:40:17.938253Z",
     "iopub.status.idle": "2025-06-22T12:40:17.954725Z",
     "shell.execute_reply": "2025-06-22T12:40:17.954154Z",
     "shell.execute_reply.started": "2025-06-22T12:40:17.938940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized successfully!\n",
      "Training dataset size: 30994\n",
      "Validation dataset size: 23872\n",
      "Model device: cuda:0\n",
      "Is model DataParallel: False\n"
     ]
    }
   ],
   "source": [
    "# 9. Initialize Trainer with Custom Loss\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer, \n",
    "    padding=True,\n",
    "    max_length=MAX_LENGTH,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainerWithAdaptiveLoss(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    loss_fn=AdaptiveFocalLoss(\n",
    "        alpha=[1.2, 1.5, 1.2, 2.0, 1.2, 2.0],\n",
    "        class_gammas={'threat':10,'identity_hate':7,'severe_toxic':7},\n",
    "        label_columns=LABEL_COLUMNS\n",
    "    ),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
    "    threshold=0.5  # Add threshold parameter\n",
    ")\n",
    "\n",
    "\n",
    "if hasattr(trainer.model, 'module'):\n",
    "    print(\"WARNING: Model is wrapped in DataParallel, unwrapping...\")\n",
    "    trainer.model = trainer.model.module\n",
    "\n",
    "print(\"Trainer initialized successfully!\")\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Model device: {next(trainer.model.parameters()).device}\")\n",
    "print(f\"Is model DataParallel: {isinstance(trainer.model, torch.nn.DataParallel)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b705fae-08ef-47d8-8b7f-8c5e61a16e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T12:40:21.068033Z",
     "iopub.status.busy": "2025-06-22T12:40:21.067511Z",
     "iopub.status.idle": "2025-06-22T16:48:29.869571Z",
     "shell.execute_reply": "2025-06-22T16:48:29.868871Z",
     "shell.execute_reply.started": "2025-06-22T12:40:21.068009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning with custom loss...\n",
      "Enhanced setup should prevent DataParallel issues...\n",
      "CUDA cache cleared\n",
      "Pre-training diagnostics:\n",
      "- Model device: cuda:0\n",
      "- Model type: <class 'peft.peft_model.PeftModelForSequenceClassification'>\n",
      "- Is DataParallel: False\n",
      "- Quantization: True\n",
      "- CUDA devices: 1\n",
      "- Training dataset size: 30994\n",
      "- Validation dataset size: 23872\n",
      "Checking initial model weights...\n",
      " Model weights are clean\n",
      "GPU Memory - Allocated: 0.42 GB\n",
      "GPU Memory - Cached: 0.57 GB\n",
      "Trainer model device: cuda:0\n",
      "Trainer model type: <class 'peft.peft_model.PeftModelForSequenceClassification'>\n",
      "\n",
      " Calling trainer.train()...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5811' max='5811' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5811/5811 4:08:06, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Mean Auc</th>\n",
       "      <th>Exact Match Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.448716</td>\n",
       "      <td>0.589316</td>\n",
       "      <td>0.411525</td>\n",
       "      <td>0.970167</td>\n",
       "      <td>0.970167</td>\n",
       "      <td>0.970167</td>\n",
       "      <td>0.782415</td>\n",
       "      <td>0.887735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.013136</td>\n",
       "      <td>0.420760</td>\n",
       "      <td>0.676859</td>\n",
       "      <td>0.478251</td>\n",
       "      <td>0.970963</td>\n",
       "      <td>0.970963</td>\n",
       "      <td>0.970963</td>\n",
       "      <td>0.827290</td>\n",
       "      <td>0.894228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.017170</td>\n",
       "      <td>0.386280</td>\n",
       "      <td>0.729163</td>\n",
       "      <td>0.489355</td>\n",
       "      <td>0.967724</td>\n",
       "      <td>0.967724</td>\n",
       "      <td>0.967724</td>\n",
       "      <td>0.849945</td>\n",
       "      <td>0.880990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>0.490564</td>\n",
       "      <td>0.685066</td>\n",
       "      <td>0.559714</td>\n",
       "      <td>0.977673</td>\n",
       "      <td>0.977673</td>\n",
       "      <td>0.977673</td>\n",
       "      <td>0.834476</td>\n",
       "      <td>0.906627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>0.468089</td>\n",
       "      <td>0.764958</td>\n",
       "      <td>0.553788</td>\n",
       "      <td>0.974035</td>\n",
       "      <td>0.974035</td>\n",
       "      <td>0.974035</td>\n",
       "      <td>0.871916</td>\n",
       "      <td>0.897914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.506939</td>\n",
       "      <td>0.697393</td>\n",
       "      <td>0.571245</td>\n",
       "      <td>0.977854</td>\n",
       "      <td>0.977854</td>\n",
       "      <td>0.977854</td>\n",
       "      <td>0.840762</td>\n",
       "      <td>0.906627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.478684</td>\n",
       "      <td>0.738198</td>\n",
       "      <td>0.559464</td>\n",
       "      <td>0.976416</td>\n",
       "      <td>0.976416</td>\n",
       "      <td>0.976416</td>\n",
       "      <td>0.860132</td>\n",
       "      <td>0.903820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.482998</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>0.566275</td>\n",
       "      <td>0.976674</td>\n",
       "      <td>0.976674</td>\n",
       "      <td>0.976674</td>\n",
       "      <td>0.862449</td>\n",
       "      <td>0.903108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.491660</td>\n",
       "      <td>0.716026</td>\n",
       "      <td>0.570427</td>\n",
       "      <td>0.977498</td>\n",
       "      <td>0.977498</td>\n",
       "      <td>0.977498</td>\n",
       "      <td>0.849505</td>\n",
       "      <td>0.904281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>0.495525</td>\n",
       "      <td>0.716160</td>\n",
       "      <td>0.571438</td>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.849905</td>\n",
       "      <td>0.906459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>0.489523</td>\n",
       "      <td>0.728671</td>\n",
       "      <td>0.568731</td>\n",
       "      <td>0.977289</td>\n",
       "      <td>0.977289</td>\n",
       "      <td>0.977289</td>\n",
       "      <td>0.855800</td>\n",
       "      <td>0.905077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent avg loss: 0.1073\n",
      "Recent avg loss: 0.1070\n",
      "Recent avg loss: 0.1064\n",
      "Recent avg loss: 0.1051\n",
      "Recent avg loss: 0.1036\n",
      "Recent avg loss: 0.1012\n",
      "Recent avg loss: 0.0967\n",
      "Recent avg loss: 0.0879\n",
      "Recent avg loss: 0.0738\n",
      "Recent avg loss: 0.0573\n",
      "Recent avg loss: 0.0497\n",
      "Recent avg loss: 0.0375\n",
      "Recent avg loss: 0.0341\n",
      "Recent avg loss: 0.0350\n",
      "Recent avg loss: 0.0278\n",
      "Recent avg loss: 0.0245\n",
      "Recent avg loss: 0.0256\n",
      "Recent avg loss: 0.0292\n",
      "Recent avg loss: 0.0277\n",
      "Recent avg loss: 0.0250\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0166\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0183\n",
      "Recent avg loss: 0.0146\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0187\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0193\n",
      "Recent avg loss: 0.0181\n",
      "Recent avg loss: 0.0196\n",
      "Recent avg loss: 0.0188\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0176\n",
      "Recent avg loss: 0.0189\n",
      "Recent avg loss: 0.0217\n",
      "Recent avg loss: 0.0146\n",
      "Recent avg loss: 0.0170\n",
      "Recent avg loss: 0.0164\n",
      "Recent avg loss: 0.0167\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0195\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0161\n",
      "Recent avg loss: 0.0191\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0162\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0158\n",
      "Recent avg loss: 0.0165\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0202\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0157\n",
      "Recent avg loss: 0.0212\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0168\n",
      "Recent avg loss: 0.0209\n",
      "Recent avg loss: 0.0197\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0168\n",
      "Recent avg loss: 0.0153\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0188\n",
      "Recent avg loss: 0.0216\n",
      "Recent avg loss: 0.0159\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0169\n",
      "Recent avg loss: 0.0182\n",
      "Recent avg loss: 0.0155\n",
      "Recent avg loss: 0.0200\n",
      "Recent avg loss: 0.0181\n",
      "Recent avg loss: 0.0216\n",
      "Recent avg loss: 0.0258\n",
      "Recent avg loss: 0.0256\n",
      "Recent avg loss: 0.0245\n",
      "Recent avg loss: 0.0251\n",
      "Recent avg loss: 0.0235\n",
      "Recent avg loss: 0.0198\n",
      "Recent avg loss: 0.0200\n",
      "Recent avg loss: 0.0268\n",
      "Recent avg loss: 0.0262\n",
      "Recent avg loss: 0.0194\n",
      "Recent avg loss: 0.0226\n",
      "Recent avg loss: 0.0248\n",
      "Recent avg loss: 0.0249\n",
      "Recent avg loss: 0.0213\n",
      "Recent avg loss: 0.0192\n",
      "Recent avg loss: 0.0247\n",
      "Recent avg loss: 0.0202\n",
      "Recent avg loss: 0.0212\n",
      "Recent avg loss: 0.0206\n",
      "Recent avg loss: 0.0170\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0124\n",
      "Recent avg loss: 0.0091\n",
      "Recent avg loss: 0.0172\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0118\n",
      "Recent avg loss: 0.0084\n",
      "Recent avg loss: 0.0105\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0177\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0179\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0153\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0124\n",
      "Recent avg loss: 0.0152\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0105\n",
      "Recent avg loss: 0.0170\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0095\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0152\n",
      "Recent avg loss: 0.0108\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0160\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0209\n",
      "Recent avg loss: 0.0190\n",
      "Recent avg loss: 0.0219\n",
      "Recent avg loss: 0.0182\n",
      "Recent avg loss: 0.0227\n",
      "Recent avg loss: 0.0209\n",
      "Recent avg loss: 0.0185\n",
      "Recent avg loss: 0.0201\n",
      "Recent avg loss: 0.0211\n",
      "Recent avg loss: 0.0183\n",
      "Recent avg loss: 0.0180\n",
      "Recent avg loss: 0.0197\n",
      "Recent avg loss: 0.0178\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0195\n",
      "Recent avg loss: 0.0218\n",
      "Recent avg loss: 0.0226\n",
      "Recent avg loss: 0.0209\n",
      "Recent avg loss: 0.0212\n",
      "Recent avg loss: 0.0187\n",
      "Recent avg loss: 0.0178\n",
      "Recent avg loss: 0.0173\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0190\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0189\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0164\n",
      "Recent avg loss: 0.0162\n",
      "Recent avg loss: 0.0165\n",
      "Recent avg loss: 0.0202\n",
      "Recent avg loss: 0.0241\n",
      "Recent avg loss: 0.0206\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0191\n",
      "Recent avg loss: 0.0170\n",
      "Recent avg loss: 0.0190\n",
      "Recent avg loss: 0.0192\n",
      "Recent avg loss: 0.0212\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0171\n",
      "Recent avg loss: 0.0201\n",
      "Recent avg loss: 0.0158\n",
      "Recent avg loss: 0.0166\n",
      "Recent avg loss: 0.0172\n",
      "Recent avg loss: 0.0157\n",
      "Recent avg loss: 0.0183\n",
      "Recent avg loss: 0.0164\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0196\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0187\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0177\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0167\n",
      "Recent avg loss: 0.0169\n",
      "Recent avg loss: 0.0188\n",
      "Recent avg loss: 0.0179\n",
      "Recent avg loss: 0.0164\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0211\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0166\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0155\n",
      "Recent avg loss: 0.0157\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0175\n",
      "Recent avg loss: 0.0164\n",
      "Recent avg loss: 0.0208\n",
      "Recent avg loss: 0.0169\n",
      "Recent avg loss: 0.0161\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0170\n",
      "Recent avg loss: 0.0185\n",
      "Recent avg loss: 0.0203\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0182\n",
      "Recent avg loss: 0.0239\n",
      "Recent avg loss: 0.0188\n",
      "Recent avg loss: 0.0181\n",
      "Recent avg loss: 0.0194\n",
      "Recent avg loss: 0.0205\n",
      "Recent avg loss: 0.0202\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0180\n",
      "Recent avg loss: 0.0205\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0184\n",
      "Recent avg loss: 0.0153\n",
      "Recent avg loss: 0.0152\n",
      "Recent avg loss: 0.0170\n",
      "Recent avg loss: 0.0191\n",
      "Recent avg loss: 0.0166\n",
      "Recent avg loss: 0.0187\n",
      "Recent avg loss: 0.0196\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0095\n",
      "Recent avg loss: 0.0167\n",
      "Recent avg loss: 0.0106\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0085\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0102\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0180\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0191\n",
      "Recent avg loss: 0.0118\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0155\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0157\n",
      "Recent avg loss: 0.0086\n",
      "Recent avg loss: 0.0151\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0114\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0114\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0106\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0107\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0160\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0102\n",
      "Recent avg loss: 0.0110\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0173\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0188\n",
      "Recent avg loss: 0.0197\n",
      "Recent avg loss: 0.0168\n",
      "Recent avg loss: 0.0226\n",
      "Recent avg loss: 0.0160\n",
      "Recent avg loss: 0.0190\n",
      "Recent avg loss: 0.0175\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0166\n",
      "Recent avg loss: 0.0203\n",
      "Recent avg loss: 0.0199\n",
      "Recent avg loss: 0.0199\n",
      "Recent avg loss: 0.0152\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0166\n",
      "Recent avg loss: 0.0153\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0108\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0103\n",
      "Recent avg loss: 0.0203\n",
      "Recent avg loss: 0.0107\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0095\n",
      "Recent avg loss: 0.0114\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0199\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0207\n",
      "Recent avg loss: 0.0161\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0167\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0195\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0174\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0161\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0108\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0151\n",
      "Recent avg loss: 0.0151\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0110\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0164\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0152\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0152\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0160\n",
      "Recent avg loss: 0.0186\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0162\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0166\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0161\n",
      "Recent avg loss: 0.0190\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0160\n",
      "Recent avg loss: 0.0159\n",
      "Recent avg loss: 0.0163\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0153\n",
      "Recent avg loss: 0.0164\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0090\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0164\n",
      "Recent avg loss: 0.0088\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0082\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0099\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0162\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0157\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0110\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0107\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0108\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0106\n",
      "Recent avg loss: 0.0107\n",
      "Recent avg loss: 0.0153\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0107\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0087\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0104\n",
      "Recent avg loss: 0.0168\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0095\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0123\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0107\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0094\n",
      "Recent avg loss: 0.0189\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0124\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0180\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0153\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0157\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0114\n",
      "Recent avg loss: 0.0086\n",
      "Recent avg loss: 0.0155\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0083\n",
      "Recent avg loss: 0.0100\n",
      "Recent avg loss: 0.0099\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0146\n",
      "Recent avg loss: 0.0170\n",
      "Recent avg loss: 0.0146\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0160\n",
      "Recent avg loss: 0.0177\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0106\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0124\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0082\n",
      "Recent avg loss: 0.0166\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0106\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0159\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0110\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0104\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0161\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0098\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0187\n",
      "Recent avg loss: 0.0108\n",
      "Recent avg loss: 0.0114\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0123\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0180\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0151\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0163\n",
      "Recent avg loss: 0.0158\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0118\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0096\n",
      "Recent avg loss: 0.0195\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0107\n",
      "Recent avg loss: 0.0089\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0097\n",
      "Recent avg loss: 0.0185\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0173\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0185\n",
      "Recent avg loss: 0.0103\n",
      "Recent avg loss: 0.0124\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0163\n",
      "Recent avg loss: 0.0123\n",
      "Recent avg loss: 0.0103\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0168\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0101\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0106\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0114\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0123\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0099\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0151\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0152\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0180\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0162\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0146\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0162\n",
      "Recent avg loss: 0.0124\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0167\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0106\n",
      "Recent avg loss: 0.0102\n",
      "Recent avg loss: 0.0188\n",
      "Recent avg loss: 0.0089\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0091\n",
      "Recent avg loss: 0.0103\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0101\n",
      "Recent avg loss: 0.0175\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0153\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0146\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0168\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0105\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0099\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0160\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0107\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0091\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0169\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0123\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0096\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0102\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0089\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0098\n",
      "Recent avg loss: 0.0175\n",
      "Recent avg loss: 0.0167\n",
      "Recent avg loss: 0.0161\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0103\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0131\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0156\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0081\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0157\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0078\n",
      "Recent avg loss: 0.0096\n",
      "Recent avg loss: 0.0103\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0151\n",
      "Recent avg loss: 0.0173\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0146\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0160\n",
      "Recent avg loss: 0.0173\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0102\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0091\n",
      "Recent avg loss: 0.0151\n",
      "Recent avg loss: 0.0123\n",
      "Recent avg loss: 0.0101\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0158\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0110\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0173\n",
      "Recent avg loss: 0.0137\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0118\n",
      "Recent avg loss: 0.0101\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0177\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0109\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0124\n",
      "Recent avg loss: 0.0128\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0187\n",
      "Recent avg loss: 0.0097\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0135\n",
      "Recent avg loss: 0.0095\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0113\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0132\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0092\n",
      "Recent avg loss: 0.0194\n",
      "Recent avg loss: 0.0103\n",
      "Recent avg loss: 0.0143\n",
      "Recent avg loss: 0.0104\n",
      "Recent avg loss: 0.0087\n",
      "Recent avg loss: 0.0108\n",
      "Recent avg loss: 0.0098\n",
      "Recent avg loss: 0.0170\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0163\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0117\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0147\n",
      "Recent avg loss: 0.0178\n",
      "Recent avg loss: 0.0104\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0127\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0148\n",
      "Recent avg loss: 0.0104\n",
      "Recent avg loss: 0.0141\n",
      "Recent avg loss: 0.0138\n",
      "Recent avg loss: 0.0102\n",
      "Recent avg loss: 0.0139\n",
      "Recent avg loss: 0.0124\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0119\n",
      "Recent avg loss: 0.0165\n",
      "Recent avg loss: 0.0157\n",
      "Recent avg loss: 0.0095\n",
      "Recent avg loss: 0.0145\n",
      "Recent avg loss: 0.0122\n",
      "Recent avg loss: 0.0100\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0116\n",
      "Recent avg loss: 0.0140\n",
      "Recent avg loss: 0.0154\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0130\n",
      "Recent avg loss: 0.0103\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0111\n",
      "Recent avg loss: 0.0167\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0112\n",
      "Recent avg loss: 0.0121\n",
      "Recent avg loss: 0.0129\n",
      "Recent avg loss: 0.0125\n",
      "Recent avg loss: 0.0144\n",
      "Recent avg loss: 0.0115\n",
      "Recent avg loss: 0.0146\n",
      "Recent avg loss: 0.0114\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0133\n",
      "Recent avg loss: 0.0150\n",
      "Recent avg loss: 0.0126\n",
      "Recent avg loss: 0.0120\n",
      "Recent avg loss: 0.0149\n",
      "Recent avg loss: 0.0186\n",
      "Recent avg loss: 0.0136\n",
      "Recent avg loss: 0.0134\n",
      "Recent avg loss: 0.0142\n",
      "Recent avg loss: 0.0110\n",
      " Fine-tuning completed successfully!\n",
      "Checking final model weights...\n",
      " Final model weights are clean\n",
      "***** train metrics *****\n",
      "  epoch                    =     2.9992\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =       0.02\n",
      "  train_runtime            = 4:08:08.20\n",
      "  train_samples_per_second =      6.245\n",
      "  train_steps_per_second   =       0.39\n",
      "\n",
      " Training Results:\n",
      "- Training loss: 0.0200\n",
      "- Training runtime: 14888.20 seconds\n",
      "- Samples per second: 6.25\n"
     ]
    }
   ],
   "source": [
    "# 10. Start Fine-tuning with Custom Loss\n",
    "print(\"Starting fine-tuning with custom loss...\")\n",
    "print(\"Enhanced setup should prevent DataParallel issues...\")\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"CUDA cache cleared\")\n",
    "\n",
    "# Enhanced model weight check\n",
    "def check_model_weights(model):\n",
    "    \"\"\"Check if model has NaN or Inf weights\"\"\"\n",
    "    nan_count = 0\n",
    "    inf_count = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if torch.isnan(param).any():\n",
    "            print(f\"WARNING: Found NaN in {name}\")\n",
    "            nan_count += 1\n",
    "        if torch.isinf(param).any():\n",
    "            print(f\"WARNING: Found Inf in {name}\")\n",
    "            inf_count += 1\n",
    "    return nan_count == 0 and inf_count == 0\n",
    "\n",
    "# Pre-training diagnostics\n",
    "print(\"Pre-training diagnostics:\")\n",
    "print(f\"- Model device: {next(model.parameters()).device}\")\n",
    "print(f\"- Model type: {type(model)}\")\n",
    "print(f\"- Is DataParallel: {isinstance(model, torch.nn.DataParallel)}\")\n",
    "print(f\"- Quantization: {USE_QUANTIZATION}\")\n",
    "print(f\"- CUDA devices: {torch.cuda.device_count()}\")\n",
    "print(f\"- Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"- Validation dataset size: {len(val_dataset)}\")\n",
    "\n",
    "# Verify no DataParallel wrapping occurred\n",
    "if isinstance(model, torch.nn.DataParallel):\n",
    "    print(\" CRITICAL: Model is wrapped in DataParallel despite preventive measures!\")\n",
    "    print(\"Attempting to unwrap...\")\n",
    "    model = model.module\n",
    "    print(f\"Model unwrapped. New type: {type(model)}\")\n",
    "\n",
    "print(\"Checking initial model weights...\")\n",
    "if not check_model_weights(model):\n",
    "    print(\" Model has NaN/Inf weights before training!\")\n",
    "    # Try to fix by reinitializing problematic weights\n",
    "    for name, param in model.named_parameters():\n",
    "        if torch.isnan(param).any() or torch.isinf(param).any():\n",
    "            print(f\"Reinitializing {name}\")\n",
    "            torch.nn.init.normal_(param, std=0.02)\n",
    "else:\n",
    "    print(\" Model weights are clean\")\n",
    "\n",
    "# Print memory usage\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory - Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU Memory - Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "# Additional check for trainer model\n",
    "if hasattr(trainer, 'model'):\n",
    "    if isinstance(trainer.model, torch.nn.DataParallel):\n",
    "        print(\" CRITICAL: Trainer model is DataParallel! Unwrapping...\")\n",
    "        trainer.model = trainer.model.module\n",
    "    print(f\"Trainer model device: {next(trainer.model.parameters()).device}\")\n",
    "    print(f\"Trainer model type: {type(trainer.model)}\")\n",
    "\n",
    "try:\n",
    "    print(\"\\n Calling trainer.train()...\")\n",
    "    train_result = trainer.train()\n",
    "    print(\" Fine-tuning completed successfully!\")\n",
    "    \n",
    "    # Check weights after training\n",
    "    print(\"Checking final model weights...\")\n",
    "    if not check_model_weights(model):\n",
    "        print(\" WARNING: Model has NaN/Inf weights after training!\")\n",
    "    else:\n",
    "        print(\" Final model weights are clean\")\n",
    "    \n",
    "    metrics = train_result.metrics\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    \n",
    "    print(f\"\\n Training Results:\")\n",
    "    print(f\"- Training loss: {train_result.training_loss:.4f}\")\n",
    "    print(f\"- Training runtime: {train_result.metrics['train_runtime']:.2f} seconds\")\n",
    "    if 'train_samples_per_second' in train_result.metrics:\n",
    "        print(f\"- Samples per second: {train_result.metrics['train_samples_per_second']:.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Enhanced debug info\n",
    "    print(f\"\\n Debug information:\")\n",
    "    print(f\"- Model device: {next(model.parameters()).device}\")\n",
    "    print(f\"- Model type: {type(model)}\")\n",
    "    print(f\"- Is DataParallel: {isinstance(model, torch.nn.DataParallel)}\")\n",
    "    print(f\"- Dataset length: {len(train_dataset)}\")\n",
    "    print(f\"- Quantization: {USE_QUANTIZATION}\")\n",
    "    print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"- GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "        print(f\"- GPU Count: {torch.cuda.device_count()}\")\n",
    "        \n",
    "    # Check if this is the StopIteration error\n",
    "    if \"StopIteration\" in str(e):\n",
    "        print(\"\\n StopIteration error detected - this is the DataParallel issue!\")\n",
    "        print(\"Possible causes:\")\n",
    "        print(\"1. Model was wrapped in DataParallel despite preventive measures\")\n",
    "        print(\"2. Quantization configuration failed\")\n",
    "        print(\"3. Device placement issues\")\n",
    "        \n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f66306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:49:27.232680Z",
     "iopub.status.busy": "2025-06-22T16:49:27.232409Z",
     "iopub.status.idle": "2025-06-22T16:49:27.324579Z",
     "shell.execute_reply": "2025-06-22T16:49:27.324020Z",
     "shell.execute_reply.started": "2025-06-22T16:49:27.232652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the fine-tuned T5 classification model...\n",
      "LoRA adapters saved to /kaggle/working/\n",
      "Best T5 classification model saved to /kaggle/working/final_best_model\n",
      "Comprehensive training configuration saved.\n",
      "Label mapping saved.\n",
      "\n",
      "GPU Memory Usage Summary:\n",
      "Allocated: 0.45 GB\n",
      "Cached: 6.29 GB\n",
      "\n",
      "✅ T5ForClassification model training and saving completed!\n",
      "📁 Model saved to: /kaggle/working/final_best_model\n",
      "🏷️ Labels: toxic, severe_toxic, obscene, threat, insult, identity_hate\n",
      "📊 Training data: 30,994 samples (subsampled: True)\n",
      "🔧 LoRA: True, Quantization: True\n",
      "📏 Max sequence length: 512 tokens\n"
     ]
    }
   ],
   "source": [
    "# 11. Save the Fine-tuned T5 Classification Model\n",
    "print(\"Saving the fine-tuned T5 classification model...\")\n",
    "\n",
    "if USE_LORA:\n",
    "    # Save LoRA adapters\n",
    "    model.save_pretrained(OUTPUT_DIR)\n",
    "    print(f\"LoRA adapters saved to {OUTPUT_DIR}\")\n",
    "    \n",
    "    # Save additional T5 classification model info\n",
    "    base_model_info = {\n",
    "        \"base_model\": MODEL_NAME,\n",
    "        \"model_type\": \"T5ForClassification\",\n",
    "        \"architecture\": \"flan-t5-base-classification\",\n",
    "        \"use_lora\": USE_LORA,\n",
    "        \"hidden_size\": model.hidden_size,\n",
    "        \"num_labels\": num_labels,\n",
    "        \"label_columns\": LABEL_COLUMNS,\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "        \"training_subsample_fraction\": TRAINING_SUBSAMPLE_FRACTION if USE_TRAINING_SUBSAMPLING else 1.0\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(f\"{OUTPUT_DIR}/adapter_config.json\", \"r\") as f:\n",
    "        adapter_config = json.load(f)\n",
    "    \n",
    "    adapter_config.update(base_model_info)\n",
    "    \n",
    "    with open(f\"{OUTPUT_DIR}/adapter_config.json\", \"w\") as f:\n",
    "        json.dump(adapter_config, f, indent=2)\n",
    "        \n",
    "else:\n",
    "    # Save full model if not using LoRA\n",
    "    trainer.save_model()\n",
    "    print(f\"Full model saved to {OUTPUT_DIR}\")\n",
    "\n",
    "# Save the best model in a separate directory\n",
    "final_model_path = os.path.join(OUTPUT_DIR, \"final_best_model\")\n",
    "os.makedirs(final_model_path, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "if hasattr(model, 'save_pretrained'):\n",
    "    if USE_LORA:\n",
    "        # For LoRA models, save the PEFT model\n",
    "        model.save_pretrained(final_model_path)\n",
    "    else:\n",
    "        # For full models, use our custom save method\n",
    "        if hasattr(model, 'encoder'):\n",
    "            # This is our T5ForClassification model\n",
    "            model.save_pretrained(final_model_path)\n",
    "        else:\n",
    "            # Fallback to trainer save\n",
    "            trainer.save_model(final_model_path)\n",
    "else:\n",
    "    trainer.save_model(final_model_path)\n",
    "\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "print(f\"Best T5 classification model saved to {final_model_path}\")\n",
    "\n",
    "# Save comprehensive training configuration\n",
    "config_info = {\n",
    "    \"model_info\": {\n",
    "        \"base_model\": MODEL_NAME,\n",
    "        \"model_type\": \"T5ForClassification\",\n",
    "        \"architecture\": \"flan-t5-base-encoder-classification-head\",\n",
    "        \"hidden_size\": model.hidden_size if hasattr(model, 'hidden_size') else 768,\n",
    "        \"num_labels\": NUM_LABELS,\n",
    "        \"label_columns\": LABEL_COLUMNS,\n",
    "        \"max_length\": MAX_LENGTH\n",
    "    },\n",
    "    \"training_info\": {\n",
    "        \"use_lora\": USE_LORA,\n",
    "        \"lora_config\": {\n",
    "            \"r\": LORA_R,\n",
    "            \"alpha\": LORA_ALPHA,\n",
    "            \"dropout\": LORA_DROPOUT,\n",
    "            \"target_modules\": LORA_TARGET_MODULES\n",
    "        } if USE_LORA else None,\n",
    "        \"training_args\": {\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"gradient_accumulation_steps\": training_args.gradient_accumulation_steps,\n",
    "            \"effective_batch_size\": BATCH_SIZE * training_args.gradient_accumulation_steps,\n",
    "            \"num_epochs\": NUM_EPOCHS,\n",
    "            \"warmup_steps\": WARMUP_STEPS,\n",
    "            \"weight_decay\": WEIGHT_DECAY,\n",
    "            \"max_grad_norm\": training_args.max_grad_norm,\n",
    "            \"lr_scheduler_type\": training_args.lr_scheduler_type\n",
    "        },\n",
    "        \"data_info\": {\n",
    "            \"use_training_subsampling\": USE_TRAINING_SUBSAMPLING,\n",
    "            \"training_subsample_fraction\": TRAINING_SUBSAMPLE_FRACTION if USE_TRAINING_SUBSAMPLING else 1.0,\n",
    "            \"final_training_samples\": len(train_texts_split),\n",
    "            \"validation_samples\": len(val_texts),\n",
    "            \"test_samples\": len(test_texts)\n",
    "        }\n",
    "    },\n",
    "    \"performance_info\": {\n",
    "        \"quantization_used\": USE_QUANTIZATION,\n",
    "        \"gradient_checkpointing\": training_args.gradient_checkpointing,\n",
    "        \"mixed_precision\": {\n",
    "            \"fp16\": training_args.fp16,\n",
    "            \"bf16\": training_args.bf16\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/training_config.json\", \"w\") as f:\n",
    "    json.dump(config_info, f, indent=2)\n",
    "\n",
    "print(\"Comprehensive training configuration saved.\")\n",
    "\n",
    "# Save label mapping for future reference\n",
    "label_mapping = {i: label for i, label in enumerate(LABEL_COLUMNS)}\n",
    "with open(f\"{OUTPUT_DIR}/label_mapping.json\", \"w\") as f:\n",
    "    json.dump(label_mapping, f, indent=2)\n",
    "print(\"Label mapping saved.\")\n",
    "\n",
    "# Print memory usage summary\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nGPU Memory Usage Summary:\")\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "    \n",
    "print(f\"\\n✅ T5ForClassification model training and saving completed!\")\n",
    "print(f\"📁 Model saved to: {final_model_path}\")\n",
    "print(f\"🏷️ Labels: {', '.join(LABEL_COLUMNS)}\")\n",
    "print(f\"📊 Training data: {len(train_texts_split):,} samples (subsampled: {USE_TRAINING_SUBSAMPLING})\")\n",
    "print(f\"🔧 LoRA: {USE_LORA}, Quantization: {USE_QUANTIZATION}\")\n",
    "print(f\"📏 Max sequence length: {MAX_LENGTH} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87881d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:50:06.779993Z",
     "iopub.status.busy": "2025-06-22T16:50:06.779285Z",
     "iopub.status.idle": "2025-06-22T16:50:07.122023Z",
     "shell.execute_reply": "2025-06-22T16:50:07.121279Z",
     "shell.execute_reply.started": "2025-06-22T16:50:06.779970Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Model type: T5ForClassification with 768 hidden dimensions\n",
      "\n",
      "================================================================================\n",
      "EXAMPLE PREDICTIONS WITH FLAN-T5-BASE CLASSIFICATION MODEL\n",
      "================================================================================\n",
      "Using T5 encoder with 512 token context window for better understanding\n",
      "\n",
      "[1] Text: 'This is a great article, thank you for sharing!'\n",
      "------------------------------------------------------------\n",
      "Toxic          : 0.0534 (LOW confidence: HIGH)\n",
      "Severe Toxic   : 0.1778 (LOW confidence: HIGH)\n",
      "Obscene        : 0.0415 (LOW confidence: HIGH)\n",
      "Threat         : 0.3311 (LOW confidence: MED)\n",
      "Insult         : 0.0311 (LOW confidence: HIGH)\n",
      "Identity Hate  : 0.2365 (LOW confidence: HIGH)\n",
      "Overall Toxic  : NO (max prob: 0.3311)\n",
      "\n",
      "[2] Text: 'You are an absolute idiot and should shut up'\n",
      "------------------------------------------------------------\n",
      "Toxic          : 0.9124 (HIGH confidence: HIGH)\n",
      "Severe Toxic   : 0.4647 (LOW confidence: MED)\n",
      "Obscene        : 0.7326 (HIGH confidence: HIGH)\n",
      "Threat         : 0.4647 (LOW confidence: MED)\n",
      "Insult         : 0.6868 (HIGH confidence: MED)\n",
      "Identity Hate  : 0.4800 (LOW confidence: MED)\n",
      "Overall Toxic  : YES (max prob: 0.9124)\n",
      "\n",
      "[3] Text: 'I disagree with your opinion but respect your right to have it'\n",
      "------------------------------------------------------------\n",
      "Toxic          : 0.0460 (LOW confidence: HIGH)\n",
      "Severe Toxic   : 0.1571 (LOW confidence: HIGH)\n",
      "Obscene        : 0.0248 (LOW confidence: HIGH)\n",
      "Threat         : 0.3242 (LOW confidence: MED)\n",
      "Insult         : 0.0206 (LOW confidence: HIGH)\n",
      "Identity Hate  : 0.2187 (LOW confidence: HIGH)\n",
      "Overall Toxic  : NO (max prob: 0.3242)\n",
      "\n",
      "[4] Text: 'This content is inappropriate and offensive'\n",
      "------------------------------------------------------------\n",
      "Toxic          : 0.3242 (LOW confidence: MED)\n",
      "Severe Toxic   : 0.2846 (LOW confidence: HIGH)\n",
      "Obscene        : 0.0827 (LOW confidence: HIGH)\n",
      "Threat         : 0.4258 (LOW confidence: MED)\n",
      "Insult         : 0.1251 (LOW confidence: HIGH)\n",
      "Identity Hate  : 0.3757 (LOW confidence: MED)\n",
      "Overall Toxic  : NO (max prob: 0.4258)\n",
      "\n",
      "[5] Text: 'The discussion could benefit from more constructive dialogue'\n",
      "------------------------------------------------------------\n",
      "Toxic          : 0.0402 (LOW confidence: HIGH)\n",
      "Severe Toxic   : 0.1541 (LOW confidence: HIGH)\n",
      "Obscene        : 0.0264 (LOW confidence: HIGH)\n",
      "Threat         : 0.3208 (LOW confidence: MED)\n",
      "Insult         : 0.0210 (LOW confidence: HIGH)\n",
      "Identity Hate  : 0.2147 (LOW confidence: HIGH)\n",
      "Overall Toxic  : NO (max prob: 0.3208)\n",
      "\n",
      "[6] Text: 'What a stupid waste of time, you morons don't understand anything'\n",
      "------------------------------------------------------------\n",
      "Toxic          : 0.7564 (HIGH confidence: HIGH)\n",
      "Severe Toxic   : 0.4116 (LOW confidence: MED)\n",
      "Obscene        : 0.5494 (HIGH confidence: MED)\n",
      "Threat         : 0.4410 (LOW confidence: MED)\n",
      "Insult         : 0.5605 (HIGH confidence: MED)\n",
      "Identity Hate  : 0.4576 (LOW confidence: MED)\n",
      "Overall Toxic  : YES (max prob: 0.7564)\n",
      "\n",
      "================================================================================\n",
      "T5 Classification Model Inference Complete\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#  Checking Inference with Fine-Tuned T5 Classification Model\n",
    "def predict_toxicity(text, model, tokenizer, device, max_length=512):\n",
    "    \"\"\"Predict toxicity for a single text using T5 classification model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize the input\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Define device based on model location\n",
    "device = next(model.parameters()).device\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Model type: T5ForClassification with {model.hidden_size} hidden dimensions\")\n",
    "\n",
    "# Test with example texts\n",
    "example_texts = [\n",
    "    \"This is a great article, thank you for sharing!\",\n",
    "    \"You are an absolute idiot and should shut up\",\n",
    "    \"I disagree with your opinion but respect your right to have it\",\n",
    "    \"This content is inappropriate and offensive\",\n",
    "    \"The discussion could benefit from more constructive dialogue\",\n",
    "    \"What a stupid waste of time, you morons don't understand anything\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE PREDICTIONS WITH FLAN-T5-BASE CLASSIFICATION MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Using T5 encoder with {MAX_LENGTH} token context window for better understanding\")\n",
    "\n",
    "for i, text in enumerate(example_texts, 1):\n",
    "    predictions = predict_toxicity(text, model, tokenizer, device, MAX_LENGTH)\n",
    "    \n",
    "    print(f\"\\n[{i}] Text: '{text}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for j, (label, prob) in enumerate(zip(LABEL_COLUMNS, predictions)):\n",
    "        status = \"HIGH\" if prob > 0.5 else \"LOW\"\n",
    "        confidence = \"HIGH\" if prob > 0.7 or prob < 0.3 else \"MED\"\n",
    "        print(f\"{label.replace('_', ' ').title():<15}: {prob:.4f} ({status} confidence: {confidence})\")\n",
    "    \n",
    "    # Overall toxicity (any label > 0.5)\n",
    "    is_toxic = any(p > 0.5 for p in predictions)\n",
    "    max_prob = max(predictions)\n",
    "    print(f\"{'Overall Toxic':<15}: {'YES' if is_toxic else 'NO'} (max prob: {max_prob:.4f})\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"T5 Classification Model Inference Complete\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39648599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T16:50:31.857372Z",
     "iopub.status.busy": "2025-06-22T16:50:31.856805Z",
     "iopub.status.idle": "2025-06-22T17:02:36.600801Z",
     "shell.execute_reply": "2025-06-22T17:02:36.599900Z",
     "shell.execute_reply.started": "2025-06-22T16:50:31.857351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on test set...\n",
      "Conditions for subsampling not met (PERFORM_SUBSAMPLING is False). Using original test data.\n",
      "Running trainer.predict() on dataset with 23936 samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated binary predictions for 23936 test samples.\n",
      "Binary test predictions saved to /kaggle/working//test_predictions_binary.csv\n",
      "\n",
      "Sample binary test predictions:\n",
      "                      id  toxic  severe_toxic  obscene  threat  insult  \\\n",
      "113679  5fe3e9df100f9d54      0             0        0       0       0   \n",
      "25142   4288e3b72823f9b2      0             0        0       0       0   \n",
      "17119   2d2569262e327ae9      0             0        0       0       0   \n",
      "149109  573f80324d6e4bd6      0             0        0       0       0   \n",
      "36061   6059872a7363cf0d      0             0        0       0       0   \n",
      "32670   56f5c83e7c08697f      0             0        0       0       0   \n",
      "155136  b9737bbbff95ee9a      0             0        0       0       0   \n",
      "82451   dc9a40c60d910bc3      0             0        0       0       0   \n",
      "124870  9c0ffc661eacdf5b      0             0        0       0       0   \n",
      "37016   62d7f8ee3cfe5f21      0             0        0       0       0   \n",
      "\n",
      "        identity_hate  \n",
      "113679              0  \n",
      "25142               0  \n",
      "17119               0  \n",
      "149109              0  \n",
      "36061               0  \n",
      "32670               0  \n",
      "155136              0  \n",
      "82451               0  \n",
      "124870              0  \n",
      "37016               0  \n"
     ]
    }
   ],
   "source": [
    "# Generate Predictions on Test Set (with proper binary format)\n",
    "print(\"Generating predictions on test set...\")\n",
    "\n",
    "SUBSAMPLE_FRACTION = 0.1\n",
    "PERFORM_SUBSAMPLING = False  # Set to False to use the full test dataset\n",
    "PREDICTION_THRESHOLD = 0.5  # Define threshold for binary predictions\n",
    "\n",
    "# Store original lengths for logging\n",
    "num_original_test_texts = 0\n",
    "if 'test_texts' in globals() and isinstance(test_texts, list):\n",
    "    num_original_test_texts = len(test_texts)\n",
    "else:\n",
    "    print(\"Error: Global 'test_texts' not found or not a list. Cannot proceed with subsampling or prediction.\")\n",
    "    PERFORM_SUBSAMPLING = False\n",
    "    dataset_to_predict_on = None\n",
    "\n",
    "# Variables to hold the data that will actually be used\n",
    "active_test_texts = globals().get('test_texts')\n",
    "active_test_labels = globals().get('test_labels')  # This might be None\n",
    "active_test_df = globals().get('test_df')  # This will be reloaded if subsampling\n",
    "\n",
    "# This will be the dataset object passed to trainer.predict()\n",
    "dataset_to_predict_on = globals().get('test_dataset')\n",
    "# This will store the PredictionOutput object\n",
    "final_test_predictions = None\n",
    "# These will store the processed predictions\n",
    "final_test_probs = np.array([])\n",
    "final_test_preds = np.array([])\n",
    "\n",
    "if PERFORM_SUBSAMPLING and num_original_test_texts > 0:\n",
    "    sample_size = int(num_original_test_texts * SUBSAMPLE_FRACTION)\n",
    "    \n",
    "    if sample_size == 0 and num_original_test_texts > 0:\n",
    "        sample_size = 1  # Ensure at least 1 sample\n",
    "    \n",
    "    if sample_size > 0 and sample_size < num_original_test_texts:\n",
    "        print(f\"Original number of test samples (from global test_texts): {num_original_test_texts}\")\n",
    "        print(f\"Subsampling to {sample_size} (approx {SUBSAMPLE_FRACTION*100:.1f}%) test samples for prediction and evaluation.\")\n",
    "        \n",
    "        indices = np.random.choice(num_original_test_texts, size=sample_size, replace=False)\n",
    "        indices = np.sort(indices)\n",
    "\n",
    "        active_test_texts = [test_texts[i] for i in indices]\n",
    "        \n",
    "        if 'test_labels' in globals() and test_labels is not None:\n",
    "            if (isinstance(test_labels, np.ndarray) or isinstance(test_labels, list)) and len(test_labels) == num_original_test_texts:\n",
    "                if isinstance(test_labels, np.ndarray):\n",
    "                    active_test_labels = test_labels[indices]\n",
    "                else:\n",
    "                    active_test_labels = [test_labels[i] for i in indices]\n",
    "                globals()['test_labels'] = active_test_labels  # Update global for next cell\n",
    "                print(f\"Global test_labels has been subsampled. New length: {len(globals()['test_labels'])}\")\n",
    "            else:\n",
    "                print(f\"Warning: Original global test_labels could not be reliably subsampled due to length mismatch with original test_texts. Global test_labels may be out of sync.\")\n",
    "        else:\n",
    "            active_test_labels = None\n",
    "            globals()['test_labels'] = None\n",
    "\n",
    "        # Create new HF dataset for subsampled test data\n",
    "        if active_test_labels is not None:\n",
    "            hf_test_data_subsampled = HFDataset.from_dict({ \"text\": active_test_texts, \"labels\": active_test_labels.tolist() })\n",
    "        else:\n",
    "            hf_test_data_subsampled = HFDataset.from_dict({ \"text\": active_test_texts })\n",
    "            \n",
    "        # Tokenize subsampled test data\n",
    "        tokenized_test_dataset_subsampled = hf_test_data_subsampled.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            num_proc=num_proc_to_use,\n",
    "            remove_columns=[\"text\"] if \"text\" in hf_test_data_subsampled.column_names else None\n",
    "        )\n",
    "        \n",
    "        if \"labels\" in tokenized_test_dataset_subsampled.column_names:\n",
    "            tokenized_test_dataset_subsampled.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        else:\n",
    "            tokenized_test_dataset_subsampled.set_format(\"torch\", columns=['input_ids', 'attention_mask'])\n",
    "            \n",
    "        dataset_to_predict_on = tokenized_test_dataset_subsampled\n",
    "        print(f\"Created a new test_dataset with {len(dataset_to_predict_on)} subsampled items.\")\n",
    "        \n",
    "        # Subsample test_df for creating the submission file\n",
    "        try:\n",
    "            original_full_test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "            if TEXT_COLUMN not in original_full_test_df.columns:\n",
    "                print(f\"Error: text_column '{TEXT_COLUMN}' not found in reloaded test_df from {TEST_DATA_PATH}.\")\n",
    "                active_test_df = None\n",
    "            elif len(original_full_test_df) == num_original_test_texts:\n",
    "                active_test_df = original_full_test_df.iloc[indices].reset_index(drop=True)\n",
    "                globals()['test_df'] = active_test_df  # Update global test_df\n",
    "                print(f\"Reloaded and subsampled test_df. New global test_df for submission has {len(globals()['test_df'])} rows.\")\n",
    "            else:\n",
    "                print(f\"Warning: Reloaded test_df from {TEST_DATA_PATH} (length {len(original_full_test_df)}) does not match num_original_test_texts ({num_original_test_texts}).\")\n",
    "                active_test_df = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error reloading or subsampling test_df from {TEST_DATA_PATH}: {e}\")\n",
    "            active_test_df = None\n",
    "    else:\n",
    "        print(\"Subsampling not performed (calculated sample size covers all/no data, or original was empty). Using original test data.\")\n",
    "else:\n",
    "    if num_original_test_texts > 0:\n",
    "        print(\"Conditions for subsampling not met (PERFORM_SUBSAMPLING is False). Using original test data.\")\n",
    "\n",
    "\n",
    "if dataset_to_predict_on is not None and len(dataset_to_predict_on) > 0:\n",
    "    print(f\"Running trainer.predict() on dataset with {len(dataset_to_predict_on)} samples.\")\n",
    "    final_test_predictions = trainer.predict(dataset_to_predict_on)\n",
    "    \n",
    "    if final_test_predictions is not None and final_test_predictions.predictions is not None:\n",
    "        # The predictions should already be binary from our custom prediction_step\n",
    "        final_test_preds = final_test_predictions.predictions.astype(int)\n",
    "        \n",
    "        # Also calculate probabilities for AUC and other probability-based metrics\n",
    "        print(f\"Generated binary predictions for {len(final_test_preds)} test samples.\")\n",
    "        globals()['test_predictions'] = final_test_predictions\n",
    "    else:\n",
    "        print(\"trainer.predict() did not return valid predictions.\")\n",
    "        globals()['test_predictions'] = None\n",
    "else:\n",
    "    print(\"Test dataset for prediction is empty or None. Skipping prediction.\")\n",
    "    globals()['test_predictions'] = None\n",
    "\n",
    "# Create submission with binary predictions\n",
    "if active_test_df is not None and not active_test_df.empty and 'id' in active_test_df.columns and len(final_test_preds) > 0:\n",
    "    if len(active_test_df) == len(final_test_preds):\n",
    "        submission_df = active_test_df[['id']].copy()\n",
    "        for i, label in enumerate(LABEL_COLUMNS):\n",
    "            submission_df[label] = final_test_preds[:, i].astype(int)  # Ensure integer format\n",
    "\n",
    "        was_effectively_subsampled = (PERFORM_SUBSAMPLING and \n",
    "                                      num_original_test_texts > 0 and\n",
    "                                      'sample_size' in locals() and sample_size > 0 and \n",
    "                                      sample_size < num_original_test_texts)\n",
    "                                      \n",
    "        submission_filename = f\"{OUTPUT_DIR}/test_predictions_binary.csv\" if not was_effectively_subsampled else f\"{OUTPUT_DIR}/test_predictions_binary_subsampled.csv\"\n",
    "        \n",
    "        submission_df.to_csv(submission_filename, index=False)\n",
    "        print(f\"Binary test predictions saved to {submission_filename}\")\n",
    "        print(\"\\nSample binary test predictions:\")\n",
    "        print(submission_df.head(10))\n",
    "    else:\n",
    "        print(f\"Warning: Length mismatch between active_test_df for submission ({len(active_test_df)}) and generated final_test_preds ({len(final_test_preds)}). Cannot create submission file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173996a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:07:31.625190Z",
     "iopub.status.busy": "2025-06-22T17:07:31.624908Z",
     "iopub.status.idle": "2025-06-22T17:07:31.966239Z",
     "shell.execute_reply": "2025-06-22T17:07:31.965442Z",
     "shell.execute_reply.started": "2025-06-22T17:07:31.625170Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL EVALUATION: FLAN-T5-BASE CLASSIFICATION MODEL\n",
      "================================================================================\n",
      "Model: google/flan-t5-base with custom classification head\n",
      "Architecture: T5 Encoder + Classification Head (Hidden Size: 768)\n",
      "Training Data: 30,994 samples (Subsampled: True)\n",
      "Max Sequence Length: 512 tokens\n",
      "LoRA: True, Quantization: True\n",
      "\n",
      " Loading test set with labels from: /kaggle/working//test_split_with_labels.csv\n",
      "✓ Test set with labels loaded: (23936, 9)\n",
      " Loading binary predictions from: /kaggle/working//test_predictions_binary.csv\n",
      "✓ Binary predictions loaded: (23936, 7)\n",
      "\n",
      " Evaluation Data Summary:\n",
      "- Test samples: 23,936\n",
      "- Labels: 6 (toxic, severe_toxic, obscene, threat, insult, identity_hate)\n",
      "- Predictions are binary: True\n",
      "- Labels are binary: True\n",
      "\n",
      "================================================================================\n",
      "FLAN-T5-BASE CLASSIFICATION RESULTS\n",
      "================================================================================\n",
      "\n",
      " Per-Label Performance:\n",
      "--------------------------------------------------------------------------------\n",
      "Label           Precision  Recall     F1-Score   Accuracy   Support   \n",
      "--------------------------------------------------------------------------------\n",
      "Toxic           0.792      0.844      0.817      0.964      2294      \n",
      "Severe Toxic    0.318      0.847      0.462      0.981      229       \n",
      "Obscene         0.759      0.878      0.814      0.979      1279      \n",
      "Threat          0.204      0.250      0.225      0.995      76        \n",
      "Insult          0.659      0.825      0.733      0.970      1186      \n",
      "Identity Hate   0.287      0.614      0.391      0.983      215       \n",
      "\n",
      " AGGREGATE PERFORMANCE METRICS:\n",
      "------------------------------------------------------------\n",
      "Macro Average     : P=0.503 R=0.710 F1=0.574\n",
      "Micro Average     : P=0.979 R=0.979 F1=0.979\n",
      "Exact Match Acc   : 0.909\n",
      "Mean Label Acc    : 0.979\n",
      "Hamming Loss      : 0.021\n",
      "\n",
      " MODEL PERFORMANCE ANALYSIS:\n",
      "------------------------------------------------------------\n",
      "FLAN-T5-base Classification Head Approach:\n",
      "- Macro F1 Score: 0.574\n",
      "- Exact Match Accuracy: 0.909\n",
      "- Mean Label Accuracy: 0.979\n",
      "- Benefits from 512 token context window\n",
      "- Efficient training with 30,994 samples\n",
      "- Parameter-efficient with LoRA: True\n",
      "\n",
      " FLAN-T5-base evaluation completed successfully!\n",
      " Best Metric - Macro F1: 0.574\n",
      " Evaluated on 23,936 test samples\n",
      " Training time: Reduced with 20.0% subsample\n",
      "\n",
      "================================================================================\n",
      "FLAN-T5-BASE TOXIC COMMENT CLASSIFICATION - COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Split Test Set with Ground Truth Labels\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EVALUATION: FLAN-T5-BASE CLASSIFICATION MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {MODEL_NAME} with custom classification head\")\n",
    "print(f\"Architecture: T5 Encoder + Classification Head (Hidden Size: {model.hidden_size})\")\n",
    "print(f\"Training Data: {len(train_texts_split):,} samples (Subsampled: {USE_TRAINING_SUBSAMPLING})\")\n",
    "print(f\"Max Sequence Length: {MAX_LENGTH} tokens\")\n",
    "print(f\"LoRA: {USE_LORA}, Quantization: {USE_QUANTIZATION}\")\n",
    "\n",
    "# Load the test set with labels for evaluation\n",
    "print(f\"\\n Loading test set with labels from: {TEST_WITH_LABELS_PATH}\")\n",
    "test_with_labels_df = pd.read_csv(TEST_WITH_LABELS_PATH)\n",
    "print(f\"✓ Test set with labels loaded: {test_with_labels_df.shape}\")\n",
    "\n",
    "# Load binary predictions\n",
    "predictions_file_path = f\"{OUTPUT_DIR}/test_predictions_binary.csv\"\n",
    "\n",
    "if os.path.exists(predictions_file_path):\n",
    "    print(f\" Loading binary predictions from: {predictions_file_path}\")\n",
    "    pred_df = pd.read_csv(predictions_file_path)\n",
    "    print(f\"✓ Binary predictions loaded: {pred_df.shape}\")\n",
    "    \n",
    "    # Ensure both datasets have the same length and order\n",
    "    if len(test_with_labels_df) == len(pred_df):\n",
    "        # Extract true labels and binary predictions\n",
    "        y_true = test_with_labels_df[LABEL_COLUMNS].values.astype(int)\n",
    "        y_pred_binary = pred_df[LABEL_COLUMNS].values.astype(int)\n",
    "        \n",
    "        print(f\"\\n Evaluation Data Summary:\")\n",
    "        print(f\"- Test samples: {y_true.shape[0]:,}\")\n",
    "        print(f\"- Labels: {y_true.shape[1]} ({', '.join(LABEL_COLUMNS)})\")\n",
    "        print(f\"- Predictions are binary: {np.all(np.isin(y_pred_binary, [0, 1]))}\")\n",
    "        print(f\"- Labels are binary: {np.all(np.isin(y_true, [0, 1]))}\")\n",
    "        \n",
    "        # Calculate comprehensive metrics\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FLAN-T5-BASE CLASSIFICATION RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Per-label metrics\n",
    "        print(\"\\n Per-Label Performance:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Label':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Accuracy':<10} {'Support':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        label_results = []\n",
    "        for i, label in enumerate(LABEL_COLUMNS):\n",
    "            true_labels = y_true[:, i]\n",
    "            pred_labels = y_pred_binary[:, i]\n",
    "            \n",
    "            # Basic metrics\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                true_labels, pred_labels, average='binary', zero_division=0\n",
    "            )\n",
    "            \n",
    "            # Accuracy for this label\n",
    "            accuracy = np.mean(true_labels == pred_labels)\n",
    "            \n",
    "            # Support\n",
    "            support = np.sum(true_labels)\n",
    "            \n",
    "            label_results.append({\n",
    "                'label': label,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'accuracy': accuracy,\n",
    "                'support': support\n",
    "            })\n",
    "            \n",
    "            print(f\"{label.replace('_', ' ').title():<15} {precision:<10.3f} {recall:<10.3f} {f1:<10.3f} {accuracy:<10.3f} {support:<10}\")\n",
    "        \n",
    "        # Aggregate metrics\n",
    "        print(f\"\\n AGGREGATE PERFORMANCE METRICS:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Macro averages\n",
    "        macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred_binary, average='macro', zero_division=0\n",
    "        )\n",
    "        \n",
    "        # Micro averages\n",
    "        micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "            y_true.flatten(), y_pred_binary.flatten(), average='micro', zero_division=0\n",
    "        )\n",
    "        \n",
    "        # Exact match accuracy (all labels must be correct)\n",
    "        exact_match = np.mean(np.all(y_pred_binary == y_true, axis=1))\n",
    "        \n",
    "        # Hamming loss\n",
    "        hamming_loss = np.mean(y_pred_binary != y_true)\n",
    "        \n",
    "        # Label-wise accuracy\n",
    "        label_accuracies = [np.mean(y_true[:, i] == y_pred_binary[:, i]) for i in range(len(LABEL_COLUMNS))]\n",
    "        mean_label_accuracy = np.mean(label_accuracies)\n",
    "        \n",
    "        print(f\"Macro Average     : P={macro_precision:.3f} R={macro_recall:.3f} F1={macro_f1:.3f}\")\n",
    "        print(f\"Micro Average     : P={micro_precision:.3f} R={micro_recall:.3f} F1={micro_f1:.3f}\")\n",
    "        print(f\"Exact Match Acc   : {exact_match:.3f}\")\n",
    "        print(f\"Mean Label Acc    : {mean_label_accuracy:.3f}\")\n",
    "        print(f\"Hamming Loss      : {hamming_loss:.3f}\")\n",
    "        \n",
    "        # Model comparison note\n",
    "        print(f\"\\n MODEL PERFORMANCE ANALYSIS:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"FLAN-T5-base Classification Head Approach:\")\n",
    "        print(f\"- Macro F1 Score: {macro_f1:.3f}\")\n",
    "        print(f\"- Exact Match Accuracy: {exact_match:.3f}\")\n",
    "        print(f\"- Mean Label Accuracy: {mean_label_accuracy:.3f}\")\n",
    "        print(f\"- Benefits from {MAX_LENGTH} token context window\")\n",
    "        print(f\"- Efficient training with {len(train_texts_split):,} samples\")\n",
    "        print(f\"- Parameter-efficient with LoRA: {USE_LORA}\")\n",
    "        \n",
    "        \n",
    "        print(f\"\\n FLAN-T5-base evaluation completed successfully!\")\n",
    "        print(f\" Best Metric - Macro F1: {macro_f1:.3f}\")\n",
    "        print(f\" Evaluated on {len(y_true):,} test samples\")\n",
    "        print(f\" Training time: Reduced with {TRAINING_SUBSAMPLE_FRACTION*100}% subsample\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Length mismatch: Test labels ({len(test_with_labels_df)}) vs Predictions ({len(pred_df)})\")\n",
    "else:\n",
    "    print(f\"Binary predictions file not found: {predictions_file_path}\")\n",
    "    print(\"Please ensure the model training and prediction steps completed successfully.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FLAN-T5-BASE TOXIC COMMENT CLASSIFICATION - COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7694410,
     "sourceId": 12213892,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
