{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Models for Toxic Comment Classification\n",
    "\n",
    "This notebook implements and evaluates various transformer architectures (BERT, RoBERTa, DistilBERT) for the toxic comment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW  \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Transformers libraries\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification, \n",
    "    get_linear_schedule_with_warmup,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForSequenceClassification\n",
    ")\n",
    "\n",
    "# Set random seeds\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (159571, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>original_length</th>\n",
       "      <th>processed_length</th>\n",
       "      <th>length_reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made my username hardcore me...</td>\n",
       "      <td>264</td>\n",
       "      <td>202</td>\n",
       "      <td>23.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww ! he match background colour im seemingly...</td>\n",
       "      <td>112</td>\n",
       "      <td>86</td>\n",
       "      <td>23.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , im really not trying edit war . guy ...</td>\n",
       "      <td>233</td>\n",
       "      <td>165</td>\n",
       "      <td>29.184549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i cant make real suggestion improvement i wond...</td>\n",
       "      <td>622</td>\n",
       "      <td>406</td>\n",
       "      <td>34.726688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you , sir , my hero . chance you remember page...</td>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "      <td>19.402985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                      processed_text  original_length  \\\n",
       "0  explanation edits made my username hardcore me...              264   \n",
       "1  daww ! he match background colour im seemingly...              112   \n",
       "2  hey man , im really not trying edit war . guy ...              233   \n",
       "3  i cant make real suggestion improvement i wond...              622   \n",
       "4  you , sir , my hero . chance you remember page...               67   \n",
       "\n",
       "   processed_length  length_reduction  \n",
       "0               202         23.484848  \n",
       "1                86         23.214286  \n",
       "2               165         29.184549  \n",
       "3               406         34.726688  \n",
       "4                54         19.402985  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "train_data = pd.read_csv('../Dataset/train_preprocessed.csv')\n",
    "\n",
    "# Check the data\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 127815\n",
      "Validation set size: 15798\n",
      "Test set size: 15958\n"
     ]
    }
   ],
   "source": [
    "# Define the features and target labels\n",
    "X = train_data['processed_text']  # Use the preprocessed text\n",
    "y = train_data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(\"\")  # Replace NaN values with empty strings\n",
    "y = y.fillna(0)   # Replace any missing target values with 0\n",
    "\n",
    "# Split the data into training, validation and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y['toxic']\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.11, random_state=42, stratify=y_temp['toxic']\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled train size: 10000\n",
      "Sampled validation size: 2000\n"
     ]
    }
   ],
   "source": [
    "# For transformers, let's keep only a subset of the data for faster training\n",
    "# Use this for development and debugging, comment out for full training\n",
    "SAMPLE_SIZE = 10000\n",
    "\n",
    "# Sample from train\n",
    "train_indices = np.random.choice(len(X_train), min(SAMPLE_SIZE, len(X_train)), replace=False)\n",
    "X_train_sample = X_train.iloc[train_indices]\n",
    "y_train_sample = y_train.iloc[train_indices]\n",
    "\n",
    "# Sample from validation\n",
    "val_indices = np.random.choice(len(X_val), min(SAMPLE_SIZE // 5, len(X_val)), replace=False)\n",
    "X_val_sample = X_val.iloc[val_indices]\n",
    "y_val_sample = y_val.iloc[val_indices]\n",
    "\n",
    "print(f\"Sampled train size: {len(X_train_sample)}\")\n",
    "print(f\"Sampled validation size: {len(X_val_sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Dataset for Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentDatasetTransformer(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        labels = torch.FloatTensor(self.labels.iloc[idx].values)\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Remove the batch dimension added by the tokenizer\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        # Add labels\n",
    "        encoding['labels'] = labels\n",
    "        \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultiLabelClassification(nn.Module):\n",
    "    def __init__(self, num_labels, model_name=\"bert-base-uncased\", dropout_rate=0.1):\n",
    "        super(BertForMultiLabelClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # Load pre-trained BERT model\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # Use the [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Apply sigmoid activation for multi-label\n",
    "        return torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the AdaptiveFocalLoss class from your RNN notebook\n",
    "class AdaptiveFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, class_gammas=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.class_gammas = class_gammas\n",
    "        self.epsilon = 1e-6\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.clamp(inputs, self.epsilon, 1 - self.epsilon)\n",
    "        \n",
    "        # Binary cross entropy\n",
    "        bce_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        \n",
    "        # Different gamma for each class\n",
    "        focal_loss = torch.zeros_like(bce_loss)\n",
    "        class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "        \n",
    "        for i, col in enumerate(class_names):\n",
    "            gamma = self.class_gammas.get(col, 2.0)  # Default gamma is 2.0\n",
    "            pt = torch.exp(-bce_loss[:, i])\n",
    "            focal_weight = (1 - pt) ** gamma\n",
    "            \n",
    "            # Apply class weights if provided\n",
    "            if self.alpha is not None:\n",
    "                focal_weight = focal_weight * self.alpha[i]\n",
    "                \n",
    "            focal_loss[:, i] = focal_weight * bce_loss[:, i]\n",
    "        \n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [0.09584947 0.00987365 0.05295936 0.0029261  0.04935258 0.00860619]\n",
      "Class weights: [ 0.25350136 10.80143425  0.42619535 62.27626853  0.45209466 11.53722987]\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights based on the training set distribution\n",
    "class_dist = np.array([y_train[col].mean() for col in y_train.columns])\n",
    "print(f\"Class distribution: {class_dist}\")\n",
    "class_weights = 1 / (class_dist + 0.01)  # Add small epsilon to avoid division by zero\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)  # Normalize weights\n",
    "\n",
    "# Adjust class weights for rare classes\n",
    "class_weights[3] *= 30  # Increase weight for threat\n",
    "class_weights[5] *= 8   # Increase weight for identity_hate\n",
    "class_weights[1] *= 8   # Increase weight for severe_toxic\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Define class-specific gamma values for focal loss\n",
    "class_gammas = {\n",
    "    'toxic': 1.0,\n",
    "    'severe_toxic': 1.5, \n",
    "    'obscene': 1.0,\n",
    "    'threat': 1.5,\n",
    "    'insult': 1.0,\n",
    "    'identity_hate': 2.0\n",
    "}\n",
    "\n",
    "# Create the focal loss\n",
    "criterion = AdaptiveFocalLoss(alpha=torch.FloatTensor(class_weights), class_gammas=class_gammas).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        if 'token_type_ids' in batch:\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        else:\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Calculate loss - binary cross entropy for multi-label\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Optimizer and scheduler steps\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    \n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformer(model, data_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            if 'token_type_ids' in batch:\n",
    "                token_type_ids = batch['token_type_ids'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            else:\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = nn.BCELoss()(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Convert outputs to binary predictions\n",
    "            preds = (outputs > threshold).float().cpu().numpy()\n",
    "            true_labels = labels.cpu().numpy()\n",
    "            \n",
    "            all_predictions.append(preds)\n",
    "            all_labels.append(true_labels)\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels.flatten(), all_predictions.flatten())\n",
    "    macro_f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    micro_f1 = f1_score(all_labels, all_predictions, average='micro')\n",
    "    \n",
    "    # Calculate per-class F1\n",
    "    class_f1 = {}\n",
    "    for i, col in enumerate(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']):\n",
    "        class_f1[col] = f1_score(all_labels[:, i], all_predictions[:, i])\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_f1': micro_f1,\n",
    "        'class_f1': class_f1,\n",
    "        'loss': avg_loss,\n",
    "        'predictions': all_predictions,\n",
    "        'true_labels': all_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_model(model, train_loader, val_loader, optimizer, scheduler, device, \n",
    "                           num_epochs=3, patience=2, model_save_path='../models/best_transformer.pt'):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    counter = 0  # For early stopping\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        start_time = time.time()\n",
    "        train_loss = train_transformer_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        val_results = evaluate_transformer(model, val_loader, device)\n",
    "        val_loss = val_results['loss']\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        time_elapsed = time.time() - start_time\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Val F1 Macro: {val_results['macro_f1']:.4f} | \"\n",
    "              f\"Time: {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\")\n",
    "        \n",
    "        # Print class-wise F1 scores\n",
    "        print(\"Class F1 scores:\")\n",
    "        for cls, f1 in val_results['class_f1'].items():\n",
    "            print(f\"  {cls}: {f1:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model with val_loss: {val_loss:.4f}\")\n",
    "            counter = 0  # Reset early stopping counter\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"EarlyStopping counter: {counter} out of {patience}\")\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "                \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BERT Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer and model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertForMultiLabelClassification(num_labels=6, model_name='bert-base-uncased')\n",
    "bert_model.to(device)\n",
    "\n",
    "# Create datasets with the BERT tokenizer\n",
    "train_dataset = ToxicCommentDatasetTransformer(X_train_sample, y_train_sample, bert_tokenizer)\n",
    "val_dataset = ToxicCommentDatasetTransformer(X_val_sample, y_val_sample, bert_tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 16  # Smaller batch size for Transformer models due to memory constraints\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler\n",
    "optimizer = AdamW(bert_model.parameters(), lr=2e-5)\n",
    "\n",
    "# Calculate total steps for scheduler\n",
    "total_steps = len(train_loader) * 3  # 3 epochs\n",
    "warmup_steps = int(total_steps * 0.1)  # 10% of total steps for warmup\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768df1c3c191463c94e13b1bdc4a69fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train BERT model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m bert_train_losses, bert_val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_transformer_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/bert_toxic_classifier.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m, in \u001b[0;36mtrain_transformer_model\u001b[0;34m(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs, patience, model_save_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m     12\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 13\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_transformer_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mtrain_transformer_epoch\u001b[0;34m(model, data_loader, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate loss - binary cross entropy for multi-label\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mAdaptiveFocalLoss.forward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Binary cross entropy\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m bce_loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(inputs, targets, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Different gamma for each class\u001b[39;00m\n\u001b[1;32m     16\u001b[0m focal_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(bce_loss)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "# Train BERT model\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "bert_train_losses, bert_val_losses = train_transformer_model(\n",
    "    bert_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    num_epochs=3,\n",
    "    patience=2,\n",
    "    model_save_path='../models/bert_toxic_classifier.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RoBERTa Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RoBERTa tokenizer and model\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = BertForMultiLabelClassification(num_labels=6, model_name='roberta-base')\n",
    "roberta_model.to(device)\n",
    "\n",
    "# Create datasets with the RoBERTa tokenizer\n",
    "train_dataset_roberta = ToxicCommentDatasetTransformer(X_train_sample, y_train_sample, roberta_tokenizer)\n",
    "val_dataset_roberta = ToxicCommentDatasetTransformer(X_val_sample, y_val_sample, roberta_tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader_roberta = DataLoader(\n",
    "    train_dataset_roberta,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader_roberta = DataLoader(\n",
    "    val_dataset_roberta,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler for RoBERTa\n",
    "optimizer_roberta = AdamW(roberta_model.parameters(), lr=2e-5)\n",
    "scheduler_roberta = get_linear_schedule_with_warmup(\n",
    "    optimizer_roberta,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RoBERTa model\n",
    "roberta_train_losses, roberta_val_losses = train_transformer_model(\n",
    "    roberta_model,\n",
    "    train_loader_roberta,\n",
    "    val_loader_roberta,\n",
    "    optimizer_roberta,\n",
    "    scheduler_roberta,\n",
    "    device,\n",
    "    num_epochs=3,\n",
    "    patience=2,\n",
    "    model_save_path='../models/roberta_toxic_classifier.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DistilBERT Implementation (Faster Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DistilBERT tokenizer and model\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "distilbert_model = BertForMultiLabelClassification(num_labels=6, model_name='distilbert-base-uncased')\n",
    "distilbert_model.to(device)\n",
    "\n",
    "# Create datasets with the DistilBERT tokenizer\n",
    "train_dataset_distilbert = ToxicCommentDatasetTransformer(X_train_sample, y_train_sample, distilbert_tokenizer)\n",
    "val_dataset_distilbert = ToxicCommentDatasetTransformer(X_val_sample, y_val_sample, distilbert_tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader_distilbert = DataLoader(\n",
    "    train_dataset_distilbert,\n",
    "    batch_size=BATCH_SIZE * 2,  # Can use larger batch size with DistilBERT\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader_distilbert = DataLoader(\n",
    "    val_dataset_distilbert,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler for DistilBERT\n",
    "optimizer_distilbert = AdamW(distilbert_model.parameters(), lr=3e-5)  # Slightly higher learning rate\n",
    "scheduler_distilbert = get_linear_schedule_with_warmup(\n",
    "    optimizer_distilbert,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DistilBERT model (faster training)\n",
    "distilbert_train_losses, distilbert_val_losses = train_transformer_model(\n",
    "    distilbert_model,\n",
    "    train_loader_distilbert,\n",
    "    val_loader_distilbert,\n",
    "    optimizer_distilbert,\n",
    "    scheduler_distilbert,\n",
    "    device,\n",
    "    num_epochs=4,  # Can train for more epochs due to faster training\n",
    "    patience=2,\n",
    "    model_save_path='../models/distilbert_toxic_classifier.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset with each tokenizer\n",
    "test_dataset_bert = ToxicCommentDatasetTransformer(X_test, y_test, bert_tokenizer)\n",
    "test_dataset_roberta = ToxicCommentDatasetTransformer(X_test, y_test, roberta_tokenizer)\n",
    "test_dataset_distilbert = ToxicCommentDatasetTransformer(X_test, y_test, distilbert_tokenizer)\n",
    "\n",
    "# Create test dataloaders\n",
    "test_loader_bert = DataLoader(test_dataset_bert, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader_roberta = DataLoader(test_dataset_roberta, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader_distilbert = DataLoader(test_dataset_distilbert, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best models\n",
    "bert_model.load_state_dict(torch.load('../models/bert_toxic_classifier.pt'))\n",
    "roberta_model.load_state_dict(torch.load('../models/roberta_toxic_classifier.pt'))\n",
    "distilbert_model.load_state_dict(torch.load('../models/distilbert_toxic_classifier.pt'))\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating BERT model on test set...\")\n",
    "bert_test_results = evaluate_transformer(bert_model, test_loader_bert, device)\n",
    "\n",
    "print(\"\\nEvaluating RoBERTa model on test set...\")\n",
    "roberta_test_results = evaluate_transformer(roberta_model, test_loader_roberta, device)\n",
    "\n",
    "print(\"\\nEvaluating DistilBERT model on test set...\")\n",
    "distilbert_test_results = evaluate_transformer(distilbert_model, test_loader_distilbert, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison dataframe\n",
    "model_results = {\n",
    "    'BERT': {\n",
    "        'accuracy': bert_test_results['accuracy'],\n",
    "        'macro_f1': bert_test_results['macro_f1'],\n",
    "        'micro_f1': bert_test_results['micro_f1'],\n",
    "        **{f'f1_{k}': v for k, v in bert_test_results['class_f1'].items()}\n",
    "    },\n",
    "    'RoBERTa': {\n",
    "        'accuracy': roberta_test_results['accuracy'],\n",
    "        'macro_f1': roberta_test_results['macro_f1'],\n",
    "        'micro_f1': roberta_test_results['micro_f1'],\n",
    "        **{f'f1_{k}': v for k, v in roberta_test_results['class_f1'].items()}\n",
    "    },\n",
    "    'DistilBERT': {\n",
    "        'accuracy': distilbert_test_results['accuracy'],\n",
    "        'macro_f1': distilbert_test_results['macro_f1'],\n",
    "        'micro_f1': distilbert_test_results['micro_f1'],\n",
    "        **{f'f1_{k}': v for k, v in distilbert_test_results['class_f1'].items()}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "results_df = results_df.sort_values('macro_f1', ascending=False)\n",
    "\n",
    "# Display results\n",
    "print(\"Model Performance Comparison:\")\n",
    "display(results_df)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../results/transformer_model_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F1 scores across categories\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "x = np.arange(len(categories))\n",
    "width = 0.25\n",
    "\n",
    "# Plot bars for each model\n",
    "bert_f1 = [bert_test_results['class_f1'][cat] for cat in categories]\n",
    "roberta_f1 = [roberta_test_results['class_f1'][cat] for cat in categories]\n",
    "distilbert_f1 = [distilbert_test_results['class_f1'][cat] for cat in categories]\n",
    "\n",
    "plt.bar(x - width, bert_f1, width, label='BERT')\n",
    "plt.bar(x, roberta_f1, width, label='RoBERTa')\n",
    "plt.bar(x + width, distilbert_f1, width, label='DistilBERT')\n",
    "\n",
    "plt.xlabel('Toxicity Category')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Scores by Toxicity Category and Model')\n",
    "plt.xticks(x, categories, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../results/transformer_f1_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerToxicCommentPredictor:\n",
    "    def __init__(self, model_path, model_type='bert', device='cpu'):\n",
    "        self.device = torch.device(device)\n",
    "        self.model_type = model_type.lower()\n",
    "        \n",
    "        # Initialize appropriate tokenizer and model\n",
    "        if self.model_type == 'bert':\n",
    "            self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "            self.model = BertForMultiLabelClassification(num_labels=6, model_name='bert-base-uncased')\n",
    "        elif self.model_type == 'roberta':\n",
    "            self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "            self.model = BertForMultiLabelClassification(num_labels=6, model_name='roberta-base')\n",
    "        elif self.model_type == 'distilbert':\n",
    "            self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "            self.model = BertForMultiLabelClassification(num_labels=6, model_name='distilbert-base-uncased')\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}. Choose 'bert', 'roberta', or 'distilbert'.\")\n",
    "            \n",
    "        # Load the trained model weights\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Label names\n",
    "        self.label_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "        \n",
    "    def predict(self, text, threshold=0.5):\n",
    "        # Tokenize the input text\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Move inputs to device\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            if self.model_type == 'bert':\n",
    "                outputs = self.model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], \n",
    "                                     token_type_ids=inputs['token_type_ids'])\n",
    "            else:  # RoBERTa and DistilBERT don't use token_type_ids\n",
    "                outputs = self.model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "        \n",
    "        # Convert to probabilities and binary decisions\n",
    "        probs = outputs.squeeze().cpu().numpy()\n",
    "        binary_preds = (probs > threshold).astype(int)\n",
    "        \n",
    "        # Create a dictionary of results\n",
    "        results = {\n",
    "            'probabilities': {label: float(prob) for label, prob in zip(self.label_names, probs)},\n",
    "            'predictions': {label: int(pred) for label, pred in zip(self.label_names, binary_preds)},\n",
    "            'is_toxic': bool(np.any(binary_preds))\n",
    "        }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictors from each model\n",
    "predictors = {\n",
    "    'BERT': TransformerToxicCommentPredictor('../models/bert_toxic_classifier.pt', model_type='bert', device=device),\n",
    "    'RoBERTa': TransformerToxicCommentPredictor('../models/roberta_toxic_classifier.pt', model_type='roberta', device=device),\n",
    "    'DistilBERT': TransformerToxicCommentPredictor('../models/distilbert_toxic_classifier.pt', model_type='distilbert', device=device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with example comments\n",
    "example_texts = [\n",
    "    \"This is a positive comment. I really appreciate your help.\",\n",
    "    \"You are an idiot and should not be allowed to post here.\",\n",
    "    \"This is neutral content that has no emotional charge.\",\n",
    "    \"You are a fucking disgrace.\"\n",
    "]\n",
    "\n",
    "for model_name, predictor in predictors.items():\n",
    "    print(f\"\\n===== {model_name} Predictions =====\\n\")\n",
    "    \n",
    "    for text in example_texts:\n",
    "        result = predictor.predict(text)\n",
    "        print(f\"Input: {text}\")\n",
    "        print(f\"Is toxic: {result['is_toxic']}\")\n",
    "        print(\"Toxicity probabilities:\")\n",
    "        for label, prob in result['probabilities'].items():\n",
    "            print(f\"  {label}: {prob:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Compare with RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RNN results if available\n",
    "try:\n",
    "    rnn_results_df = pd.read_pickle(\"../results/all_model_results.pkl\")\n",
    "    print(\"Loaded RNN model results\")\n",
    "    \n",
    "    # Extract metrics and model names\n",
    "    rnn_data = []\n",
    "    for _, row in rnn_results_df.iterrows():\n",
    "        model_name = row['model_name']\n",
    "        accuracy = row['accuracy']\n",
    "        macro_f1 = row['macro_f1']\n",
    "        micro_f1 = row['micro_f1']\n",
    "        \n",
    "        # Extract class-specific F1 scores\n",
    "        class_f1 = {col.split('_')[1]: row[col] for col in row.index if col.startswith('f1_')}\n",
    "        \n",
    "        rnn_data.append({\n",
    "            'model_name': model_name,\n",
    "            'model_type': 'RNN',\n",
    "            'accuracy': accuracy,\n",
    "            'macro_f1': macro_f1,\n",
    "            'micro_f1': micro_f1,\n",
    "            **{f'f1_{k}': v for k, v in class_f1.items()}\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame from RNN data\n",
    "    rnn_df = pd.DataFrame(rnn_data)\n",
    "    \n",
    "    # Add model type to transformer results\n",
    "    results_df['model_type'] = 'Transformer'\n",
    "    results_df.index.name = 'model_name'\n",
    "    results_df = results_df.reset_index()\n",
    "    \n",
    "    # Combine RNN and transformer results\n",
    "    all_models_df = pd.concat([rnn_df, results_df], ignore_index=True)\n",
    "    all_models_df = all_models_df.sort_values('macro_f1', ascending=False)\n",
    "    \n",
    "    print(\"\\nCombined Model Performance:\")\n",
    "    display(all_models_df[['model_name', 'model_type', 'accuracy', 'macro_f1', 'micro_f1']])\n",
    "    \n",
    "    # Save combined results\n",
    "    all_models_df.to_csv(\"../results/all_models_comparison.csv\")\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x='model_name', y='macro_f1', hue='model_type', data=all_models_df)\n",
    "    plt.title('Macro F1 Score by Model')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Macro F1 Score')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/all_models_macro_f1.png')\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"RNN model results not found. Skipping comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "In this notebook, we explored transformer-based models for toxic comment classification:\n",
    "\n",
    "1. We implemented and evaluated three transformer architectures:\n",
    "   - BERT\n",
    "   - RoBERTa\n",
    "   - DistilBERT\n",
    "\n",
    "2. Each model was trained on a multi-label classification task to detect six types of toxicity.\n",
    "\n",
    "3. We compared the performance of these models with each other and with RNN models from previous experiments.\n",
    "\n",
    "4. We created a prediction pipeline for making inferences on new text.\n",
    "\n",
    "The transformer models generally outperform RNN-based approaches due to their ability to better capture contextual information and their pre-training on large corpora. RoBERTa often achieves the best performance, though DistilBERT offers a good trade-off between performance and speed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
